# =============================================================================
# LangGraph RAG Agent 학습 환경 설정
# =============================================================================
# 이 파일을 복사하여 .env 파일로 저장하고, 실제 값을 입력하세요.
# cp .env.example .env

# -----------------------------------------------------------------------------
# OpenAI 호환 API 설정 (Local LLM, vLLM, Ollama 등)
# -----------------------------------------------------------------------------
# Local LLM 사용 시 API Key는 보통 무시되지만, 라이브러리 요구사항을 위해 임의의 값을 입력합니다.
OPENAI_API_KEY=lm-studio

# Local LLM 서버 주소 (예: LM Studio 기본값)
OPENAI_API_BASE=http://localhost:1234/v1

# 사용할 모델 이름 (서버에 로드된 모델명과 일치해야 할 수 있음)
# 예: llama3, mistral-7b-instruct, gpt-4o-mini (OpenAI 사용 시)
OPENAI_MODEL=local-model

# -----------------------------------------------------------------------------
# 임베딩 모델 설정
# -----------------------------------------------------------------------------
# 임베딩 모델 이름 (Local 사용 시 서버에 로드된 모델명)
# 예: text-embedding-3-small (OpenAI), nomic-embed-text (Ollama)
OPENAI_EMBEDDING_MODEL=local-embedding-model

# 임베딩 전용 URL (선택사항, 생략 시 OPENAI_API_BASE 사용)
# 별도의 임베딩 서버를 띄운 경우 사용하세요.
# OPENAI_EMBEDDING_API_BASE=http://localhost:1234/v1

# -----------------------------------------------------------------------------
# 일반 설정
# -----------------------------------------------------------------------------
# 로깅 레벨 (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# LangSmith 추적 (선택사항 - 디버깅용)
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=your-langsmith-api-key
# LANGCHAIN_PROJECT=langgraph-rag-learning
