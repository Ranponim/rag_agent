import os
import sys
from pathlib import Path
import httpx
import logging

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€í•˜ì—¬ ìœ í‹¸ë¦¬í‹° ë¡œë“œ
sys.path.insert(0, str(Path(__file__).parent.parent))

from langchain_openai import ChatOpenAI

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("diagnosis")

def diagnose():
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
    api_key = os.getenv("OPENAI_API_KEY", "lm-studio")
    base_url = os.getenv("OPENAI_API_BASE", "http://localhost:1234/v1")
    model = os.getenv("OPENAI_MODEL", "local-model")
    
    print("\n" + "="*60)
    print("ğŸ” LLM ì—°ê²° ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸")
    print("="*60)
    
    print(f"ğŸ“ Target Base URL: {base_url}")
    print(f"ğŸ”‘ API Key: {api_key[:4]}***")
    
    # 1. ë‹¨ìˆœ HTTP ì—°ê²° (Models ì—”ë“œí¬ì¸íŠ¸)
    print("\n[1] ê¸°ë³¸ HTTP ì—°ê²° í…ŒìŠ¤íŠ¸ (/v1/models)")
    try:
        models_url = f"{base_url.rstrip('/')}/models"
        print(f"   URL: {models_url}")
        
        # Curlê³¼ ìœ ì‚¬í•œ í—¤ë” ì„¤ì •
        headers = {
            "Authorization": f"Bearer {api_key}",
            "User-Agent": "curl/7.83.1", # Mimic curl
            "Accept": "*/*"
        }
        
        # trust_env=Falseë¡œ ì‹œìŠ¤í…œ í”„ë¡ì‹œ ë¬´ì‹œ, verifying=Falseë¡œ ì¸ì¦ì„œ ë¬´ì‹œ ì‹œë„
        transport = httpx.HTTPTransport(retries=1)
        with httpx.Client(transport=transport, trust_env=False, verify=False) as client:
            response = client.get(models_url, headers=headers, timeout=10.0)
        
        print(f"   ìƒíƒœ ì½”ë“œ: {response.status_code}")
        if response.status_code == 200:
            print("   âœ… ì—°ê²° ì„±ê³µ!")
            try:
                data = response.json()
                print(f"   ëª¨ë¸ ëª©ë¡: {[m['id'] for m in data.get('data', [])[:3]]} ...")
            except:
                print(f"   ì‘ë‹µ ë³¸ë¬¸: {response.text[:100]}...")
        else:
            print(f"   âŒ ì—°ê²° ì‹¤íŒ¨ (HTTP {response.status_code})")
            print(f"   ì‘ë‹µ ë³¸ë¬¸: {response.text}")
            
    except Exception as e:
        print(f"   âŒ ì˜ˆì™¸ ë°œìƒ: {e}")

    # 2. LangChain ChatOpenAI í…ŒìŠ¤íŠ¸
    print("\n[2] LangChain ChatOpenAI í…ŒìŠ¤íŠ¸")
    try:
        llm = ChatOpenAI(
            api_key=api_key,
            base_url=base_url,
            model=model,
            temperature=0,
            max_retries=1, # ë¹ ë¥¸ ì‹¤íŒ¨ë¥¼ ìœ„í•´
        )
        
        print(f"   LLM ìƒì„±: {llm}")
        print("   ë©”ì‹œì§€ ì „ì†¡ ì¤‘...") 
        
        # í´ë¼ì´ì–¸íŠ¸ì˜ ì‹¤ì œ Base URL í™•ì¸
        try:
            if hasattr(llm, "client") and hasattr(llm.client, "base_url"):
                 print(f"   OpenAI Client Base URL: {llm.client.base_url}")
            elif hasattr(llm, "base_url"):
                 print(f"   ChatOpenAI Base URL: {llm.base_url}")
        except Exception as e:
            print(f"   (Base URL í™•ì¸ ë¶ˆê°€: {e})")
        
        response = llm.invoke("Hello, simple test.")
        print(f"   âœ… ì‘ë‹µ ìˆ˜ì‹ : {response.content}")
        
    except Exception as e:
        print(f"   âŒ LangChain ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

    # 3. Typo Check (Completitions)
    print("\n[3] Typo URL Check (/chat/completitions)")
    try:
        typo_url = f"{base_url.rstrip('/')}/chat/completitions"
        print(f"   Testing Typo URL: {typo_url}")
        response = httpx.post(typo_url, headers={"Authorization": f"Bearer {api_key}"}, timeout=2.0)
        print(f"   ìƒíƒœ ì½”ë“œ: {response.status_code}")
        if response.status_code != 404:
             print("   âš ï¸ WARNING: ì„œë²„ê°€ ì˜¤íƒ€ë‚œ URL(/chat/completitions)ì— ì‘ë‹µí–ˆìŠµë‹ˆë‹¤!")
    except Exception as e:
        print(f"   (ì˜¤íƒ€ URL ì—°ê²° ì‹¤íŒ¨ - ì •ìƒ: {e})")

    # 4. LangChain Streaming í…ŒìŠ¤íŠ¸
    print("\n[4] LangChain ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸")
    try:
        llm = ChatOpenAI(
            api_key=api_key,
            base_url=base_url,
            model=model,
            temperature=0,
            max_retries=1,
            streaming=True
        )
        
        print("   ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ (ì‘ë‹µì´ í•œ ê¸€ìì”© í‘œì‹œë˜ì–´ì•¼ í•¨):")
        print("   > ", end="", flush=True)
        
        for chunk in llm.stream("Tell me a short sentence about why coding is fun."):
            content = chunk.content
            if content:
                print(content, end="", flush=True)
        
        print("\n   âœ… ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ!")
            
    except Exception as e:
        print(f"\n   âŒ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    diagnose()
