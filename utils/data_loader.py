# -*- coding: utf-8 -*-
"""
============================================================================
ğŸ“¦ RAG ë°ì´í„° ë¡œë” ëª¨ë“ˆ - ê³µí†µ ë°ì´í„° ë¡œë”© ë° ë²¡í„°í™” ìœ í‹¸ë¦¬í‹°
============================================================================

RAG ì˜ˆì œ íŒŒì¼ë“¤ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°ì´í„° ë¡œë”©, ë²¡í„°í™”, ì„ë² ë”© ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
    - ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ ì§€ì› (TXT, MD, CSV, PDF, XLSX, JSON, JSONL)
    - Vector Store ì˜ì†í™” (í•œ ë²ˆ ì„ë² ë”©í•œ ë°ì´í„° ì¬ì‚¬ìš©)
    - ./rag í´ë” íŒŒì¼ ë³€ê²½ ê°ì§€ (ì¶”ê°€/ìˆ˜ì • ì‹œ ìë™ ì¬ì„ë² ë”©)

ì‚¬ìš© ì˜ˆì‹œ:
    from utils.data_loader import get_rag_vector_store
    
    # Vector Store ê°€ì ¸ì˜¤ê¸° (ìë™ìœ¼ë¡œ ë°ì´í„° ë¡œë”© ë° ì„ë² ë”©)
    vs = get_rag_vector_store(collection_name="naive_rag")
    
    # ê²€ìƒ‰
    results = vs.search("LangGraphë€?", k=3)
"""

import os
import json
import hashlib
import logging
from pathlib import Path
from typing import List, Optional, Dict, Type

from langchain_core.documents import Document
from langchain_core.document_loaders.base import BaseLoader
from langchain_community.document_loaders import (
    DirectoryLoader,
    TextLoader,
    CSVLoader,
    PyPDFLoader,
    UnstructuredExcelLoader,
    JSONLoader  # JSON íŒŒì¼ìš© (ì¼ë°˜ JSON ì²˜ë¦¬)
)

from utils.llm_factory import get_embeddings
from utils.vector_store import VectorStoreManager

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)


# =============================================================================
# ğŸ“„ ì»¤ìŠ¤í…€ ë¡œë”: JSONLineLoader (ì‚¬ìš©ì ê¸°ì¡´ ì½”ë“œ ê¸°ë°˜)
# =============================================================================

class JSONLineLoader(BaseLoader):
    """
    JSONL(Line-delimited JSON) íŒŒì¼ì„ í•œ ì¤„ì”© ì½ì–´ì„œ Documentë¡œ ë³€í™˜í•˜ëŠ” ë¡œë”
    
    ê° ì¤„ ì „ì²´ë¥¼ ë¬¸ìì—´ë¡œ ì„ë² ë”©í•˜ì—¬ ëª¨ë“  í•„ë“œê°€ ê²€ìƒ‰ ëŒ€ìƒì´ ë©ë‹ˆë‹¤.
    ì¼ë°˜ JSON íŒŒì¼ë„ í•œ ì¤„ì— í•˜ë‚˜ì˜ JSON ê°ì²´ê°€ ìˆìœ¼ë©´ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    
    Args:
        file_path: JSONL íŒŒì¼ ê²½ë¡œ
        encoding: íŒŒì¼ ì¸ì½”ë”© (ê¸°ë³¸ê°’: utf-8)
    
    Example:
        >>> loader = JSONLineLoader("data.jsonl")
        >>> docs = loader.load()
        >>> print(len(docs))  # ê° ì¤„ì´ í•˜ë‚˜ì˜ Document
    """
    
    def __init__(self, file_path: str, encoding: str = 'utf-8'):
        """JSONLineLoader ì´ˆê¸°í™”"""
        self.file_path = file_path       # ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ
        self.encoding = encoding          # íŒŒì¼ ì¸ì½”ë”© (í•œê¸€ ì§€ì›ì„ ìœ„í•´ utf-8 ì‚¬ìš©)
    
    def load(self) -> List[Document]:
        """
        JSONL íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        
        Returns:
            List[Document]: ê° ì¤„ì„ Documentë¡œ ë³€í™˜í•œ ë¦¬ìŠ¤íŠ¸
        """
        docs = []  # ê²°ê³¼ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
        
        try:
            # íŒŒì¼ì„ ì½ê¸° ëª¨ë“œë¡œ ì—´ê¸°
            with open(self.file_path, 'r', encoding=self.encoding) as f:
                # íŒŒì¼ì„ í•œ ì¤„ì”© ìˆœíšŒ
                for line in f:
                    # ë¹ˆ ì¤„ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
                    if line.strip():
                        # ì¤„ ì „ì²´ë¥¼ page_contentë¡œ, íŒŒì¼ ê²½ë¡œë¥¼ metadataì— ì €ì¥
                        docs.append(Document(
                            page_content=line,  # JSON ë¬¸ìì—´ ì „ì²´ê°€ ì„ë² ë”© ëŒ€ìƒ
                            metadata={"source": self.file_path}  # ì¶œì²˜ ì •ë³´
                        ))
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¡œê·¸ ì¶œë ¥ (í”„ë¡œê·¸ë¨ì€ ê³„ì† ì§„í–‰)
            print(f"Error loading {self.file_path}: {e}")
        
        return docs


# =============================================================================
# ğŸ”§ íŒŒì¼ ë³€ê²½ ê°ì§€ ìœ í‹¸ë¦¬í‹°
# =============================================================================

def _get_folder_hash(folder_path: str, extensions: List[str]) -> str:
    """
    í´ë” ë‚´ íŒŒì¼ë“¤ì˜ í•´ì‹œê°’ì„ ê³„ì‚°í•˜ì—¬ ë³€ê²½ ê°ì§€ì— ì‚¬ìš©
    
    íŒŒì¼ ëª©ë¡ê³¼ ê° íŒŒì¼ì˜ ìˆ˜ì • ì‹œê°„ì„ ì¡°í•©í•˜ì—¬ í•´ì‹œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    í•´ì‹œê°€ ë‹¤ë¥´ë©´ íŒŒì¼ì´ ì¶”ê°€/ìˆ˜ì •/ì‚­ì œëœ ê²ƒì…ë‹ˆë‹¤.
    
    Args:
        folder_path: ê°ì‹œí•  í´ë” ê²½ë¡œ
        extensions: ê°ì‹œí•  íŒŒì¼ í™•ì¥ì ëª©ë¡
    
    Returns:
        str: í´ë” ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ëŠ” í•´ì‹œ ë¬¸ìì—´
    """
    folder = Path(folder_path)
    
    # í´ë”ê°€ ì—†ìœ¼ë©´ ë¹ˆ í•´ì‹œ ë°˜í™˜
    if not folder.exists():
        return "empty"
    
    # íŒŒì¼ ì •ë³´ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
    file_info = []
    
    # ì§€ì •ëœ í™•ì¥ìì˜ íŒŒì¼ë“¤ì„ ì°¾ì•„ì„œ ì •ë³´ ìˆ˜ì§‘
    for ext in extensions:
        for file_path in folder.rglob(f"*{ext}"):
            if file_path.is_file():
                # íŒŒì¼ëª…ê³¼ ìˆ˜ì • ì‹œê°„ì„ ë¬¸ìì—´ë¡œ ì €ì¥
                mtime = os.path.getmtime(file_path)
                file_info.append(f"{file_path}:{mtime}")
    
    # íŒŒì¼ ì •ë³´ë¥¼ ì •ë ¬í•˜ì—¬ ì¼ê´€ëœ í•´ì‹œ ìƒì„±
    file_info.sort()
    
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ í•´ì‹œ ë°˜í™˜
    if not file_info:
        return "no_files"
    
    # ë¬¸ìì—´ì„ í•©ì³ì„œ MD5 í•´ì‹œ ìƒì„±
    combined = "\n".join(file_info)
    return hashlib.md5(combined.encode()).hexdigest()


def _get_hash_file_path(persist_directory: str) -> str:
    """í•´ì‹œ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    return os.path.join(persist_directory, ".folder_hash")


def _read_saved_hash(persist_directory: str) -> Optional[str]:
    """ì €ì¥ëœ í•´ì‹œê°’ ì½ê¸°"""
    hash_file = _get_hash_file_path(persist_directory)
    if os.path.exists(hash_file):
        with open(hash_file, 'r') as f:
            return f.read().strip()
    return None


def _save_hash(persist_directory: str, hash_value: str):
    """í•´ì‹œê°’ ì €ì¥"""
    hash_file = _get_hash_file_path(persist_directory)
    os.makedirs(persist_directory, exist_ok=True)
    with open(hash_file, 'w') as f:
        f.write(hash_value)


# =============================================================================
# ğŸ“‚ RAG ë°ì´í„° ë¡œë” í´ë˜ìŠ¤
# =============================================================================

class RAGDataLoader:
    """
    RAG ì‹œìŠ¤í…œì„ ìœ„í•œ í†µí•© ë°ì´í„° ë¡œë”
    
    ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì„ ì§€ì›í•˜ë©°, ./rag í´ë”ì˜ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
    Vector Store ì˜ì†í™”ì™€ íŒŒì¼ ë³€ê²½ ê°ì§€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    Attributes:
        source_dir: ë°ì´í„° ì†ŒìŠ¤ í´ë” ê²½ë¡œ (ê¸°ë³¸ê°’: ./rag)
        encoding: íŒŒì¼ ì¸ì½”ë”© (ê¸°ë³¸ê°’: utf-8)
    
    Example:
        >>> loader = RAGDataLoader()
        >>> docs = loader.load_all()
        >>> print(f"ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")
    """
    
    # ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ìì™€ ë¡œë” ë§¤í•‘
    # DirectoryLoaderì—ì„œ ì‚¬ìš©í•  ë¡œë” í´ë˜ìŠ¤ë“¤
    LOADER_MAP: Dict[str, Type[BaseLoader]] = {
        ".txt": TextLoader,           # ì¼ë°˜ í…ìŠ¤íŠ¸ íŒŒì¼
        ".md": TextLoader,            # ë§ˆí¬ë‹¤ìš´ íŒŒì¼
        ".csv": CSVLoader,            # CSV íŒŒì¼
        ".pdf": PyPDFLoader,          # PDF ë¬¸ì„œ
        ".xlsx": UnstructuredExcelLoader,  # Excel íŒŒì¼
        # JSON: JSONLoader ì‚¬ìš© (ë³„ë„ ì²˜ë¦¬)
        # JSONL: JSONLineLoader ì‚¬ìš© (ë³„ë„ ì²˜ë¦¬)
    }
    
    def __init__(
        self, 
        source_dir: str = "./rag",
        encoding: str = "utf-8"
    ):
        """
        RAGDataLoader ì´ˆê¸°í™”
        
        Args:
            source_dir: ë°ì´í„° ì†ŒìŠ¤ í´ë” ê²½ë¡œ
            encoding: íŒŒì¼ ì¸ì½”ë”©
        """
        self.source_dir = source_dir  # ë°ì´í„°ë¥¼ ì½ì–´ì˜¬ í´ë”
        self.encoding = encoding       # íŒŒì¼ ì¸ì½”ë”©
        
        # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(source_dir):
            os.makedirs(source_dir)
            print(f"ğŸ“ {source_dir} í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
    
    def load_all(self) -> List[Document]:
        """
        ì†ŒìŠ¤ í´ë”ì˜ ëª¨ë“  ì§€ì› íŒŒì¼ì„ ë¡œë“œ
        
        Returns:
            List[Document]: ë¡œë“œëœ ëª¨ë“  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        print(f"\nğŸ“¥ [ë°ì´í„° ë¡œë”] {self.source_dir} í´ë”ì—ì„œ íŒŒì¼ ë¡œë”© ì¤‘...")
        
        all_documents = []
        
        # ê° í™•ì¥ìë³„ë¡œ íŒŒì¼ ë¡œë“œ
        for ext, loader_cls in self.LOADER_MAP.items():
            try:
                docs = self._load_by_extension(ext, loader_cls)
                if docs:
                    all_documents.extend(docs)
                    print(f"   â†’ {ext} íŒŒì¼ {len(docs)}ê°œ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                # íŠ¹ì • í™•ì¥ì ë¡œë“œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                print(f"   âš ï¸ {ext} ë¡œë” ê²½ê³ : {str(e)[:50]}...")
        
        # JSON íŒŒì¼ ë¡œë“œ (LangChain JSONLoader ì‚¬ìš©)
        try:
            json_docs = self._load_json_files()
            if json_docs:
                all_documents.extend(json_docs)
                print(f"   â†’ .json íŒŒì¼ {len(json_docs)}ê°œ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸ .json ë¡œë” ê²½ê³ : {str(e)[:50]}...")
        
        # JSONL íŒŒì¼ ë¡œë“œ (ì»¤ìŠ¤í…€ JSONLineLoader ì‚¬ìš© - í•œ ì¤„ì”© ì²˜ë¦¬)
        try:
            jsonl_docs = self._load_jsonl_files()
            if jsonl_docs:
                all_documents.extend(jsonl_docs)
                print(f"   â†’ .jsonl íŒŒì¼ {len(jsonl_docs)}ê°œ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸ .jsonl ë¡œë” ê²½ê³ : {str(e)[:50]}...")
        
        if all_documents:
            print(f"âœ… ì´ {len(all_documents)}ê°œì˜ ë¬¸ì„œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print(f"   âš ï¸ {self.source_dir} í´ë”ì— ì§€ì›ë˜ëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        return all_documents
    
    def _load_by_extension(
        self, 
        extension: str, 
        loader_cls: Type[BaseLoader]
    ) -> List[Document]:
        """
        íŠ¹ì • í™•ì¥ìì˜ íŒŒì¼ë“¤ì„ ë¡œë“œ
        
        Args:
            extension: íŒŒì¼ í™•ì¥ì (ì˜ˆ: ".txt")
            loader_cls: ì‚¬ìš©í•  ë¡œë” í´ë˜ìŠ¤
        
        Returns:
            List[Document]: í•´ë‹¹ í™•ì¥ì íŒŒì¼ë“¤ì˜ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        # DirectoryLoader ì‚¬ìš©
        loader = DirectoryLoader(
            path=self.source_dir,
            glob=f"**/*{extension}",
            loader_cls=loader_cls,
            loader_kwargs={"encoding": self.encoding},
            use_multithreading=False,  # Windows ì•ˆì •ì„±
            silent_errors=True
        )
        
        return loader.load()
    
    def _load_json_files(self) -> List[Document]:
        """
        JSON íŒŒì¼ì„ LangChain JSONLoaderë¡œ ë¡œë“œ
        
        ì¼ë°˜ JSON íŒŒì¼ì„ ì „ì²´ êµ¬ì¡°ë¡œ íŒŒì‹±í•˜ì—¬ Documentë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            List[Document]: ë¡œë“œëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        documents = []
        source_path = Path(self.source_dir)
        
        # .json íŒŒì¼ ì°¾ê¸°
        for file_path in source_path.rglob("*.json"):
            if file_path.is_file():
                try:
                    # JSONLoader: ì „ì²´ JSON êµ¬ì¡°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    loader = JSONLoader(
                        file_path=str(file_path),
                        jq_schema=".",  # ì „ì²´ JSON ê°ì²´ ì„ íƒ
                        text_content=False  # JSONì„ ë¬¸ìì—´ë¡œ ë³€í™˜
                    )
                    docs = loader.load()
                    documents.extend(docs)
                except Exception as e:
                    # jq ê´€ë ¨ ì˜¤ë¥˜ ì‹œ í…ìŠ¤íŠ¸ë¡œ ì½ê¸° fallback
                    try:
                        with open(file_path, 'r', encoding=self.encoding) as f:
                            content = f.read()
                        documents.append(Document(
                            page_content=content,
                            metadata={"source": str(file_path)}
                        ))
                    except Exception as fallback_e:
                        print(f"   âš ï¸ JSON ë¡œë“œ ì‹¤íŒ¨ {file_path}: {fallback_e}")
        
        return documents
    
    def _load_jsonl_files(self) -> List[Document]:
        """
        JSONL íŒŒì¼ì„ ì»¤ìŠ¤í…€ JSONLineLoaderë¡œ ë¡œë“œ (í•œ ì¤„ì”© ì²˜ë¦¬)
        
        ê° ì¤„ì„ ë³„ë„ì˜ Documentë¡œ ë³€í™˜í•˜ì—¬ ê°œë³„ ì„ë² ë”©í•©ë‹ˆë‹¤.
        
        Returns:
            List[Document]: ë¡œë“œëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        documents = []
        source_path = Path(self.source_dir)
        
        # .jsonl íŒŒì¼ ì°¾ê¸°
        for file_path in source_path.rglob("*.jsonl"):
            if file_path.is_file():
                loader = JSONLineLoader(
                    file_path=str(file_path),
                    encoding=self.encoding
                )
                docs = loader.load()
                documents.extend(docs)
        
        return documents
    
    def get_supported_extensions(self) -> List[str]:
        """ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ì ëª©ë¡ ë°˜í™˜"""
        return list(self.LOADER_MAP.keys()) + [".json", ".jsonl"]


# =============================================================================
# ğŸš€ í¸ì˜ í•¨ìˆ˜: Vector Store ì´ˆê¸°í™” ë° ë°ì´í„° ë¡œë”© í†µí•©
# =============================================================================

def get_rag_vector_store(
    collection_name: str = "rag_collection",
    source_dir: str = "./rag",
    persist_dir: str = "./vector_db",
    embedding_provider: Optional[str] = None,
    force_reload: bool = False
) -> VectorStoreManager:
    """
    RAGìš© Vector Storeë¥¼ ì´ˆê¸°í™”í•˜ê³  ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    
    ./rag í´ë”ì˜ íŒŒì¼ ë³€ê²½ì„ ê°ì§€í•˜ì—¬ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì¬ì„ë² ë”©í•©ë‹ˆë‹¤.
    í•œ ë²ˆ ì„ë² ë”©í•œ ë°ì´í„°ëŠ” persist_dirì— ì €ì¥ë˜ì–´ ì¬ì‚¬ìš©ë©ë‹ˆë‹¤.
    
    Args:
        collection_name: Vector Store ì»¬ë ‰ì…˜ ì´ë¦„
        source_dir: ë°ì´í„° ì†ŒìŠ¤ í´ë” (ê¸°ë³¸ê°’: ./rag)
        persist_dir: Vector Store ì˜ì†í™” í´ë” (ê¸°ë³¸ê°’: ./vector_db)
        embedding_provider: ì„ë² ë”© provider ("openai" ë˜ëŠ” "ollama", Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
        force_reload: Trueë©´ íŒŒì¼ ë³€ê²½ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ê°•ì œ ì¬ì„ë² ë”©
    
    Returns:
        VectorStoreManager: ì´ˆê¸°í™”ëœ Vector Store ë§¤ë‹ˆì €
    
    Example:
        >>> vs = get_rag_vector_store(collection_name="naive_rag")
        >>> results = vs.search("LangGraphë€?", k=3)
    """
    # ì»¬ë ‰ì…˜ë³„ ì˜ì†í™” ê²½ë¡œ ì„¤ì •
    collection_persist_dir = os.path.join(persist_dir, collection_name)
    
    # ì„ë² ë”© ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
    if embedding_provider:
        embeddings = get_embeddings(provider=embedding_provider)
    else:
        embeddings = get_embeddings()
    
    # Vector Store ë§¤ë‹ˆì € ìƒì„± (ì˜ì†í™” ê²½ë¡œ ì§€ì •)
    manager = VectorStoreManager(
        embeddings=embeddings,
        collection_name=collection_name,
        persist_directory=collection_persist_dir
    )
    
    # íŒŒì¼ ë³€ê²½ ê°ì§€ë¥¼ ìœ„í•œ í•´ì‹œ ê³„ì‚°
    loader = RAGDataLoader(source_dir=source_dir)
    extensions = loader.get_supported_extensions()
    current_hash = _get_folder_hash(source_dir, extensions)
    saved_hash = _read_saved_hash(collection_persist_dir)
    
    # ì¬ì„ë² ë”© í•„ìš” ì—¬ë¶€ íŒë‹¨
    need_reload = force_reload or (current_hash != saved_hash)
    
    if need_reload:
        if force_reload:
            print("ğŸ”„ ê°•ì œ ë¦¬ë¡œë“œê°€ ìš”ì²­ë˜ì—ˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë‹¤ì‹œ ì„ë² ë”©í•©ë‹ˆë‹¤...")
        else:
            print("ğŸ” ./rag í´ë”ì— ë³€ê²½ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë‹¤ì‹œ ì„ë² ë”©í•©ë‹ˆë‹¤...")
        
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ìƒˆë¡œ ë¡œë“œ
        manager.clear()
        
        # ë°ì´í„° ë¡œë“œ
        documents = loader.load_all()
        
        if documents:
            # Vector Storeì— ë¬¸ì„œ ì¶”ê°€ (ìë™ìœ¼ë¡œ ì²­í‚¹ ë° ì„ë² ë”©)
            manager.add_documents(documents)
            print(f"âœ… {len(documents)}ê°œì˜ ë¬¸ì„œê°€ Vector Storeì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ê°€
            print("   âš ï¸ ë¡œë”©ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì ì¬í•©ë‹ˆë‹¤.")
            manager.add_texts(["LangGraphì™€ RAG ì˜ˆì œ ë°ì´í„°ì…ë‹ˆë‹¤."])
        
        # í˜„ì¬ í•´ì‹œ ì €ì¥
        _save_hash(collection_persist_dir, current_hash)
    else:
        print(f"âœ… ./rag í´ë”ì— ë³€ê²½ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ì¡´ ì„ë² ë”©ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.")
        print(f"   (ì €ì¥ ìœ„ì¹˜: {collection_persist_dir})")
    
    return manager


# =============================================================================
# ğŸ§ª í…ŒìŠ¤íŠ¸ ì½”ë“œ
# =============================================================================

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ“¦ RAG ë°ì´í„° ë¡œë” í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # Vector Store ê°€ì ¸ì˜¤ê¸° (ìë™ ê°ì§€ ë° ì„ë² ë”©)
    vs = get_rag_vector_store(collection_name="test_collection")
    
    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    query = "LangGraphë€?"
    results = vs.search(query, k=2)
    
    print(f"\nğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ì¿¼ë¦¬: '{query}')")
    print(f"ê²°ê³¼ ({len(results)}ê°œ):")
    for i, doc in enumerate(results, 1):
        preview = doc.page_content[:100].replace('\n', ' ')
        print(f"   [{i}] {preview}...")
