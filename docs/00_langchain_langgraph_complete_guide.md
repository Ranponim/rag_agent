# ğŸš€ LangChain & LangGraph ì™„ë²½ ê°€ì´ë“œ

ì´ˆë³´ìë¥¼ ìœ„í•œ LangChainë¶€í„° LangGraphê¹Œì§€ì˜ ì™„ë²½í•œ í•™ìŠµ ê°€ì´ë“œì…ë‹ˆë‹¤.

---

## ğŸ“‹ ëª©ì°¨

- [1. LangChain ì†Œê°œ](#1-langchain-ì†Œê°œ)
  - [LangChainì´ë€?](#langchainì´ë€)
  - [í•µì‹¬ ì»´í¬ë„ŒíŠ¸](#í•µì‹¬-ì»´í¬ë„ŒíŠ¸)
- [2. LCEL (LangChain Expression Language) ì™„ë²½ ê°€ì´ë“œ](#2-lcel-langchain-expression-language-ì™„ë²½-ê°€ì´ë“œ)
  - [LCELì´ë€?](#lcelì´ë€)
  - [Runnable ì¸í„°í˜ì´ìŠ¤](#runnable-ì¸í„°í˜ì´ìŠ¤)
  - [LCEL ì‹¤ìŠµ ì˜ˆì œ](#lcel-ì‹¤ìŠµ-ì˜ˆì œ)
- [3. LangChainì˜ í•œê³„ì™€ LangGraphì˜ ë“±ì¥](#3-langchainì˜-í•œê³„ì™€-langgraphì˜-ë“±ì¥)
- [4. LangGraph í•µì‹¬ ê°œë…](#4-langgraph-í•µì‹¬-ê°œë…)
- [5. LangGraph ë‹¨ê³„ë³„ í•™ìŠµ ì˜ˆì œ](#5-langgraph-ë‹¨ê³„ë³„-í•™ìŠµ-ì˜ˆì œ)
- [6. LangGraph API ìƒì„¸ ë ˆí¼ëŸ°ìŠ¤](#6-langgraph-api-ìƒì„¸-ë ˆí¼ëŸ°ìŠ¤)
- [7. ê·¸ë˜í”„ íŒ¨í„´ ëª¨ìŒ](#7-ê·¸ë˜í”„-íŒ¨í„´-ëª¨ìŒ)
- [8. í•™ìŠµ ë¡œë“œë§µ](#8-í•™ìŠµ-ë¡œë“œë§µ)

---

## 1. LangChain ì†Œê°œ

### LangChainì´ë€?

**LangChain**ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ê°œë°œí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” **ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬**ì…ë‹ˆë‹¤.

#### ì™œ LangChainì´ í•„ìš”í•œê°€ìš”?

LLMì„ ì§ì ‘ ì‚¬ìš©í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì–´ë ¤ì›€ì´ ìˆìŠµë‹ˆë‹¤:

- ğŸ”§ **ë³µì¡í•œ í†µí•©**: ë‹¤ì–‘í•œ LLM ì œê³µì(OpenAI, Anthropic, Ollama ë“±)ë§ˆë‹¤ APIê°€ ë‹¤ë¦„
- ğŸ“ **í”„ë¡¬í”„íŠ¸ ê´€ë¦¬**: íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì‘ì„±ê³¼ ì¬ì‚¬ìš©ì´ ì–´ë ¤ì›€
- ğŸ”— **ì›Œí¬í”Œë¡œìš° êµ¬ì„±**: ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ì—°ê²°í•˜ëŠ” íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ì´ ë³µì¡í•¨
- ğŸ› ï¸ **ë„êµ¬ ì—°ë™**: ì™¸ë¶€ API, ë°ì´í„°ë² ì´ìŠ¤ ë“±ê³¼ì˜ í†µí•©ì´ ë²ˆê±°ë¡œì›€

LangChainì€ ì´ëŸ¬í•œ ë¬¸ì œë“¤ì„ í•´ê²°í•˜ëŠ” **í†µí•© ì¸í„°í˜ì´ìŠ¤**ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸

LangChainì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œë¥¼ ì•Œì•„ë´…ì‹œë‹¤.

#### 1) Chat Models (ì±„íŒ… ëª¨ë¸)

LLMê³¼ ìƒí˜¸ì‘ìš©í•˜ëŠ” í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.

```python
# OpenAI í˜¸í™˜ ëª¨ë¸ (Local LLM í¬í•¨)
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.7,  # ì°½ì˜ì„± ì¡°ì ˆ (0~1)
    max_tokens=1000   # ìµœëŒ€ ì‘ë‹µ ê¸¸ì´
)

# Ollama (ë¡œì»¬ ì˜¤í”ˆì†ŒìŠ¤ LLM)
from langchain_ollama import ChatOllama

llm = ChatOllama(
    model="llama3",
    temperature=0
)
```

#### 2) Prompts & Prompt Templates (í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿)

ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

```python
from langchain_core.prompts import ChatPromptTemplate

# ê¸°ë³¸ í…œí”Œë¦¿
prompt = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ {role}ì…ë‹ˆë‹¤."),
    ("human", "{question}")
])

# ì‚¬ìš© ì˜ˆì‹œ
formatted = prompt.invoke({
    "role": "ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸",
    "question": "LangChainì´ ë­ì•¼?"
})
print(formatted)
# ì¶œë ¥:
# [SystemMessage(content='ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.'),
#  HumanMessage(content='LangChainì´ ë­ì•¼?')]
```

#### 3) Output Parsers (ì¶œë ¥ íŒŒì„œ)

LLM ì‘ë‹µì„ ì›í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

```python
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field

# ë¬¸ìì—´ íŒŒì„œ (ê¸°ë³¸)
parser = StrOutputParser()

# JSON íŒŒì„œ (êµ¬ì¡°í™”ëœ ë°ì´í„°)
class Person(BaseModel):
    name: str = Field(description="ì‚¬ëŒì˜ ì´ë¦„")
    age: int = Field(description="ì‚¬ëŒì˜ ë‚˜ì´")

json_parser = JsonOutputParser(pydantic_object=Person)

# íŒŒì„œ ì‚¬ìš©
prompt_with_format = ChatPromptTemplate.from_messages([
    ("system", "ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:\n{format_instructions}"),
    ("human", "{query}")
])

# format_instructions ìë™ ìƒì„±
format_instructions = json_parser.get_format_instructions()
```

#### 4) Tools (ë„êµ¬)

LLMì´ ì™¸ë¶€ ì„¸ê³„ì™€ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

```python
from langchain_core.tools import tool

@tool
def search_web(query: str) -> str:
    """ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰í•  í‚¤ì›Œë“œ
    
    Returns:
        str: ê²€ìƒ‰ ê²°ê³¼
    """
    # ì‹¤ì œë¡œëŠ” ê²€ìƒ‰ API í˜¸ì¶œ
    return f"{query}ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼..."

@tool
def calculate(expression: str) -> str:
    """ìˆ˜í•™ í‘œí˜„ì‹ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        expression: ê³„ì‚°í•  í‘œí˜„ì‹ (ì˜ˆ: "2 + 2")
    
    Returns:
        str: ê³„ì‚° ê²°ê³¼
    """
    try:
        result = eval(expression)  # ì£¼ì˜: í”„ë¡œë•ì…˜ì—ì„œëŠ” ì•ˆì „í•œ íŒŒì„œ ì‚¬ìš©
        return f"ê²°ê³¼: {result}"
    except Exception as e:
        return f"ì˜¤ë¥˜: {e}"

# ë„êµ¬ ëª©ë¡
tools = [search_web, calculate]

# LLMì— ë„êµ¬ ë°”ì¸ë”©
llm_with_tools = llm.bind_tools(tools)
```

#### 5) Messages (ë©”ì‹œì§€)

ëŒ€í™”ë¥¼ êµ¬ì„±í•˜ëŠ” ê¸°ë³¸ ë‹¨ìœ„ì…ë‹ˆë‹¤.

```python
from langchain_core.messages import (
    SystemMessage,  # AIì˜ ì—­í• /ê·œì¹™ ì •ì˜
    HumanMessage,   # ì‚¬ìš©ì ì…ë ¥
    AIMessage,      # AI ì‘ë‹µ
    ToolMessage     # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
)

# ëŒ€í™” êµ¬ì„± ì˜ˆì‹œ
messages = [
    SystemMessage(content="ë‹¹ì‹ ì€ ìˆ˜í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
    HumanMessage(content="2 + 2ëŠ”?"),
    AIMessage(content="4ì…ë‹ˆë‹¤."),
    HumanMessage(content="10 ê³±í•˜ê¸° 5ëŠ”?")
]

# LLM í˜¸ì¶œ
response = llm.invoke(messages)
print(response.content)  # "50ì…ë‹ˆë‹¤."
```

---

## 2. LCEL (LangChain Expression Language) ì™„ë²½ ê°€ì´ë“œ

### LCELì´ë€?

**LCEL** (LangChain Expression Language)ì€ LangChain ì»´í¬ë„ŒíŠ¸ë“¤ì„ **ì²´ì¸(Chain)**ìœ¼ë¡œ ì—°ê²°í•˜ëŠ” **ì„ ì–¸ì (Declarative) ë¬¸ë²•**ì…ë‹ˆë‹¤.

#### LCELì˜ í•µì‹¬ ì² í•™

```python
# âŒ ì „í†µì ì¸ ë°©ì‹ (ëª…ë ¹í˜•)
result1 = prompt.format(question="ì•ˆë…•?")
result2 = llm.invoke(result1)
result3 = parser.parse(result2)

# âœ… LCEL ë°©ì‹ (ì„ ì–¸í˜•)
chain = prompt | llm | parser
result = chain.invoke({"question": "ì•ˆë…•?"})
```

**ì¥ì :**
- ğŸ“– **ì½ê¸° ì‰¬ì›€**: íŒŒì´í”„ë¼ì¸ì˜ íë¦„ì´ ëª…í™•
- ğŸ”„ **ì¬ì‚¬ìš© ê°€ëŠ¥**: ì²´ì¸ì„ ë³€ìˆ˜ë¡œ ì €ì¥í•˜ê³  ì¬ì‚¬ìš©
- âš¡ **ìë™ ìµœì í™”**: LangChainì´ ë‚´ë¶€ì ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬ ë“± ìµœì í™”
- ğŸ”§ **ìŠ¤íŠ¸ë¦¬ë° ì§€ì›**: `.stream()` ë©”ì„œë“œë¡œ ì‹¤ì‹œê°„ ì‘ë‹µ ê°€ëŠ¥

### Runnable ì¸í„°í˜ì´ìŠ¤

LCELì˜ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ëŠ” **Runnable ì¸í„°í˜ì´ìŠ¤**ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

#### Runnableì˜ í•µì‹¬ ë©”ì„œë“œ

```python
from langchain_core.runnables import Runnable

# ëª¨ë“  Runnableì€ ë‹¤ìŒ ë©”ì„œë“œë¥¼ ê°€ì§:

# 1. invoke() - ë™ê¸° ì‹¤í–‰
result = chain.invoke(input_data)

# 2. ainvoke() - ë¹„ë™ê¸° ì‹¤í–‰
result = await chain.ainvoke(input_data)

# 3. stream() - ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
for chunk in chain.stream(input_data):
    print(chunk, end="", flush=True)

# 4. batch() - ë°°ì¹˜ ì‹¤í–‰
results = chain.batch([input1, input2, input3])
```

### LCEL ì‹¤ìŠµ ì˜ˆì œ

ë‹¨ê³„ì ìœ¼ë¡œ LCELì„ ìµí˜€ë´…ì‹œë‹¤.

#### Step 1: ê°„ë‹¨í•œ Prompt + LLM ì²´ì¸

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# 1. ì»´í¬ë„ŒíŠ¸ ì •ì˜
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

prompt = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë²ˆì—­ê°€ì…ë‹ˆë‹¤."),
    ("human", "{text}ë¥¼ {language}ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.")
])

# 2. ì²´ì¸ êµ¬ì„± (íŒŒì´í”„ ì—°ì‚°ì |)
chain = prompt | llm

# 3. ì‹¤í–‰
result = chain.invoke({
    "text": "Hello, World!",
    "language": "í•œêµ­ì–´"
})

print(result.content)
# ì¶œë ¥: "ì•ˆë…•í•˜ì„¸ìš”, ì„¸ê³„!"
```

**íŒŒì´í”„ ì—°ì‚°ì `|`ì˜ ì˜ë¯¸:**
- `A | B`: "Aì˜ ì¶œë ¥ì„ Bì˜ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬"
- `prompt | llm`: "í”„ë¡¬í”„íŠ¸ ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬"

#### Step 2: Output Parser ì¶”ê°€

```python
from langchain_core.output_parsers import StrOutputParser

# íŒŒì„œ ì¶”ê°€: LLM ì‘ë‹µì—ì„œ ë¬¸ìì—´ë§Œ ì¶”ì¶œ
parser = StrOutputParser()

# ì²´ì¸ í™•ì¥
chain = prompt | llm | parser

# ì‹¤í–‰
result = chain.invoke({
    "text": "Thank you",
    "language": "ì¼ë³¸ì–´"
})

print(result)  # ì´ì œ ë¬¸ìì—´ë§Œ ë°˜í™˜ë¨
# ì¶œë ¥: "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™"
```

#### Step 3: ë³µì¡í•œ ì²´ì¸ êµ¬ì„±

```python
from langchain_core.runnables import RunnableLambda

# ì»¤ìŠ¤í…€ ë¡œì§ì„ ì²´ì¸ì— ì¶”ê°€
def uppercase_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ë¥¼ ëŒ€ë¬¸ìë¡œ ë³€í™˜"""
    return text.upper()

def add_emoji(text: str) -> str:
    """ì´ëª¨ì§€ ì¶”ê°€"""
    return f"âœ¨ {text} âœ¨"

# ì—¬ëŸ¬ ë‹¨ê³„ ì²´ì¸
chain = (
    prompt 
    | llm 
    | StrOutputParser() 
    | RunnableLambda(uppercase_text)  # ì»¤ìŠ¤í…€ í•¨ìˆ˜
    | RunnableLambda(add_emoji)
)

result = chain.invoke({
    "text": "Hello",
    "language": "ìŠ¤í˜ì¸ì–´"
})

print(result)
# ì¶œë ¥: "âœ¨ HOLA âœ¨"
```

#### Step 4: ì¡°ê±´ë¶€ ì²´ì¸ (RunnableBranch)

```python
from langchain_core.runnables import RunnableBranch

# ì…ë ¥ ì–¸ì–´ì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬
formal_prompt = ChatPromptTemplate.from_template(
    "ë‹¤ìŒì„ ê²©ì‹ìˆê²Œ ë²ˆì—­: {text}"
)
casual_prompt = ChatPromptTemplate.from_template(
    "ë‹¤ìŒì„ ìºì£¼ì–¼í•˜ê²Œ ë²ˆì—­: {text}"
)

# ì¡°ê±´ë¶€ ë¶„ê¸°
branch = RunnableBranch(
    (lambda x: x.get("formal", False), formal_prompt | llm | parser),
    casual_prompt | llm | parser  # ê¸°ë³¸ê°’
)

# ê²©ì‹ìˆëŠ” ë²ˆì—­
result1 = branch.invoke({"text": "Hello", "formal": True})

# ìºì£¼ì–¼í•œ ë²ˆì—­
result2 = branch.invoke({"text": "Hello", "formal": False})
```

#### Step 5: ë³‘ë ¬ ì‹¤í–‰ (RunnableParallel)

```python
from langchain_core.runnables import RunnableParallel

# ì—¬ëŸ¬ ì–¸ì–´ë¡œ ë™ì‹œ ë²ˆì—­
translate_ko = ChatPromptTemplate.from_template("{text}ë¥¼ í•œêµ­ì–´ë¡œ") | llm | parser
translate_ja = ChatPromptTemplate.from_template("{text}ë¥¼ ì¼ë³¸ì–´ë¡œ") | llm | parser
translate_es = ChatPromptTemplate.from_template("{text}ë¥¼ ìŠ¤í˜ì¸ì–´ë¡œ") | llm | parser

# ë³‘ë ¬ ì²´ì¸
parallel_chain = RunnableParallel(
    korean=translate_ko,
    japanese=translate_ja,
    spanish=translate_es
)

# í•œë²ˆì— 3ê°œ ì–¸ì–´ë¡œ ë²ˆì—­
results = parallel_chain.invoke({"text": "Good morning"})

print(results)
# ì¶œë ¥:
# {
#     'korean': 'ì¢‹ì€ ì•„ì¹¨',
#     'japanese': 'ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™',
#     'spanish': 'Buenos dÃ­as'
# }
```

---

## 3. LangChainì˜ í•œê³„ì™€ LangGraphì˜ ë“±ì¥

### LangChainì˜ í•œê³„

LangChainê³¼ LCELì€ ê°•ë ¥í•˜ì§€ë§Œ, **ì„ í˜• êµ¬ì¡°(Linear Pipeline)**ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

```
[ì…ë ¥] â†’ [ì²˜ë¦¬1] â†’ [ì²˜ë¦¬2] â†’ [ì²˜ë¦¬3] â†’ [ì¶œë ¥]
```

ì´ êµ¬ì¡°ëŠ” ê°„ë‹¨í•œ ì‘ì—…ì—ëŠ” ì¶©ë¶„í•˜ì§€ë§Œ, ë‹¤ìŒê³¼ ê°™ì€ ìƒí™©ì—ì„œ í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤:

> [!WARNING]
> **LangChain/LCELë§Œìœ¼ë¡œ êµ¬í˜„í•˜ê¸° ì–´ë ¤ìš´ ê²ƒë“¤**
> - âŒ ê²°ê³¼ì— ë”°ë¼ **ë‹¤ë¥¸ ê²½ë¡œë¡œ ë¶„ê¸°**í•´ì•¼ í•  ë•Œ
> - âŒ ì‹¤íŒ¨ ì‹œ **ì´ì „ ë‹¨ê³„ë¡œ ëŒì•„ê°€**ì•¼ í•  ë•Œ (ë£¨í”„)
> - âŒ ì—¬ëŸ¬ ì‘ì—…ì„ **ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í•©ì³**ì•¼ í•  ë•Œ
> - âŒ **ë³µì¡í•œ ìƒíƒœ**ë¥¼ ì—¬ëŸ¬ ë‹¨ê³„ì—ì„œ ê³µìœ í•˜ê³  ìˆ˜ì •í•´ì•¼ í•  ë•Œ
> - âŒ Agentê°€ **ìŠ¤ìŠ¤ë¡œ íŒë‹¨**í•˜ì—¬ ë„êµ¬ë¥¼ ë°˜ë³µ í˜¸ì¶œí•´ì•¼ í•  ë•Œ

### LangGraphì˜ ë“±ì¥

**LangGraph**ëŠ” ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë“±ì¥í–ˆìŠµë‹ˆë‹¤. **ê·¸ë˜í”„(Graph)** êµ¬ì¡°ë¡œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```mermaid
graph LR
    A[ì…ë ¥] --> B{íŒë‹¨}
    B -->|ì¡°ê±´1| C[ì²˜ë¦¬A]
    B -->|ì¡°ê±´2| D[ì²˜ë¦¬B]
    C --> E[ê²°ê³¼ ê²€ì¦]
    D --> E
    E -->|ì‹¤íŒ¨| B
    E -->|ì„±ê³µ| F[ì¶œë ¥]
```

### LangChain vs LangGraph ë¹„êµ

| íŠ¹ì§• | LangChain (LCEL) | LangGraph |
|:---:|:---|:---|
| **êµ¬ì¡°** | ì„ í˜• íŒŒì´í”„ë¼ì¸ | ìˆœí™˜ ê·¸ë˜í”„ |
| **íë¦„ ì œì–´** | A â†’ B â†’ C (ì¼ë°©í–¥) | A â†’ B â†’ A (ë£¨í”„ ê°€ëŠ¥) |
| **ìƒíƒœ ê´€ë¦¬** | ì²´ì¸ ê°„ ì „ë‹¬ | ëª…ì‹œì  State ê°ì²´ |
| **ë¶„ê¸°** | ì œí•œì  (RunnableBranch) | ììœ ë¡œìš´ ì¡°ê±´ë¶€ ë¶„ê¸° |
| **ë£¨í”„** | ë¶ˆê°€ëŠ¥ | ê°€ëŠ¥ (ìê¸° ìˆ˜ì • Agent) |
| **ì œì–´ê¶Œ** | í”„ë ˆì„ì›Œí¬ ì£¼ë„ | ê°œë°œìê°€ ê·¸ë˜í”„ë¡œ ëª…ì‹œ |
| **ë¹„ìœ ** | ğŸ­ ì¡°ë¦½ ë¼ì¸ | ğŸ—ºï¸ ì˜ì‚¬ê²°ì • í”Œë¡œìš°ì°¨íŠ¸ |
| **ì í•©í•œ ìš©ë„** | ë‹¨ìˆœ íŒŒì´í”„ë¼ì¸, RAG | **AI Agent**, ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° |

> [!TIP]
> **Agentë€?**
> ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ì—¬ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³ , ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³ , í•„ìš”í•˜ë©´ ë‹¤ì‹œ ì‹œë„í•˜ëŠ” "ììœ¨ì ì¸ AI"ì…ë‹ˆë‹¤.
> LangGraphëŠ” ì´ëŸ° Agentë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

---

## 4. LangGraph í•µì‹¬ ê°œë…

LangGraphë¥¼ ì´í•´í•˜ë ¤ë©´ **4ê°€ì§€ í•µì‹¬ ê°œë…**ë§Œ ì•Œë©´ ë©ë‹ˆë‹¤.

```mermaid
graph TD
    subgraph "LangGraphì˜ 4ê°€ì§€ í•µì‹¬ ìš”ì†Œ"
        A[ğŸ“Š Graph<br/>ì „ì²´ ì„¤ê³„ë„]
        B[ğŸ”² Node<br/>ì‘ì—… ë‹¨ìœ„]
        C[â¡ï¸ Edge<br/>ì—°ê²° í†µë¡œ]
        D[ğŸ“¦ State<br/>ê³µìœ  ë©”ëª¨ë¦¬]
    end
    
    A --> B
    A --> C
    A --> D
    B -.-> D
    C -.-> B
```

### 1. ê·¸ë˜í”„(Graph) - ì „ì²´ ì„¤ê³„ë„

**ê·¸ë˜í”„**ëŠ” ì „ì²´ ì›Œí¬í”Œë¡œìš°ì˜ "ì§€ë„"ì…ë‹ˆë‹¤.

```python
from langgraph.graph import StateGraph

# ê·¸ë˜í”„ ìƒì„± (ìƒíƒœ ìŠ¤í‚¤ë§ˆ ì „ë‹¬)
graph = StateGraph(MyState)
```

**ë¹„ìœ **: ê·¸ë˜í”„ëŠ” **ê±´ë¬¼ ì„¤ê³„ë„**ì™€ ê°™ìŠµë‹ˆë‹¤.

### 2. ë…¸ë“œ(Node) - ì‘ì—… ë‹¨ìœ„

**ë…¸ë“œ**ëŠ” ì‹¤ì œë¡œ ë¬´ì–¸ê°€ë¥¼ ìˆ˜í–‰í•˜ëŠ” "ì‘ì—… ë‹¨ìœ„"ì…ë‹ˆë‹¤.

```python
def my_task(state):
    """
    ë…¸ë“œ í•¨ìˆ˜ì˜ ê·œì¹™:
    - ì…ë ¥: í˜„ì¬ ìƒíƒœ(state)
    - ì¶œë ¥: ì—…ë°ì´íŠ¸í•  ìƒíƒœë§Œ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
    """
    current_value = state["count"]
    new_value = current_value + 1
    return {"count": new_value}

# ê·¸ë˜í”„ì— ë…¸ë“œ ì¶”ê°€
graph.add_node("my_task", my_task)
```

**ë¹„ìœ **: ë…¸ë“œëŠ” **ê³µì¥ì˜ ì‘ì—…ì**ì…ë‹ˆë‹¤.

### 3. ì—£ì§€(Edge) - ì—°ê²° í†µë¡œ

**ì—£ì§€**ëŠ” ë…¸ë“œì™€ ë…¸ë“œë¥¼ ì—°ê²°í•˜ëŠ” "í†µë¡œ"ì…ë‹ˆë‹¤.

#### ì¼ë°˜ ì—£ì§€ (ë¬´ì¡°ê±´ ì´ë™)
```python
from langgraph.graph import START, END

graph.add_edge(START, "node_a")      # ì‹œì‘ â†’ node_a
graph.add_edge("node_a", "node_b")   # node_a â†’ node_b
graph.add_edge("node_b", END)        # node_b â†’ ì¢…ë£Œ
```

#### ì¡°ê±´ë¶€ ì—£ì§€ (ì¡°ê±´ì— ë”°ë¼ ë¶„ê¸°)
```python
from typing import Literal

def router(state) -> Literal["path_a", "path_b", END]:
    if state["score"] >= 80:
        return "path_a"
    elif state["score"] >= 50:
        return "path_b"
    return END

graph.add_conditional_edges("check", router)
```

**ë¹„ìœ **:
- ì¼ë°˜ ì—£ì§€ = **ì¼ë°©í†µí–‰ ë„ë¡œ**
- ì¡°ê±´ë¶€ ì—£ì§€ = **êµì°¨ë¡œ**

### 4. ìƒíƒœ(State) - ê³µìœ  ë©”ëª¨ë¦¬

**ìƒíƒœ**ëŠ” ê·¸ë˜í”„ì˜ ëª¨ë“  ë…¸ë“œê°€ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” "ê³µìœ  ë©”ëª¨ë¦¬"ì…ë‹ˆë‹¤.

```python
from typing import TypedDict

class MyState(TypedDict):
    question: str      # ì‚¬ìš©ì ì§ˆë¬¸
    answer: str        # AI ë‹µë³€
    count: int         # ì‹œë„ íšŸìˆ˜
    documents: list    # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤
```

**ë¹„ìœ **: ìƒíƒœëŠ” **íšŒì‚¬ì˜ ê³µìœ  ë¬¸ì„œí•¨**ì…ë‹ˆë‹¤.

> [!NOTE]
> **MessagesState - ì±—ë´‡ìš© íŠ¹ìˆ˜ ìƒíƒœ**
> LangGraphëŠ” ì±—ë´‡ ê°œë°œì— í¸ë¦¬í•œ `MessagesState`ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
> ```python
> from langgraph.graph import MessagesState
> 
> # MessagesStateë¥¼ ì‚¬ìš©í•˜ë©´ messages í•„ë“œê°€ ìë™ ì •ì˜ë¨
> graph = StateGraph(MessagesState)
> ```

---

## 5. LangGraph ë‹¨ê³„ë³„ í•™ìŠµ ì˜ˆì œ

ì´ì œ ì‹¤ì œ ì½”ë“œë¥¼ í†µí•´ LangGraphë¥¼ ìµí˜€ë´…ì‹œë‹¤.

### Step 1: ê°€ì¥ ë‹¨ìˆœí•œ ê·¸ë˜í”„

**ëª©í‘œ**: ë…¸ë“œ 1ê°œë§Œ ìˆëŠ” ê°€ì¥ ë‹¨ìˆœí•œ ê·¸ë˜í”„ ë§Œë“¤ê¸°

```python
from typing import TypedDict
from langgraph.graph import StateGraph, START, END

class SimpleState(TypedDict):
    message: str

def greet(state: SimpleState) -> dict:
    """ì¸ì‚¬ ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ëŠ” ë…¸ë“œ"""
    greeting = f"ì•ˆë…•í•˜ì„¸ìš”! ë‹¹ì‹ ì˜ ë©”ì‹œì§€: '{state['message']}'"
    return {"message": greeting}

# ê·¸ë˜í”„ êµ¬ì„±
graph = StateGraph(SimpleState)
graph.add_node("greet", greet)
graph.add_edge(START, "greet")
graph.add_edge("greet", END)

app = graph.compile()
result = app.invoke({"message": "LangGraph ë°°ìš°ëŠ” ì¤‘!"})
```

### Step 2: ì¡°ê±´ë¶€ ë¶„ê¸° êµ¬í˜„

**ëª©í‘œ**: ìƒíƒœ ê°’ì— ë”°ë¼ ë‹¤ë¥¸ ê²½ë¡œë¡œ ë¶„ê¸°í•˜ê¸°

```python
from typing import Literal
from langgraph.graph import StateGraph, START, END

class GradeState(TypedDict):
    score: int
    grade: str

def grade_router(state: GradeState) -> Literal["excellent", "good", "needs_work"]:
    """ì ìˆ˜ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œ ê²°ì •"""
    if state["score"] >= 90:
        return "excellent"
    elif state["score"] >= 70:
        return "good"
    return "needs_work"

# ê·¸ë˜í”„ êµ¬ì„±
graph = StateGraph(GradeState)
graph.add_node("check_score", lambda s: {})
graph.add_node("excellent", lambda s: {"grade": "A"})
graph.add_node("good", lambda s: {"grade": "B"})
graph.add_node("needs_work", lambda s: {"grade": "C"})

graph.add_edge(START, "check_score")
graph.add_conditional_edges("check_score", grade_router)
graph.add_edge("excellent", END)
graph.add_edge("good", END)
graph.add_edge("needs_work", END)

app = graph.compile()
```

### Step 3: ì™„ì „í•œ Agent (ë„êµ¬ í˜¸ì¶œ + ë£¨í”„)

**ëª©í‘œ**: LLM + ë„êµ¬ + ë£¨í”„ë¥¼ í™œìš©í•œ Agent êµ¬í˜„

```python
from typing import Literal
from langchain_core.messages import HumanMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.prebuilt import ToolNode
from utils.llm_factory import get_llm

llm = get_llm()

# ë„êµ¬ ì •ì˜
@tool
def get_weather(city: str) -> str:
    """ë„ì‹œì˜ ë‚ ì”¨ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return f"{city}: ë§‘ìŒ, 15Â°C"

tools = [get_weather]
llm_with_tools = llm.bind_tools(tools)

# ë…¸ë“œ í•¨ìˆ˜
def agent_node(state: MessagesState) -> dict:
    response = llm_with_tools.invoke(state["messages"])
    return {"messages": [response]}

def should_continue(state: MessagesState) -> Literal["tools", END]:
    last_message = state["messages"][-1]
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"
    return END

# ê·¸ë˜í”„ êµ¬ì„±
graph = StateGraph(MessagesState)
graph.add_node("agent", agent_node)
graph.add_node("tools", ToolNode(tools))

graph.add_edge(START, "agent")
graph.add_conditional_edges("agent", should_continue)
graph.add_edge("tools", "agent")  # ë£¨í”„!

app = graph.compile()

# ì‹¤í–‰
result = app.invoke({"messages": [HumanMessage(content="ì„œìš¸ ë‚ ì”¨ëŠ”?")]})
```

---

## 6. LangGraph API ìƒì„¸ ë ˆí¼ëŸ°ìŠ¤

### Graph êµ¬ì„±

#### StateGraph

```python
from langgraph.graph import StateGraph

class MyState(TypedDict):
    data: str

graph = StateGraph(MyState)
```

**ì£¼ìš” ë©”ì„œë“œ:**
- `add_node()` - ë…¸ë“œ ì¶”ê°€
- `add_edge()` - ì—£ì§€ ì¶”ê°€  
- `add_conditional_edges()` - ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€
- `compile()` - ì»´íŒŒì¼

#### MessagesState

```python
from langgraph.graph import MessagesState

# messages í•„ë“œê°€ ìë™ ì •ì˜ë¨
graph = StateGraph(MessagesState)
```

### Node ê´€ë¦¬

#### add_node()

```python
def my_node(state: MyState) -> dict:
    return {"data": "updated"}

graph.add_node("node_name", my_node)
```

#### ToolNode

```python
from langgraph.prebuilt import ToolNode

tools = [search, calculate]
tool_node = ToolNode(tools)
graph.add_node("tools", tool_node)
```

### Edge ê´€ë¦¬

#### add_edge()

```python
from langgraph.graph import START, END

graph.add_edge(START, "node_a")
graph.add_edge("node_a", END)
```

#### add_conditional_edges()

```python
def router(state) -> Literal["path_a", END]:
    if state["condition"]:
        return "path_a"
    return END

graph.add_conditional_edges("node", router)
```

### ì‹¤í–‰

#### compile()

```python
compiled = graph.compile()

# ë©”ëª¨ë¦¬ ì‚¬ìš©
from langgraph.checkpoint.memory import MemorySaver
memory = MemorySaver()
compiled = graph.compile(checkpointer=memory)
```

#### invoke()

```python
result = compiled.invoke({"question": "ì•ˆë…•?"})

# thread_id ì‚¬ìš©
config = {"configurable": {"thread_id": "session-1"}}
result = compiled.invoke({"question": "ì•ˆë…•?"}, config)
```

#### stream()

```python
for event in compiled.stream({"question": "ì•ˆë…•?"}):
    print(event)
```

---

## 7. ê·¸ë˜í”„ íŒ¨í„´ ëª¨ìŒ

### 1. ë‹¨ìˆœ ìˆœì°¨ ì‹¤í–‰

```python
graph.add_edge(START, "step1")
graph.add_edge("step1", "step2")
graph.add_edge("step2", END)
```

### 2. ì¡°ê±´ë¶€ ë¶„ê¸°

```python
graph.add_edge(START, "check")
graph.add_conditional_edges("check", router)
graph.add_edge("path_a", END)
graph.add_edge("path_b", END)
```

### 3. ë£¨í”„ (ìê¸° ìˆ˜ì •)

```python
graph.add_edge(START, "process")
graph.add_conditional_edges("process", should_retry)
graph.add_edge("retry", "process")  # ë£¨í”„!
```

### 4. ë³‘ë ¬ ì‹¤í–‰

```python
graph.add_edge(START, "branch_a")
graph.add_edge(START, "branch_b")
graph.add_edge(["branch_a", "branch_b"], "merge")
graph.add_edge("merge", END)
```

### 5. Agent ë£¨í”„ (ë„êµ¬ í˜¸ì¶œ)

```python
graph.add_edge(START, "agent")
graph.add_conditional_edges("agent", should_continue)
graph.add_edge("tools", "agent")  # ë£¨í”„!
```

---

## 8. í•™ìŠµ ë¡œë“œë§µ

### ì¶”ì²œ í•™ìŠµ ìˆœì„œ

```mermaid
graph TD
    A[1ë‹¨ê³„: LangChain ê¸°ì´ˆ] --> B[2ë‹¨ê³„: LCEL ì²´ì¸]
    B --> C[3ë‹¨ê³„: LangGraph ê¸°ë³¸]
    C --> D[4ë‹¨ê³„: LangGraph ê³ ê¸‰]
    
    A1[Chat Models<br/>Prompts<br/>Tools] --> A
    B1[íŒŒì´í”„ ì—°ì‚°ì<br/>Runnable] --> B
    C1[Graph<br/>Node<br/>State] --> C
    D1[ì¡°ê±´ë¶€ ë¶„ê¸°<br/>ë£¨í”„<br/>Agent] --> D
```

### 1ë‹¨ê³„: LangChain ê¸°ì´ˆ

**í•™ìŠµ ë‚´ìš©:**
- Chat Models, Prompt Templates, Tools

**ì‹¤ìŠµ ì˜ˆì œ:**
- `examples/01_base_agent_standard.py`
- `examples/01_base_agent_react.py`

### 2ë‹¨ê³„: LCEL ì²´ì¸

**í•™ìŠµ ë‚´ìš©:**
- Runnable ì¸í„°í˜ì´ìŠ¤
- íŒŒì´í”„ ì—°ì‚°ì(`|`) í™œìš©

**ì‹¤ìŠµ:**
- ë³¸ ë¬¸ì„œì˜ LCEL ì˜ˆì œë“¤

### 3ë‹¨ê³„: LangGraph ê¸°ë³¸

**í•™ìŠµ ë‚´ìš©:**
- Graph, Node, Edge, State
- ë‹¨ìˆœ ê·¸ë˜í”„ êµ¬ì„±

**ì‹¤ìŠµ:**
- Step 1~2 ì˜ˆì œ

### 4ë‹¨ê³„: LangGraph ê³ ê¸‰

**í•™ìŠµ ë‚´ìš©:**
- ì¡°ê±´ë¶€ ë¶„ê¸°, ë£¨í”„, Agent

**ì‹¤ìŠµ ì˜ˆì œ:**
- Step 3 ì˜ˆì œ
- `examples/02_naive_rag.py`
- `examples/04_advanced_rag.py`

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [LangChain ê³µì‹ ë¬¸ì„œ](https://python.langchain.com/)
- [LangGraph ê³µì‹ ë¬¸ì„œ](https://langchain-ai.github.io/langgraph/)
- [LangGraph GitHub](https://github.com/langchain-ai/langgraph)
- [LCEL ê°€ì´ë“œ](https://python.langchain.com/docs/expression_language/)

---

> [!TIP]
> **ë‹¤ìŒ ë‹¨ê³„**
> 
> ì´ ë¬¸ì„œë¥¼ ì½ì—ˆë‹¤ë©´ ì‹¤ì œ ì˜ˆì œ ì½”ë“œë¥¼ ì‹¤í–‰í•´ë³´ì„¸ìš”!
> 
> 1. `examples/01_base_agent_standard.py` - LangChain ê¸°ë³¸
> 2. `examples/02_naive_rag.py` - LangGraph RAG
> 3. `examples/04_advanced_rag.py` - ê³ ê¸‰ Agent íŒ¨í„´

