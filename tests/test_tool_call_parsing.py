# -*- coding: utf-8 -*-
"""
GPT-OSS Tool Call íŒŒì‹± í…ŒìŠ¤íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” GPT-OSS-20Bì˜ tool call ì‘ë‹µ í˜•ì‹ì„ í™•ì¸í•˜ê³ ,
LangChainì´ ì´ë¥¼ ì–´ë–»ê²Œ íŒŒì‹±í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import sys
from pathlib import Path
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.tools import tool
from config.settings import get_settings


@tool
def get_weather(city: str) -> str:
    """íŠ¹ì • ë„ì‹œì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return f"{city}ì€(ëŠ”) ë§‘ìŒ, 15Â°C"


@tool
def calculate(expression: str) -> str:
    """ìˆ˜í•™ í‘œí˜„ì‹ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    return f"ê²°ê³¼: {eval(expression)}"


def test_raw_response():
    """LLMì˜ raw ì‘ë‹µ í˜•ì‹ì„ í™•ì¸í•©ë‹ˆë‹¤."""
    settings = get_settings()
    
    llm = ChatOpenAI(
        api_key=settings.openai_api_key or "dummy-key",
        model=settings.openai_model,
        base_url=settings.openai_api_base,
    )
    
    tools = [get_weather, calculate]
    llm_with_tools = llm.bind_tools(tools)
    
    messages = [
        SystemMessage(content="ë‹¹ì‹ ì€ ë‚ ì”¨ ì¡°íšŒì™€ ê³„ì‚°ì„ ë•ëŠ” ìœ ìš©í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."),
        HumanMessage(content="ì„œìš¸ ë‚ ì”¨ ì–´ë•Œ?"),
    ]
    
    print("=" * 60)
    print("1. LLM ì‘ë‹µ ë¶„ì„ (tool binding í¬í•¨)")
    print("=" * 60)
    
    response = llm_with_tools.invoke(messages)
    
    print(f"\nğŸ“Œ ì‘ë‹µ íƒ€ì…: {type(response).__name__}")
    print(f"\nğŸ“Œ response.content:")
    print(f"   Type: {type(response.content)}")
    print(f"   Value: {repr(response.content)}")
    
    print(f"\nğŸ“Œ response.tool_calls:")
    if hasattr(response, 'tool_calls'):
        print(f"   Type: {type(response.tool_calls)}")
        print(f"   Value: {response.tool_calls}")
        print(f"   Length: {len(response.tool_calls) if response.tool_calls else 0}")
    else:
        print("   âŒ tool_calls ì†ì„± ì—†ìŒ")
    
    print(f"\nğŸ“Œ response.additional_kwargs:")
    if hasattr(response, 'additional_kwargs'):
        print(f"   {json.dumps(response.additional_kwargs, indent=4, ensure_ascii=False)}")
    
    # contentê°€ JSON ë¬¸ìì—´ì¸ì§€ í™•ì¸
    if response.content and isinstance(response.content, str):
        try:
            parsed = json.loads(response.content)
            print(f"\nğŸ“Œ contentë¥¼ JSONìœ¼ë¡œ íŒŒì‹± ê°€ëŠ¥:")
            print(f"   {json.dumps(parsed, indent=4, ensure_ascii=False)}")
        except json.JSONDecodeError:
            print(f"\nğŸ“Œ contentëŠ” JSONì´ ì•„ë‹˜")
    
    return response


def test_without_tools():
    """ë„êµ¬ ì—†ì´ ì¼ë°˜ ì‘ë‹µì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    settings = get_settings()
    
    llm = ChatOpenAI(
        api_key=settings.openai_api_key or "dummy-key",
        model=settings.openai_model,
        base_url=settings.openai_api_base,
    )
    
    messages = [
        SystemMessage(content="ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."),
        HumanMessage(content="ì•ˆë…•í•˜ì„¸ìš”"),
    ]
    
    print("\n" + "=" * 60)
    print("2. ì¼ë°˜ ëŒ€í™” (ë„êµ¬ ë°”ì¸ë”© ì—†ìŒ)")
    print("=" * 60)
    
    response = llm.invoke(messages)
    
    print(f"\nğŸ“Œ ì‘ë‹µ íƒ€ì…: {type(response).__name__}")
    print(f"ğŸ“Œ content: {response.content}")
    
    return response


if __name__ == "__main__":
    print("\nğŸ”¬ GPT-OSS Tool Call íŒŒì‹± í…ŒìŠ¤íŠ¸\n")
    
    response1 = test_raw_response()
    response2 = test_without_tools()
    
    print("\n" + "=" * 60)
    print("3. ê²°ë¡ ")
    print("=" * 60)
    
    if response1.tool_calls:
        print("\nâœ… tool_callsê°€ ì •ìƒì ìœ¼ë¡œ íŒŒì‹±ë¨ - ë¬¸ì œì—†ìŒ")
    else:
        print("\nâŒ tool_callsê°€ ë¹„ì–´ìˆìŒ - Harmony í¬ë§· íŒŒì‹± í•„ìš”")
        if response1.content:
            print(f"   contentì— ìˆëŠ” ê°’: {response1.content}")
