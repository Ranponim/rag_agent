# -*- coding: utf-8 -*-
"""
============================================================================
ğŸ“š 05. Integrated RAG - Entity + Advanced + Adaptive í†µí•© ì‹œìŠ¤í…œ
============================================================================

03_entity_rag, 04_advanced_rag, 04a_adaptive_ragì˜ ê¸°ë²•ì„ í•˜ë‚˜ë¡œ í†µí•©í•œ 
ìµœì¢… ì™„ì„±í˜• RAG Agentì…ë‹ˆë‹¤.

ğŸ¯ í†µí•©ëœ í•µì‹¬ ê¸°ìˆ :
    1. Adaptive Router: ì§ˆë¬¸ ë‚œì´ë„(simple/moderate/complex) ìë™ íŒë³„
    2. Entity RAG: ì—”í‹°í‹° ì¶”ì¶œ ë° ë³‘ë ¬ ê²€ìƒ‰ (Fan-out/Fan-in)
    3. Advanced RAG: ë¬¸ì„œ í‰ê°€(Grading) ë° ì¿¼ë¦¬ ì¬ì‘ì„± ë£¨í”„
    4. ê³µí†µ ë°ì´í„° ë¡œë”: Vector Store ì˜ì†í™” ë° íŒŒì¼ ë³€ê²½ ê°ì§€

ê·¸ë˜í”„ êµ¬ì¡°:
                                 â”Œâ†’ direct_answer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ END (simple)
                                 â”‚
    START â†’ classify â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â†’ entity_search â”€â”¬â†’ semantic_search â”€â”
                                 â”‚                  â”‚                   â”‚
                                 â”‚                  â””â†’ merge â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚                           â”‚
                                 â”‚                           â†“
                                 â””â†’ complex_rag â”€â”¬â†’ grade_docs â”€â”¬â†’ generate â†’ END
                                                 â”‚              â”‚
                                                 â”‚              â””â†’ rewrite â†’ retrieve â”€â”˜
                                                 â”‚
                                                 â””â†’ multi_step_rag â†’ END

ì‹¤í–‰ ë°©ë²•:
    python examples/05_integrated_test.py
"""

import sys
import os
from pathlib import Path
from typing import TypedDict, List, Literal

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# LangChain êµ¬ì„± ìš”ì†Œ
from langchain_openai import ChatOpenAI
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

# LangGraph êµ¬ì„± ìš”ì†Œ
from langgraph.graph import StateGraph, START, END

# í”„ë¡œì íŠ¸ ìœ í‹¸ë¦¬í‹°
from utils.llm_factory import log_llm_error
from utils.vector_store import VectorStoreManager
from utils.data_loader import get_rag_vector_store


# =============================================================================
# ğŸ“‹ 1. í†µí•© ìƒíƒœ(State) ì •ì˜
# =============================================================================

class IntegratedRAGState(TypedDict):
    """
    í†µí•© RAG ì‹œìŠ¤í…œì˜ ìƒíƒœ
    
    ëª¨ë“  RAG ê¸°ë²•ì—ì„œ í•„ìš”í•œ í•„ë“œë“¤ì„ í†µí•©í•©ë‹ˆë‹¤.
    """
    # ê¸°ë³¸ í•„ë“œ
    question: str                    # ì‚¬ìš©ì ì§ˆë¬¸
    answer: str                      # ìµœì¢… ë‹µë³€
    
    # Adaptive RAG (04a) í•„ë“œ
    query_complexity: str            # ì§ˆë¬¸ ë‚œì´ë„ (simple/moderate/complex)
    strategy_used: str               # ì‚¬ìš©ëœ ì „ëµ ì´ë¦„
    
    # Entity RAG (03) í•„ë“œ
    entities: List[str]              # ì¶”ì¶œëœ ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸
    entity_docs: List[Document]      # ì—”í‹°í‹° ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼
    semantic_docs: List[Document]    # ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ê²°ê³¼
    
    # Advanced RAG (04) í•„ë“œ
    documents: List[Document]        # ë³‘í•©/ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
    grade: str                       # ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ (relevant/irrelevant)
    loop_count: int                  # ì¿¼ë¦¬ ì¬ì‘ì„± ë£¨í”„ ì¹´ìš´í„°
    
    # ë””ë²„ê¹…ìš©
    steps_taken: List[str]           # ê±°ì³ì˜¨ ë…¸ë“œ ê¸°ë¡


# =============================================================================
# ğŸ—„ï¸ 2. Vector Store ì´ˆê¸°í™” (ê³µí†µ ëª¨ë“ˆ ì‚¬ìš©)
# =============================================================================

def get_vector_store() -> VectorStoreManager:
    """
    í†µí•© RAGìš© Vector Store ì´ˆê¸°í™”
    
    ëª¨ë“  ê¸°ëŠ¥ì´ ê°™ì€ collectionì„ ê³µìœ í•˜ì—¬ ì„ë² ë”©ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    return get_rag_vector_store(collection_name="integrated_rag")


# =============================================================================
# ğŸ§  3. Adaptive RAG ë…¸ë“œ: ì§ˆë¬¸ ë¶„ë¥˜ (04a ê¸°ë²•)
# =============================================================================

def classify_query(state: IntegratedRAGState) -> dict:
    """
    [Adaptive] ì§ˆë¬¸ ë‚œì´ë„ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    
    - simple: ê²€ìƒ‰ ì—†ì´ ë°”ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ê°„ë‹¨í•œ ì§ˆë¬¸
    - moderate: ì¼ë°˜ì ì¸ RAG ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸
    - complex: ì—”í‹°í‹° ì¶”ì¶œ + ë‹¤ë‹¨ê³„ ë¶„ì„ì´ í•„ìš”í•œ ë³µì¡í•œ ì§ˆë¬¸
    """
    print(f"\nğŸ§ [ë¶„ë¥˜] ì§ˆë¬¸ ë‚œì´ë„ ë¶„ì„ ì¤‘...")
    
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ 3ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”. ë‹¨ì–´ í•˜ë‚˜ë§Œ ë‹µí•˜ì„¸ìš”.
1. "simple": ì¸ì‚¬, ì‹œê°„ ë¬»ê¸°, ìƒì‹ì ì¸ ì§ˆë¬¸
2. "moderate": í•œ ë²ˆì˜ ê²€ìƒ‰ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ì¼ë°˜ ì§ˆë¬¸  
3. "complex": ì—¬ëŸ¬ ê°œë… ë¹„êµ, ì‹¬ì¸µ ë¶„ì„ì´ í•„ìš”í•œ ë³µì¡í•œ ì§ˆë¬¸"""),
        ("human", "{question}"),
    ])
    
    response = (prompt | model).invoke({"question": state["question"]})
    complexity = response.content.lower().strip()
    
    # ìœ íš¨í•˜ì§€ ì•Šì€ ì‘ë‹µì€ moderateë¡œ ê¸°ë³¸ ì„¤ì •
    if complexity not in ["simple", "moderate", "complex"]:
        complexity = "moderate"
    
    print(f"   â†’ íŒë‹¨ ê²°ê³¼: '{complexity}' ìˆ˜ì¤€")
    
    return {
        "query_complexity": complexity,
        "steps_taken": ["classify"]
    }


# =============================================================================
# âš¡ 4. Simple ì „ëµ: ì§ì ‘ ë‹µë³€ (04a ê¸°ë²•)
# =============================================================================

def direct_answer(state: IntegratedRAGState) -> dict:
    """
    [Simple] ê²€ìƒ‰ ì—†ì´ LLMì˜ ì§€ì‹ìœ¼ë¡œ ì§ì ‘ ë‹µë³€í•©ë‹ˆë‹¤.
    """
    print("âš¡ [Simple] ê²€ìƒ‰ ì—†ì´ ë°”ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.")
    
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    
    response = model.invoke(state["question"])
    
    return {
        "answer": response.content,
        "strategy_used": "Simple (ì§ì ‘ ë‹µë³€)",
        "steps_taken": state["steps_taken"] + ["direct_answer"]
    }


# =============================================================================
# ğŸ·ï¸ 5. Entity RAG ë…¸ë“œë“¤ (03 ê¸°ë²•)
# =============================================================================

def extract_entities(state: IntegratedRAGState) -> dict:
    """
    [Entity RAG] LLMì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì—ì„œ í•µì‹¬ ì—”í‹°í‹°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    print("ğŸ·ï¸ [Entity] ì—”í‹°í‹° ì¶”ì¶œ ì¤‘...")
    
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ(ì—”í‹°í‹°)ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
ì˜ˆì‹œ: {{"entities": ["LangGraph", "RAG"]}}
ì§ˆë¬¸: {question}"""),
    ])
    
    try:
        chain = prompt | model | JsonOutputParser()
        result = chain.invoke({"question": state["question"]})
        entities = result.get("entities", [])
        print(f"   â†’ ì¶”ì¶œëœ ì—”í‹°í‹°: {entities}")
        return {"entities": entities}
    except Exception as e:
        print(f"   â†’ ì¶”ì¶œ ì‹¤íŒ¨, ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜: {e}")
        return {"entities": []}


def search_by_entity(state: IntegratedRAGState) -> dict:
    """
    [Entity RAG] ì—”í‹°í‹° ê¸°ë°˜ ê²€ìƒ‰ (ë³‘ë ¬ ì‹¤í–‰ 1)
    """
    print("ğŸ” [Entity] ì—”í‹°í‹° ê¸°ë°˜ ê²€ìƒ‰ ìˆ˜í–‰...")
    
    vs = get_vector_store()
    results = []
    
    for entity in state.get("entities", []):
        docs = vs.search(entity, k=1)
        results.extend(docs)
        print(f"   â†’ '{entity}' ê²€ìƒ‰: {len(docs)}ê°œ ë¬¸ì„œ")
    
    return {"entity_docs": results}


def search_semantic(state: IntegratedRAGState) -> dict:
    """
    [Entity RAG] ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ (ë³‘ë ¬ ì‹¤í–‰ 2)
    """
    print("ğŸ” [Semantic] ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ìˆ˜í–‰...")
    
    vs = get_vector_store()
    docs = vs.search(state["question"], k=2)
    print(f"   â†’ {len(docs)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")
    
    return {"semantic_docs": docs}


def merge_results(state: IntegratedRAGState) -> dict:
    """
    [Entity RAG] ì—”í‹°í‹° + ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© (Fan-in)
    """
    print("ğŸ”„ [Merge] ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ì¤‘...")
    
    seen = set()
    merged = []
    
    all_docs = state.get("entity_docs", []) + state.get("semantic_docs", [])
    
    for doc in all_docs:
        if doc.page_content not in seen:
            merged.append(doc)
            seen.add(doc.page_content)
    
    print(f"   â†’ ì´ {len(merged)}ê°œ ë¬¸ì„œ ë³‘í•©ë¨")
    
    return {
        "documents": merged,
        "steps_taken": state["steps_taken"] + ["entity_search", "semantic_search", "merge"]
    }


# =============================================================================
# ğŸ“Š 6. Advanced RAG ë…¸ë“œë“¤ (04 ê¸°ë²•)
# =============================================================================

def grade_documents(state: IntegratedRAGState) -> dict:
    """
    [Advanced] ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ê´€ë ¨ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤ (Grading)
    """
    print("ğŸ“Š [Grade] ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ ì¤‘...")
    
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    
    prompt = ChatPromptTemplate.from_template(
        """ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆìœ¼ë©´ 'yes', ì—†ìœ¼ë©´ 'no'ë¼ê³ ë§Œ í•˜ì„¸ìš”.
ì§ˆë¬¸: {question}
ë¬¸ì„œ: {document}"""
    )
    
    chain = prompt | model
    
    is_relevant = False
    for i, doc in enumerate(state.get("documents", [])):
        res = chain.invoke({
            "question": state["question"],
            "document": doc.page_content
        })
        
        if "yes" in res.content.lower():
            print(f"   â†’ ë¬¸ì„œ {i+1}: ê´€ë ¨ ìˆìŒ âœ“")
            is_relevant = True
            break
        else:
            print(f"   â†’ ë¬¸ì„œ {i+1}: ê´€ë ¨ ì—†ìŒ âœ—")
    
    grade = "relevant" if is_relevant else "irrelevant"
    print(f"   ğŸ“‹ ìµœì¢… í‰ê°€: {grade}")
    
    return {
        "grade": grade,
        "steps_taken": state["steps_taken"] + ["grade_documents"]
    }


def rewrite_query(state: IntegratedRAGState) -> dict:
    """
    [Advanced] ê´€ë ¨ ë¬¸ì„œê°€ ì—†ì„ ë•Œ ì§ˆë¬¸ì„ ì¬ì‘ì„±í•©ë‹ˆë‹¤ (Fallback)
    """
    print("ğŸ”„ [Rewrite] ì§ˆë¬¸ ì¬ì‘ì„± ì¤‘...")
    
    current_count = state.get("loop_count", 0)
    
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    
    # LLMì„ ì‚¬ìš©í•˜ì—¬ ë” ë‚˜ì€ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    response = model.invoke(
        f"ë‹¤ìŒ ì§ˆë¬¸ì„ ê²€ìƒ‰ì— ë” ì í•©í•˜ê²Œ ë‹¤ì‹œ ì‘ì„±í•´ì£¼ì„¸ìš”. ì§ˆë¬¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\nì›ë³¸: {state['question']}"
    )
    new_query = response.content.strip()
    
    print(f"   â†’ ê¸°ì¡´: {state['question']}")
    print(f"   â†’ ë³€ê²½: {new_query}")
    print(f"   â†’ ì¬ì‹œë„ íšŸìˆ˜: {current_count + 1}")
    
    return {
        "question": new_query,
        "loop_count": current_count + 1,
        "steps_taken": state["steps_taken"] + ["rewrite_query"]
    }


def retrieve_for_rewrite(state: IntegratedRAGState) -> dict:
    """
    [Advanced] ì¬ì‘ì„±ëœ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•©ë‹ˆë‹¤
    """
    print(f"ğŸ” [Retrieve] ì¬ê²€ìƒ‰ ìˆ˜í–‰: {state['question']}")
    
    vs = get_vector_store()
    docs = vs.search(state["question"], k=3)
    
    print(f"   â†’ {len(docs)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")
    
    return {"documents": docs}


# =============================================================================
# ğŸ“ 7. ë‹µë³€ ìƒì„± ë…¸ë“œ
# =============================================================================

def generate_answer(state: IntegratedRAGState) -> dict:
    """
    ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print("ğŸ“ [Generate] ë‹µë³€ ìƒì„± ì¤‘...")
    
    context = "\n".join(d.page_content for d in state.get("documents", []))
    
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    
    response = model.invoke(f"ì°¸ê³  ë¬¸ì„œ:\n{context}\n\nì§ˆë¬¸: {state['question']}\n\në‹µë³€:")
    
    return {
        "answer": response.content,
        "strategy_used": "Advanced RAG (Entity + Grading)",
        "steps_taken": state["steps_taken"] + ["generate"]
    }


def generate_fallback_answer(state: IntegratedRAGState) -> dict:
    """
    ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆì„ ë•Œ LLM ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
    """
    print("ğŸ“ [Fallback] ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ, ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€...")
    
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    
    response = model.invoke(state["question"])
    
    return {
        "answer": response.content,
        "strategy_used": "Fallback (ì¼ë°˜ LLM)",
        "steps_taken": state["steps_taken"] + ["fallback_generate"]
    }


# =============================================================================
# ğŸ”¬ 8. Complex ì „ëµ: ë‹¤ë‹¨ê³„ ë¶„ì„ (04a ê¸°ë²•)
# =============================================================================

def complex_multi_step_rag(state: IntegratedRAGState) -> dict:
    """
    [Complex] ì§ˆë¬¸ì„ ë¶„í•´í•˜ì—¬ ë‹¤ë‹¨ê³„ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
    """
    print("ğŸ”¬ [Complex] ë‹¤ë‹¨ê³„ ì •ë°€ ë¶„ì„ ìˆ˜í–‰...")
    
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    
    # 1. ì§ˆë¬¸ ë¶„í•´
    decompose_res = model.invoke(
        f"ì´ ì§ˆë¬¸ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ë¨¼ì € ì•Œì•„ì•¼ í•  ì„¸ë¶€ ì§ˆë¬¸ 2ê°œë¥¼ ì‘ì„±í•˜ì„¸ìš”. í•œ ì¤„ì”© ì“°ì„¸ìš”.\nì§ˆë¬¸: {state['question']}"
    )
    sub_queries = [q.strip() for q in decompose_res.content.split("\n") if q.strip()][:2]
    print(f"   â†’ ì„¸ë¶€ ì§ˆë¬¸: {sub_queries}")
    
    # 2. ê° ì„¸ë¶€ ì§ˆë¬¸ + ì›ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ê²€ìƒ‰
    vs = get_vector_store()
    all_context = []
    
    for sq in sub_queries + [state["question"]]:
        docs = vs.search(sq, k=2)
        all_context.extend([d.page_content for d in docs])
    
    # 3. ì¤‘ë³µ ì œê±° ë° ì‹¬ì¸µ ë‹µë³€ ìƒì„±
    final_context = "\n".join(list(set(all_context)))
    
    response = model.invoke(
        f"ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¬ì¸µ ë¶„ì„ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.\n\nì°¸ê³  ì •ë³´:\n{final_context}\n\nì§ˆë¬¸: {state['question']}"
    )
    
    return {
        "answer": response.content,
        "strategy_used": "Complex (ë‹¤ë‹¨ê³„ ì •ë°€ RAG)",
        "steps_taken": state["steps_taken"] + ["complex_multi_step"]
    }


# =============================================================================
# ğŸš¦ 9. ì¡°ê±´ë¶€ ë¼ìš°íŒ… í•¨ìˆ˜ë“¤
# =============================================================================

def route_by_complexity(state: IntegratedRAGState) -> Literal["simple", "moderate", "complex"]:
    """
    ë¶„ë¥˜ëœ ë‚œì´ë„ì— ë”°ë¼ ê²½ë¡œë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    """
    return state["query_complexity"]


def check_grade_and_loop(state: IntegratedRAGState) -> Literal["generate", "rewrite", "fallback"]:
    """
    ë¬¸ì„œ í‰ê°€ ê²°ê³¼ì™€ ë£¨í”„ íšŸìˆ˜ì— ë”°ë¼ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    """
    # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ ì‹œ fallback
    if state.get("loop_count", 0) > 1:
        print("   âš ï¸ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ â†’ fallback")
        return "fallback"
    
    if state.get("grade") == "relevant":
        print("   âœ… ê´€ë ¨ ë¬¸ì„œ í™•ì¸ë¨ â†’ ë‹µë³€ ìƒì„±")
        return "generate"
    else:
        print("   ğŸ”„ ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ â†’ ì§ˆë¬¸ ì¬ì‘ì„±")
        return "rewrite"


# =============================================================================
# ğŸ”— 10. ê·¸ë˜í”„ ì¡°ë¦½
# =============================================================================

def create_graph():
    """
    ëª¨ë“  RAG ê¸°ë²•ì„ í†µí•©í•œ ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    builder = StateGraph(IntegratedRAGState)
    
    # -------------------------------------------------------------------------
    # ë…¸ë“œ ë“±ë¡
    # -------------------------------------------------------------------------
    
    # Adaptive ë¶„ë¥˜
    builder.add_node("classify", classify_query)
    
    # Simple ì „ëµ
    builder.add_node("direct_answer", direct_answer)
    
    # Moderate ì „ëµ (Entity RAG)
    builder.add_node("extract_entities", extract_entities)
    builder.add_node("entity_search", search_by_entity)
    builder.add_node("semantic_search", search_semantic)
    builder.add_node("merge", merge_results)
    
    # Advanced RAG (Grading + Rewrite)
    builder.add_node("grade_documents", grade_documents)
    builder.add_node("rewrite_query", rewrite_query)
    builder.add_node("retrieve", retrieve_for_rewrite)
    builder.add_node("generate", generate_answer)
    builder.add_node("fallback_generate", generate_fallback_answer)
    
    # Complex ì „ëµ
    builder.add_node("complex_rag", complex_multi_step_rag)
    
    # -------------------------------------------------------------------------
    # ì—£ì§€ ì—°ê²°
    # -------------------------------------------------------------------------
    
    # ì‹œì‘ â†’ ë¶„ë¥˜
    builder.add_edge(START, "classify")
    
    # ë‚œì´ë„ë³„ ë¶„ê¸°
    builder.add_conditional_edges(
        "classify",
        route_by_complexity,
        {
            "simple": "direct_answer",
            "moderate": "extract_entities",
            "complex": "complex_rag"
        }
    )
    
    # Simple ì¢…ë£Œ
    builder.add_edge("direct_answer", END)
    
    # Complex ì¢…ë£Œ
    builder.add_edge("complex_rag", END)
    
    # Moderate: Entity RAG ë³‘ë ¬ ê²€ìƒ‰
    builder.add_edge("extract_entities", "entity_search")
    builder.add_edge("extract_entities", "semantic_search")
    builder.add_edge("entity_search", "merge")
    builder.add_edge("semantic_search", "merge")
    
    # Moderate: Advanced RAG (Grading + Rewrite ë£¨í”„)
    builder.add_edge("merge", "grade_documents")
    
    builder.add_conditional_edges(
        "grade_documents",
        check_grade_and_loop,
        {
            "generate": "generate",
            "rewrite": "rewrite_query",
            "fallback": "fallback_generate"
        }
    )
    
    # Rewrite ë£¨í”„
    builder.add_edge("rewrite_query", "retrieve")
    builder.add_edge("retrieve", "grade_documents")
    
    # ìƒì„± ì¢…ë£Œ
    builder.add_edge("generate", END)
    builder.add_edge("fallback_generate", END)
    
    return builder.compile()


# =============================================================================
# â–¶ï¸ 11. ì‹¤í–‰ í•¨ìˆ˜ ë° CLI
# =============================================================================

def run_integrated_rag(question: str, app):
    """
    í†µí•© RAG íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    print(f"\n{'='*60}")
    print(f"ğŸ™‹ ì§ˆë¬¸: {question}")
    print("="*60)
    
    try:
        result = app.invoke({
            "question": question,
            "query_complexity": "",
            "strategy_used": "",
            "entities": [],
            "entity_docs": [],
            "semantic_docs": [],
            "documents": [],
            "grade": "",
            "loop_count": 0,
            "answer": "",
            "steps_taken": []
        })
        
        print(f"\nğŸ“Š ì‚¬ìš©ëœ ì „ëµ: {result.get('strategy_used', 'Unknown')}")
        print(f"ğŸ’¡ ì‹¤í–‰ ê²½ë¡œ: {' â†’ '.join(result.get('steps_taken', []))}")
        print(f"\nğŸ¤– ë‹µë³€:\n{result.get('answer', 'ë‹µë³€ ìƒì„± ì‹¤íŒ¨')}")
        
    except Exception as e:
        log_llm_error(e)
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸš€ í†µí•© RAG ì‹œìŠ¤í…œ (Entity + Advanced + Adaptive)")
    print("="*60)
    print("- ì§ˆë¬¸ ë‚œì´ë„ì— ë”°ë¼ ìµœì ì˜ RAG ì „ëµì„ ìë™ ì„ íƒí•©ë‹ˆë‹¤.")
    print("- ì¢…ë£Œ: 'quit', 'exit', ë˜ëŠ” 'q'")
    print("="*60)
    
    # ê·¸ë˜í”„ ìƒì„±
    app = create_graph()
    
    while True:
        try:
            user_input = input("\nğŸ™‹ ì§ˆë¬¸: ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() in ("quit", "exit", "q"):
                print("ğŸ‘‹ í†µí•© RAG Agentë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”!")
                break
            
            run_integrated_rag(user_input, app)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
