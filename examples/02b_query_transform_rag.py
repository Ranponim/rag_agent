# -*- coding: utf-8 -*-
"""
02b. Query Transform RAG - ì¿¼ë¦¬ ë³€í™˜ RAG

ì´ ì˜ˆì œëŠ” ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰ íš¨ìœ¨ì„ ë†’ì´ëŠ” RAGë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
HyDE(Hypothetical Document Embeddings)ì™€ Multi-Query ê¸°ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

í•™ìŠµ ëª©í‘œ:
    1. HyDE: ê°€ìƒ ë¬¸ì„œ ìƒì„± í›„ ê²€ìƒ‰
    2. Multi-Query: ì¿¼ë¦¬ë¥¼ ì—¬ëŸ¬ ë³€í˜•ìœ¼ë¡œ í™•ì¥
    3. ì¿¼ë¦¬ ë¶„í•´: ë³µì¡í•œ ì§ˆë¬¸ì„ ë‹¨ìˆœí•œ ì§ˆë¬¸ë“¤ë¡œ ë¶„í•´
    4. ê²°ê³¼ í“¨ì „

ì‹¤í–‰: python examples/02b_query_transform_rag.py
"""

import sys
from pathlib import Path
from typing import TypedDict, List

sys.path.insert(0, str(Path(__file__).parent.parent))

from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, START, END

from config.settings import get_settings
from utils.llm_factory import get_llm, get_embeddings
from utils.vector_store import VectorStoreManager


# =============================================================================
# 1. State ì •ì˜
# =============================================================================

class QueryTransformState(TypedDict):
    """Query Transform RAG ìƒíƒœ"""
    original_question: str               # ì›ë³¸ ì§ˆë¬¸
    hyde_document: str                   # HyDEë¡œ ìƒì„±ëœ ê°€ìƒ ë¬¸ì„œ
    multi_queries: List[str]             # Multi-Query ë³€í˜•ë“¤
    hyde_results: List[Document]         # HyDE ê²€ìƒ‰ ê²°ê³¼
    multi_query_results: List[Document]  # Multi-Query ê²€ìƒ‰ ê²°ê³¼
    merged_documents: List[Document]     # ë³‘í•©ëœ ë¬¸ì„œ
    context: str
    answer: str


# =============================================================================
# 2. Vector Store ì´ˆê¸°í™”
# =============================================================================

_qt_vs: VectorStoreManager = None

def get_qt_vs() -> VectorStoreManager:
    global _qt_vs
    if _qt_vs is None:
        print("ğŸ“š Query Transform Vector Store ì´ˆê¸°í™”...")
        _qt_vs = VectorStoreManager(
            embeddings=get_embeddings(),
            collection_name="query_transform_rag",
            chunk_size=300,
        )
        samples = [
            "LangGraphëŠ” LangChain íŒ€ì´ ê°œë°œí•œ ìƒíƒœ ê¸°ë°˜ ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. StateGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.",
            "RAG(Retrieval-Augmented Generation)ëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ë²•ìœ¼ë¡œ, LLMì—ê²Œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µí•©ë‹ˆë‹¤.",
            "HyDE(Hypothetical Document Embeddings)ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ê°€ìƒì˜ ë‹µë³€ì„ ë¨¼ì € ìƒì„±í•˜ê³ , ê·¸ ë‹µë³€ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.",
            "Multi-QueryëŠ” í•˜ë‚˜ì˜ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê´€ì ì—ì„œ ì¬ì‘ì„±í•˜ì—¬ ê²€ìƒ‰ ë²”ìœ„ë¥¼ ë„“íˆëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.",
            "ì„ë² ë”©ì€ í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ìœ ì‚¬í•œ ì˜ë¯¸ë¥¼ ê°€ì§„ í…ìŠ¤íŠ¸ëŠ” ìœ ì‚¬í•œ ë²¡í„°ë¥¼ ê°–ìŠµë‹ˆë‹¤.",
            "Vector StoreëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¡œ, ì„ë² ë”©ëœ ë¬¸ì„œë¥¼ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
            "Query Decompositionì€ ë³µì¡í•œ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ë‹¨ìˆœí•œ ì§ˆë¬¸ìœ¼ë¡œ ë¶„í•´í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.",
            "Reciprocal Rank Fusionì€ ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©í•  ë•Œ ìˆœìœ„ë¥¼ ê³ ë ¤í•˜ì—¬ ë³‘í•©í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.",
        ]
        _qt_vs.add_texts(texts=samples)
        print(f"âœ… {len(samples)}ê°œ ë¬¸ì„œ ì¶”ê°€")
    return _qt_vs


# =============================================================================
# 3. ë…¸ë“œ í•¨ìˆ˜
# =============================================================================

def generate_hyde_document(state: QueryTransformState) -> dict:
    """
    HyDE: ê°€ìƒ ë¬¸ì„œ ìƒì„±
    
    ì§ˆë¬¸ì— ëŒ€í•œ ê°€ìƒì˜ ë‹µë³€ì„ ë¨¼ì € ìƒì„±í•©ë‹ˆë‹¤.
    ì´ ë‹µë³€ì€ ì‹¤ì œ ë¬¸ì„œì™€ ìœ ì‚¬í•œ ì–´íœ˜ë¥¼ í¬í•¨í•  ê°€ëŠ¥ì„±ì´ ë†’ì•„
    ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ íš¨ìœ¨ì´ ë†’ì•„ì§‘ë‹ˆë‹¤.
    """
    print(f"\nğŸ”® [HyDE] ê°€ìƒ ë¬¸ì„œ ìƒì„± ì¤‘...")
    
    llm = get_llm()
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„¸í•œ ì„¤ëª…ì„ ì œê³µí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ë§ˆì¹˜ êµê³¼ì„œë‚˜ ë¬¸ì„œì— ìˆì„ ë²•í•œ ìƒì„¸í•œ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
ì‹¤ì œë¡œ ì •í™•í•œì§€ ëª¨ë¥´ë”ë¼ë„, ê°€ëŠ¥í•œ ì „ë¬¸ì ì¸ ì–´íœ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."""),
        ("human", "{question}"),
    ])
    
    response = (prompt | llm).invoke({"question": state["original_question"]})
    hyde_doc = response.content
    
    print(f"   â†’ ê°€ìƒ ë¬¸ì„œ: {hyde_doc[:100]}...")
    
    return {"hyde_document": hyde_doc}


def generate_multi_queries(state: QueryTransformState) -> dict:
    """
    Multi-Query: ì¿¼ë¦¬ ë³€í˜• ìƒì„±
    
    ì›ë³¸ ì§ˆë¬¸ì„ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì¬ì‘ì„±í•˜ì—¬
    ê²€ìƒ‰ ë²”ìœ„ë¥¼ ë„“í™ë‹ˆë‹¤.
    """
    print(f"\nğŸ”„ [Multi-Query] ì¿¼ë¦¬ ë³€í˜• ìƒì„± ì¤‘...")
    
    llm = get_llm()
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ê²€ìƒ‰ ì¿¼ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì§ˆë¬¸ì„ 3ê°€ì§€ ë‹¤ë¥¸ ê´€ì ì—ì„œ ì¬ì‘ì„±í•˜ì„¸ìš”.
ê° ì§ˆë¬¸ì€ ê°™ì€ ì •ë³´ë¥¼ ì°¾ì§€ë§Œ ë‹¤ë¥¸ í‘œí˜„ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

í˜•ì‹:
1. [ì²« ë²ˆì§¸ ë³€í˜•]
2. [ë‘ ë²ˆì§¸ ë³€í˜•]
3. [ì„¸ ë²ˆì§¸ ë³€í˜•]"""),
        ("human", "ì›ë³¸ ì§ˆë¬¸: {question}"),
    ])
    
    response = (prompt | llm).invoke({"question": state["original_question"]})
    
    # ì‘ë‹µì—ì„œ ì§ˆë¬¸ë“¤ ì¶”ì¶œ
    lines = response.content.strip().split("\n")
    queries = []
    for line in lines:
        line = line.strip()
        if line and (line[0].isdigit() or line.startswith("-")):
            # ë²ˆí˜¸ë‚˜ ëŒ€ì‹œ ì œê±°
            query = line.lstrip("0123456789.-) ").strip()
            if query:
                queries.append(query)
    
    # ì›ë³¸ ì§ˆë¬¸ë„ í¬í•¨
    queries = [state["original_question"]] + queries[:3]
    
    print(f"   â†’ ì¿¼ë¦¬ ë³€í˜•ë“¤:")
    for i, q in enumerate(queries):
        print(f"      [{i+1}] {q}")
    
    return {"multi_queries": queries}


def search_with_hyde(state: QueryTransformState) -> dict:
    """HyDE ë¬¸ì„œë¡œ ê²€ìƒ‰"""
    print(f"\nğŸ” [HyDE ê²€ìƒ‰] ê°€ìƒ ë¬¸ì„œë¡œ ê²€ìƒ‰ ì¤‘...")
    
    vs = get_qt_vs()
    docs = vs.search(query=state["hyde_document"], k=3)
    
    print(f"   â†’ {len(docs)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨")
    
    return {"hyde_results": docs}


def search_with_multi_queries(state: QueryTransformState) -> dict:
    """Multi-Queryë¡œ ê²€ìƒ‰"""
    print(f"\nğŸ” [Multi-Query ê²€ìƒ‰] ì—¬ëŸ¬ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ ì¤‘...")
    
    vs = get_qt_vs()
    all_docs = []
    seen_contents = set()
    
    for i, query in enumerate(state["multi_queries"]):
        docs = vs.search(query=query, k=2)
        for doc in docs:
            if doc.page_content not in seen_contents:
                all_docs.append(doc)
                seen_contents.add(doc.page_content)
        print(f"   ì¿¼ë¦¬ [{i+1}]: {len(docs)}ê°œ")
    
    print(f"   â†’ ì´ {len(all_docs)}ê°œ ê³ ìœ  ë¬¸ì„œ")
    
    return {"multi_query_results": all_docs}


def merge_results(state: QueryTransformState) -> dict:
    """
    ê²°ê³¼ ë³‘í•© (Reciprocal Rank Fusion ê°œë… ì ìš©)
    
    HyDEì™€ Multi-Query ê²°ê³¼ë¥¼ ë³‘í•©í•˜ê³  ì¤‘ë³µ ì œê±°í•©ë‹ˆë‹¤.
    """
    print(f"\nğŸ”€ [ë³‘í•©] ê²°ê³¼ í†µí•© ì¤‘...")
    
    # ë‘ ê²°ê³¼ ë³‘í•© (ì¤‘ë³µ ì œê±°)
    seen = set()
    merged = []
    
    # HyDE ê²°ê³¼ ë¨¼ì € (ë³´í†µ ë” ì •í™•)
    for doc in state.get("hyde_results", []):
        if doc.page_content not in seen:
            merged.append(doc)
            seen.add(doc.page_content)
    
    # Multi-Query ê²°ê³¼ ì¶”ê°€
    for doc in state.get("multi_query_results", []):
        if doc.page_content not in seen:
            merged.append(doc)
            seen.add(doc.page_content)
    
    # ìµœëŒ€ 5ê°œë¡œ ì œí•œ
    merged = merged[:5]
    
    context = "\n\n".join([
        f"[ë¬¸ì„œ {i+1}] {doc.page_content}"
        for i, doc in enumerate(merged)
    ])
    
    print(f"   â†’ ìµœì¢… {len(merged)}ê°œ ë¬¸ì„œ")
    
    return {"merged_documents": merged, "context": context}


def generate_answer(state: QueryTransformState) -> dict:
    """ë‹µë³€ ìƒì„±"""
    print(f"\nğŸ’­ [ìƒì„±] ë‹µë³€ ìƒì„± ì¤‘...")
    
    llm = get_llm()
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}"""),
        ("human", "{question}"),
    ])
    
    response = (prompt | llm).invoke({
        "context": state["context"],
        "question": state["original_question"]
    })
    
    return {"answer": response.content}


# =============================================================================
# 4. ê·¸ë˜í”„ ìƒì„±
# =============================================================================

def create_query_transform_rag():
    """
    Query Transform RAG ê·¸ë˜í”„
    
    êµ¬ì¡°:
        START â†’ generate_hyde â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ search_hyde â”€â”€â”€â”€â”€â”€â”
              â””â†’ generate_multi_queries â†’ search_multi â”€â”€â”€â”€â”´â†’ merge â†’ generate â†’ END
    """
    graph = StateGraph(QueryTransformState)
    
    # ë…¸ë“œ ì¶”ê°€
    graph.add_node("generate_hyde", generate_hyde_document)
    graph.add_node("generate_multi_queries", generate_multi_queries)
    graph.add_node("search_hyde", search_with_hyde)
    graph.add_node("search_multi", search_with_multi_queries)
    graph.add_node("merge", merge_results)
    graph.add_node("generate", generate_answer)
    
    # ì—£ì§€ (ë³‘ë ¬ ì¿¼ë¦¬ ë³€í™˜)
    graph.add_edge(START, "generate_hyde")
    graph.add_edge(START, "generate_multi_queries")
    graph.add_edge("generate_hyde", "search_hyde")
    graph.add_edge("generate_multi_queries", "search_multi")
    graph.add_edge("search_hyde", "merge")
    graph.add_edge("search_multi", "merge")
    graph.add_edge("merge", "generate")
    graph.add_edge("generate", END)
    
    print("âœ… Query Transform RAG ì»´íŒŒì¼ ì™„ë£Œ!")
    return graph.compile()


# =============================================================================
# 5. ì‹¤í–‰
# =============================================================================

def run_query_transform_rag(question: str) -> str:
    graph = create_query_transform_rag()
    
    initial_state = {
        "original_question": question,
        "hyde_document": "",
        "multi_queries": [],
        "hyde_results": [],
        "multi_query_results": [],
        "merged_documents": [],
        "context": "",
        "answer": ""
    }
    
    print(f"\n{'='*60}")
    print(f"ğŸ™‹ ì§ˆë¬¸: {question}")
    print('='*60)
    
    result = graph.invoke(initial_state)
    
    print(f"\nğŸ¤– ë‹µë³€:\n{result['answer']}")
    print('='*60)
    
    return result["answer"]


if __name__ == "__main__":
    from utils.llm_factory import log_llm_error
    
    print("\n" + "="*60)
    print("Query Transform RAG ì˜ˆì œ")
    print("="*60)
    
    queries = [
        "HyDEê°€ ë­ì•¼?",
        "RAGì—ì„œ ì¿¼ë¦¬ ë³€í™˜ì€ ì–´ë–¤ ì¢…ë¥˜ê°€ ìˆì–´?",
    ]
    
    for query in queries:
        try:
            run_query_transform_rag(query)
        except Exception as e:
            log_llm_error(e)
            print(f"âŒ ì˜¤ë¥˜: {e}")
        print()
