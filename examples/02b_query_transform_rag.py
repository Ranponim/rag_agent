# -*- coding: utf-8 -*-
# ì´ íŒŒì¼ì€ UTF-8 ì¸ì½”ë”©ì„ ì‚¬ìš©í•˜ì—¬ í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤. (ì´ˆì‹¬ììš© ìƒì„¸ ì£¼ì„ ë²„ì „)

"""
============================================================================
ğŸ“š 02b. Query Transform RAG - ì§ˆë¬¸(Query)ì„ ë” ë˜‘ë˜‘í•˜ê²Œ ë°”ê¿”ì„œ ê²€ìƒ‰í•˜ê¸°
============================================================================

ì‚¬ìš©ìê°€ ëŒ€ì¶© ë¬¼ì–´ë´ë„ AIê°€ ê·¸ ì§ˆë¬¸ì„ ê²€ìƒ‰í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ 'ë³€ì‹ (Transform)'ì‹œì¼œ
ë” ì •í™•í•œ ì •ë³´ë¥¼ ì°¾ì•„ë‚´ëŠ” ê³ ê¸‰ ê¸°ìˆ ë“¤ì„ ë°°ì›ë‹ˆë‹¤.

ğŸ¯ í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸:
    1. HyDE: ì§ˆë¬¸ì— ëŒ€í•œ 'ê°€ì§œ ëŒ€ë‹µ'ì„ ë¨¼ì € ìƒìƒí•´ë³´ê³ , ê·¸ ìƒìƒì„ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    2. Multi-Query: ì§ˆë¬¸ í•˜ë‚˜ë¥¼ 3~4ê°œì˜ ë‹¤ì–‘í•œ í‘œí˜„ìœ¼ë¡œ ë°”ê¿”ì„œ ê·¸ë¬¼ë§ì„ ë„“ê²Œ í¼ì¹©ë‹ˆë‹¤.
    3. ë³‘ë ¬ ê²€ìƒ‰: ì—¬ëŸ¬ ê°ˆë˜ì˜ ê²€ìƒ‰ì„ ë™ì‹œì— ì§„í–‰í•˜ì—¬ ì‹œê°„ì„ ë‹¨ì¶•í•˜ê³  ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
"""

# =============================================================================
# ğŸ“¦ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (ë„êµ¬ ê°€ë°© ì±™ê¸°ê¸°)
# =============================================================================

import sys                              # ì‹œìŠ¤í…œ í™˜ê²½ ì œì–´
import os                               # í™˜ê²½ë³€ìˆ˜ ì ‘ê·¼ìš©
from pathlib import Path                # íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬
from typing import TypedDict, List      # ë°ì´í„° í˜•ì‹ ì •ì˜

# í”„ë¡œì íŠ¸ ìµœìƒë‹¨ í´ë”ë¥¼ ê²½ë¡œì— ì¶”ê°€í•˜ì—¬ config, utils ë“±ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
sys.path.insert(0, str(Path(__file__).parent.parent))

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# LangChainì˜ ë¬¸ì„œ í˜•ì‹ê³¼ ì§€ì‹œì„œ(í”„ë¡¬í”„íŠ¸) ë„êµ¬
from langchain_openai import ChatOpenAI # LLM ëª¨ë¸ í´ë˜ìŠ¤
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate

# LangGraphì˜ ìˆœì„œë„(ê·¸ë˜í”„) ì œì‘ ë„êµ¬
from langgraph.graph import StateGraph, START, END

# í”„ë¡œì íŠ¸ ì „ìš© ìœ í‹¸ë¦¬í‹°ë“¤
from utils.llm_factory import get_embeddings, log_llm_error
from utils.vector_store import VectorStoreManager


# =============================================================================
# ğŸ“‹ 1. ìƒíƒœ(State) ì •ì˜í•˜ê¸° (ê³µìœ  ì‘ì—…íŒ)
# =============================================================================

class QueryTransformState(TypedDict):
    """ì´ RAG ì‹œìŠ¤í…œì´ ì¼í•˜ë©´ì„œ ì ì–´ë‘˜ ë©”ëª¨ì¥ í•­ëª©ë“¤ì…ë‹ˆë‹¤."""
    original_question: str               # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì›ë˜ ì§ˆë¬¸
    hyde_document: str                   # 1. HyDE ê¸°ë²•ìœ¼ë¡œ ë§Œë“  'ê°€ìƒ ë‹µë³€' ì§€ë¬¸
    multi_queries: List[str]             # 2. ì—¬ëŸ¬ ê´€ì ìœ¼ë¡œ ë‹¤ì‹œ ì“´ ì§ˆë¬¸ ëª©ë¡
    hyde_results: List[Document]         # HyDEë¡œ ì°¾ì•„ë‚¸ ì‹¤ì œ ë¬¸ì„œë“¤
    multi_query_results: List[Document]  # ë³€í˜• ì§ˆë¬¸ë“¤ë¡œ ì°¾ì•„ë‚¸ ì‹¤ì œ ë¬¸ì„œë“¤
    merged_documents: List[Document]     # ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹œ ëª©ë¡
    context: str                         # AIì—ê²Œ ë³´ì—¬ì¤„ ìµœì¢… ì°¸ê³  ì§€ë¬¸ í•©ë³¸
    answer: str                          # AIê°€ ìµœì¢…ì ìœ¼ë¡œ ì‘ì„±í•œ ë‹µë³€


# =============================================================================
# ğŸ—„ï¸ 2. Vector Store ì´ˆê¸°í™” (ê³µí†µ ëª¨ë“ˆ ì‚¬ìš©)
# =============================================================================

from utils.data_loader import get_rag_vector_store

def get_qt_vs() -> VectorStoreManager:
    """ê²€ìƒ‰ ë³€í™˜ ì „ìš© ì§€ì‹ ì°½ê³ ë¥¼ ìƒì„±í•˜ê³  ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    return get_rag_vector_store(collection_name="query_transform_rag")


# =============================================================================
# ğŸ”§ 3. ê° ë‹¨ê³„(Node)ì—ì„œ í•˜ëŠ” ì¼ ì •ì˜í•˜ê¸°
# =============================================================================

def generate_hyde_document(state: QueryTransformState) -> dict:
    """[ê²½ë¡œ A-1] HyDE ê°€ìƒ ë¬¸ì„œ ë§Œë“¤ê¸°: 'ë‹µë³€ì€ ì´ëŸ´ ê±°ì•¼'ë¼ê³  ìƒìƒí•˜ê¸°"""
    print(f"\nğŸ”® [HyDE] ì§ˆë¬¸ì— ëŒ€í•œ 'ê°€ìƒì˜ ì •ë‹µ'ì„ ìƒìƒí•´ì„œ ì¨ë³´ëŠ” ì¤‘...")
    
    # AI ëª¨ë¸ ì´ˆê¸°í™”
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    # AIì—ê²Œ ê°€ì§œ ë‹µë³€ì„ ì•„ì£¼ ìœ ì‹í•˜ê²Œ ì¨ë‹¬ë¼ê³  ë¶€íƒí•©ë‹ˆë‹¤.
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ë‹¹ì‹ ì€ ì§€ì‹ ë°±ê³¼ì‚¬ì „ í¸ì§‘ìì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ì•„ì£¼ ìƒì„¸í•˜ê³  ì „ë¬¸ì ì¸ 'ê°€ìƒ ë‹µë³€'ì„ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."),
        ("human", "{question}"),
    ])
    
    # AIê°€ ìƒìƒí•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    response = (prompt | model).invoke({"question": state["original_question"]})
    print(f"   â†’ ê°€ìƒ ë‹µë³€ ìƒìƒ ì™„ë£Œ! ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    
    # ìƒì„±ëœ ê°€ìƒ ë‹µë³€ì„ 'hyde_document' ì¹¸ì— ì ìŠµë‹ˆë‹¤.
    return {"hyde_document": response.content}


def generate_multi_queries(state: QueryTransformState) -> dict:
    """[ê²½ë¡œ B-1] Multi-Query ë§Œë“¤ê¸°: ì§ˆë¬¸ì„ ì—¬ëŸ¬ ë°©ì‹ìœ¼ë¡œ ë‹¤ì‹œ ì“°ê¸°"""
    print(f"\nğŸ”„ [Multi-Query] ì§ˆë¬¸ì„ 3ê°€ì§€ ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ë³€í˜•í•˜ëŠ” ì¤‘...")
    
    # AI ëª¨ë¸ ì´ˆê¸°í™”
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    # ì§ˆë¬¸ì˜ ì˜ë¯¸ëŠ” ê°™ì§€ë§Œ ë‹¨ì–´ êµ¬ì„±ì„ ë‹¤ë¥´ê²Œ í•˜ì—¬ ê²€ìƒ‰ ê·¸ë¬¼ì„ ë„“í™ë‹ˆë‹¤.
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ì›ë³¸ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ì— ë„ì›€ì´ ë ë§Œí•œ ë³€í˜• ì§ˆë¬¸ 3ê°œë¥¼ ë§Œë“œì„¸ìš”. í•œ ì¤„ì— í•˜ë‚˜ì”©ë§Œ ì“°ì„¸ìš”."),
        ("human", "ì›ë³¸ ì§ˆë¬¸: {question}"),
    ])
    
    response = (prompt | model).invoke({"question": state["original_question"]})
    
    # AIì˜ ë‹µë³€ì„ ì¤„ ë‹¨ìœ„ë¡œ ìª¼ê°œ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤.
    queries = [q.strip() for q in response.content.split("\n") if q.strip()]
    # ì›ë³¸ ì§ˆë¬¸ê¹Œì§€ í¬í•¨í•´ì„œ ì´ 4ê°œì˜ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ë³´í•©ë‹ˆë‹¤.
    final_queries = [state["original_question"]] + queries[:3]
    
    print(f"   â†’ í™•ì¥ëœ ì§ˆë¬¸ ê·¸ë¬¼: {final_queries}")
    # ì—¬ëŸ¬ ì§ˆë¬¸ë“¤ì„ 'multi_queries' ì¹¸ì— ê¸°ë¡í•©ë‹ˆë‹¤.
    return {"multi_queries": final_queries}


def search_with_hyde(state: QueryTransformState) -> dict:
    """[ê²½ë¡œ A-2] ìƒìƒí•œ ë‹µë³€(HyDE)ê³¼ ê°€ì¥ ë¹„ìŠ·í•œ ì§„ì§œ ë¬¸ì„œ ì°¾ê¸°"""
    print(f"ğŸ” [HyDE ê²€ìƒ‰] AIì˜ ìƒìƒë ¥ê³¼ ê°€ì¥ ì¼ì¹˜í•˜ëŠ” ì§„ì§œ ìë£Œë¥¼ ì°¾ëŠ” ì¤‘...")
    vs = get_qt_vs()
    # ê°€ì§œ ë‹µë³€ì„ ì¿¼ë¦¬ë¡œ ì¨ì„œ ì‹¤ì œ ì§€ì‹ ì°½ê³ ë¥¼ ë’¤ì§‘ë‹ˆë‹¤.
    docs = vs.search(query=state["hyde_document"], k=3)
    return {"hyde_results": docs}


def search_with_multi_queries(state: QueryTransformState) -> dict:
    """[ê²½ë¡œ B-2] 4ê°œì˜ ì§ˆë¬¸ ê·¸ë¬¼ë¡œ ì‹¹ì“¸ì´ ê²€ìƒ‰í•˜ê¸°"""
    print(f"ğŸ” [Multi-Query ê²€ìƒ‰] {len(state['multi_queries'])}ê°œì˜ ì§ˆë¬¸ ê·¸ë¬¼ë¡œ ë„“ê²Œ ë’¤ì§€ëŠ” ì¤‘...")
    vs = get_qt_vs()
    
    all_docs = []
    seen_content = set() # ì¤‘ë³µëœ ë‚´ìš©ì„ ê±¸ëŸ¬ë‚´ê¸° ìœ„í•œ ì¥ì¹˜
    
    # ê° ì§ˆë¬¸ë§ˆë‹¤ ëŒì•„ê°€ë©° ê²€ìƒ‰í•©ë‹ˆë‹¤.
    for q in state["multi_queries"]:
        docs = vs.search(query=q, k=2)
        for d in docs:
            # ì´ë¯¸ ì°¾ì€ ë‚´ìš©ì´ ì•„ë‹ˆë©´ ëª©ë¡ì— ë‹´ìŠµë‹ˆë‹¤.
            if d.page_content not in seen_content:
                all_docs.append(d)
                seen_content.add(d.page_content)
                
    return {"multi_query_results": all_docs}


def merge_results(state: QueryTransformState) -> dict:
    """[í†µí•© ë‹¨ê³„] ë‘ ê²½ë¡œ(A, B)ì—ì„œ ì–»ì€ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ë¡œ ì˜ˆì˜ê²Œ í•©ì¹˜ê¸°"""
    print(f"\nğŸ”€ [ê²°ê³¼ í•©ì¹˜ê¸°] ëª¨ë“  ê²€ìƒ‰ ê²½ë¡œì˜ ê²°ê³¼ë¥¼ í†µí•©í•˜ê³  ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.")
    
    seen = set()
    merged = []
    
    # HyDE ê²€ìƒ‰ ê²°ê³¼ì™€ Multi-Query ê²€ìƒ‰ ê²°ê³¼ë¥¼ í•œ í†µì— ë‹´ìŠµë‹ˆë‹¤.
    total_docs = state.get("hyde_results", []) + state.get("multi_query_results", [])
    
    for doc in total_docs:
        if doc.page_content not in seen:
            merged.append(doc)
            seen.add(doc.page_content)
    
    # ë„ˆë¬´ ë³µì¡í•˜ë©´ ìƒìœ„ 5ê°œë§Œ ìµœì¢… í›„ë³´ë¡œ ì •í•©ë‹ˆë‹¤.
    final_docs = merged[:5]
    print(f"   â†’ ìµœì¢…ì ìœ¼ë¡œ {len(final_docs)}ê°œì˜ ìœ ë‹ˆí¬í•œ ì§€ì‹ ë¬¸ì„œë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")
    
    # AIê°€ ì½ê¸° ì¢‹ê²Œ ë¬¸ì¥ë“¤ì„ í•©ì³ì„œ ì»¨í…ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤.
    context = "\n\n".join([f"[ì°¸ì¡°{i+1}] {d.page_content}" for i, d in enumerate(final_docs)])
    
    return {"merged_documents": final_docs, "context": context}


def generate_answer(state: QueryTransformState) -> dict:
    """[ë§ˆì§€ë§‰: ë‹µë³€ ì“°ê¸°] í’ë¶€í•˜ê²Œ ëª¨ì€ ì§€ì‹ìœ¼ë¡œ ì™„ë²½í•œ ë‹µì¥ ì“°ê¸°"""
    print("ğŸ“ [ìµœì¢… ë‹µë³€] ì •êµí•˜ê²Œ ìˆ˜ì§‘ëœ ì •ë³´ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•©ë‹ˆë‹¤...")
    
    # AI ëª¨ë¸ ì´ˆê¸°í™”
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ë‹¹ì‹ ì€ ë„ì„œê´€ ì‚¬ì„œì²˜ëŸ¼ ì •í™•í•œ ì •ë³´ë§Œì„ ì•Œë ¤ì£¼ëŠ” AI ê°€ì´ë“œì…ë‹ˆë‹¤."),
        ("human", "ì°¸ì¡°í•œ ì§€ì‹ë“¤:\n{context}\n\nì‚¬ìš©ì ì§ˆë¬¸: {question}"),
    ])
    
    # ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    response = (prompt | model).invoke({
        "context": state["context"],
        "question": state["original_question"]
    })
    
    # ë“œë””ì–´ ì™„ì„±ëœ ë‹µë³€ì„ ê¸°ë¡í•©ë‹ˆë‹¤.
    return {"answer": response.content}


# =============================================================================
# ğŸ”— 4. ì „ì²´ì ì¸ ì—…ë¬´ íë¦„ë„(Graph) ì¡°ë¦½í•˜ê¸°
# =============================================================================

def create_graph():
    """ë³‘ë ¬(ë™ì‹œ) ê²€ìƒ‰ì´ ê°€ëŠ¥í•œ ê³ ê¸‰ RAG ìˆœì„œë„ë¥¼ ë§Œë“­ë‹ˆë‹¤."""
    # ìš°ë¦¬ê°€ ë§Œë“  ë©”ëª¨ì¥(QueryTransformState)ì„ ì‚¬ìš©í•˜ëŠ” ë„ë©´ì„ í¼ì¹©ë‹ˆë‹¤.
    builder = StateGraph(QueryTransformState)
    
    # 1. ì¼í•  ì‚¬ëŒ(ë…¸ë“œ)ë“¤ì„ ì´ë¦„í‘œì™€ í•¨ê»˜ ë“±ë¡í•©ë‹ˆë‹¤.
    builder.add_node("gen_hyde", generate_hyde_document)
    builder.add_node("gen_multi", generate_multi_queries)
    builder.add_node("search_hyde", search_with_hyde)
    builder.add_node("search_multi", search_with_multi_queries)
    builder.add_node("merge", merge_results)
    builder.add_node("generate", generate_answer)
    
    # 2. í™”ì‚´í‘œë¥¼ ì´ì–´ì¤ë‹ˆë‹¤. (STARTì—ì„œ ë‘ ê°ˆë˜ë¡œ ë‚˜ë‰©ë‹ˆë‹¤!)
    builder.add_edge(START, "gen_hyde")             # Aê²½ë¡œ: HyDE ì‹œì‘
    builder.add_edge(START, "gen_multi")            # Bê²½ë¡œ: Multi-Query ì‹œì‘
    
    builder.add_edge("gen_hyde", "search_hyde")     # Aê²½ë¡œ ì´ì–´ê°€ê¸°
    builder.add_edge("gen_multi", "search_multi")   # Bê²½ë¡œ ì´ì–´ê°€ê¸°
    
    builder.add_edge("search_hyde", "merge")        # Aê²°ê³¼ë¥¼ í•©ì¹˜ê¸° ë‹¨ê³„ë¡œ ë³´ëƒ„
    builder.add_edge("search_multi", "merge")       # Bê²°ê³¼ë„ í•©ì¹˜ê¸° ë‹¨ê³„ë¡œ ë³´ëƒ„
    
    builder.add_edge("merge", "generate")           # í•©ì³ì§„ ê²°ê³¼ë¡œ ë‹µë³€ ì‹œì‘
    builder.add_edge("generate", END)               # ë‹µë³€ ë!
    
    # 3. ì¡°ë¦½ ì™„ë£Œëœ ìˆœì„œë„ë¥¼ ì‹¤í–‰ ê°€ëŠ¥í•œ ê¸°ê³„(Graph)ë¡œ ë§Œë“­ë‹ˆë‹¤.
    return builder.compile()


# =============================================================================
# â–¶ï¸ 5. ì‹¤ì œë¡œ ëŒë ¤ë³´ê¸° (CLI ì‹¤í–‰ë¶€)
# =============================================================================

def run_qt_rag(query: str, app):
    """ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ì‘ë™ ê³¼ì •ì„ ë³´ì—¬ì£¼ë©° ë‹µë³€í•©ë‹ˆë‹¤."""
    print(f"\n{'='*60}")
    print(f"ğŸ™‹ ì§ˆë¬¸: {query}")
    print(f"{'='*60}")
    
    try:
        # ê°€ë™ ì¤€ë¹„(ì…ë ¥ê°’ ì„¸íŒ…)
        result = app.invoke({
            "original_question": query,
            "hyde_document": "",
            "multi_queries": [],
            "hyde_results": [],
            "multi_query_results": [],
            "merged_documents": [],
            "context": "",
            "answer": ""
        })
        
        # íƒ„ìƒí•œ ë‹µë³€ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
        print(f"\nğŸ¤– AI ê°€ì´ë“œì˜ ë‹µë³€:\n{result['answer']}")
        
    except Exception as e:
        log_llm_error(e)
        print(f"âŒ ë„ì¤‘ì— ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë‚¬ìŠµë‹ˆë‹¤: {e}")


if __name__ == "__main__":
    print("\n" + "ğŸŒŸ Query Transform RAG ì‹œìŠ¤í…œì„ ê°€ë™í•©ë‹ˆë‹¤! ğŸŒŸ")
    print("ì§ˆë¬¸ì„ ì–´ë–»ê²Œ ë°”ê¿”ì„œ ê²€ìƒ‰í•˜ëŠ”ì§€ ê³¼ì •ì„ ì§€ì¼œë³´ì„¸ìš”.")
    print("- ì¢…ë£Œí•˜ë ¤ë©´ 'q' í˜¹ì€ 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")
    
    # 1. íë¦„ë„ ê¸°ê³„ë¥¼ í•œ ë²ˆ ë§Œë“¤ì–´ ë‘¡ë‹ˆë‹¤.
    app = create_graph()
    
    # 2. ë°˜ë³µí•´ì„œ ì§ˆë¬¸ì„ ë°›ìŠµë‹ˆë‹¤.
    while True:
        try:
            line = input("ğŸ™‹ ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ê²ƒì„ ì ì–´ì£¼ì„¸ìš”: ").strip()
            
            if not line: continue
                
            if line.lower() in ("quit", "exit", "q"):
                print("ğŸ‘‹ ì´ìš©í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”.")
                break
                
            # ì‹¤í–‰!
            run_qt_rag(line, app)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ê¸‰íˆ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâš ï¸ ì˜ˆê¸°ì¹˜ ëª»í•œ ì—ëŸ¬: {e}")
            break
