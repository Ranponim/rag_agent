# -*- coding: utf-8 -*-
"""
03. Entity RAG ì˜ˆì œ - ì—”í‹°í‹° ê¸°ë°˜ ë³‘ë ¬ ê²€ìƒ‰

LangGraphì˜ ë³‘ë ¬ ì‹¤í–‰(Parallel Execution) ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬,
ì—”í‹°í‹° ê¸°ë°˜ ê²€ìƒ‰ê³¼ ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì„ ë™ì‹œì— ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë³‘í•©í•˜ëŠ” íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤.

í•™ìŠµ ëª©í‘œ:
    1. LangGraphì˜ ë³‘ë ¬ ë…¸ë“œ ì‹¤í–‰ (Fan-out / Fan-in) íŒ¨í„´ êµ¬í˜„
    2. LLMì„ ì´ìš©í•œ ì—”í‹°í‹° ì¶”ì¶œ (Structured Output)
    3. ë‹¤ì¤‘ ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© (Merge) ì „ëµ

ì‹¤í–‰ ë°©ë²•:
    python examples/03_entity_rag.py
"""

import sys
from pathlib import Path
from typing import TypedDict, List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€í•˜ì—¬ ë‚´ë¶€ ëª¨ë“ˆ(config, utils)ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆê²Œ í•¨
sys.path.insert(0, str(Path(__file__).parent.parent))

# LangChain: ì—”í‹°í‹° ì¶”ì¶œ ë° ë¬¸ì„œ ê²€ìƒ‰ ê´€ë ¨
from langchain_core.documents import Document  # ê²€ìƒ‰ëœ ë°ì´í„°ì˜ í‘œì¤€ ë¬¸ì„œ ê°ì²´
from langchain_core.prompts import ChatPromptTemplate  # ì¿¼ë¦¬ ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ì„¤ê³„ë„
from langchain_core.output_parsers import JsonOutputParser  # ì¶”ì¶œëœ ì—”í‹°í‹°ë¥¼ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
from langgraph.graph import StateGraph, START, END  # ë³‘ë ¬ ì‹¤í–‰ íë¦„ ì œì–´ë¥¼ ìœ„í•œ ê·¸ë˜í”„ êµ¬ì„± ë„êµ¬

# í”„ë¡œì íŠ¸ ìœ í‹¸ë¦¬í‹°
from config.settings import get_settings  # ì„¤ì • ì •ë³´ ë¡œë“œ
from utils.llm_factory import get_llm, get_embeddings, log_llm_error  # LLM/ì„ë² ë”© ìƒì„± ë° ì˜¤ë¥˜ ê¸°ë¡
from utils.vector_store import VectorStoreManager  # ë²¡í„° DB ê²€ìƒ‰ ë§¤ë‹ˆì €


# =============================================================================
# 1. State ì •ì˜
# =============================================================================

class EntityRAGState(TypedDict):
    """
    Entity RAG ìƒíƒœ

    ë³‘ë ¬ ì‹¤í–‰ì„ ìœ„í•´ ê° ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³„ë„ì˜ í•„ë“œë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    question: str                    # ì‚¬ìš©ì ì§ˆë¬¸
    entities: List[str]              # ì¶”ì¶œëœ ì—”í‹°í‹° ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    entity_docs: List[Document]      # ì—”í‹°í‹° ê²€ìƒ‰ ê²°ê³¼ (Exact Match)
    semantic_docs: List[Document]    # ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ê²°ê³¼ (Vector Search)
    merged_docs: List[Document]      # ë³‘í•©ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
    answer: str                      # ìµœì¢… ë‹µë³€


# =============================================================================
# 2. Vector Store ì¤€ë¹„ (ë©”íƒ€ë°ì´í„° í¬í•¨)
# =============================================================================

def get_vector_store() -> VectorStoreManager:
    """Vector Store ì´ˆê¸°í™” ë° ë©”íƒ€ë°ì´í„° í¬í•¨ ë°ì´í„° ë¡œë“œ"""
    embeddings = get_embeddings()
    manager = VectorStoreManager(embeddings=embeddings, collection_name="entity_rag")

    if True: # í•­ìƒ ë°ì´í„° ë¡œë“œ ì‹œë„ (ì˜ˆì œìš©)
        data = [
            ("LangGraphëŠ” ìˆœí™˜ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.", {"tags": "LangGraph"}),
            ("LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.", {"tags": "LangChain"}),
            ("RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ ì…ë‹ˆë‹¤.", {"tags": "RAG"}),
            ("Vector DBëŠ” ì„ë² ë”©ì„ ì €ì¥í•©ë‹ˆë‹¤.", {"tags": "VectorDB"}),
        ]
        manager.add_texts([d[0] for d in data], metadatas=[d[1] for d in data])

    return manager


# =============================================================================
# 3. ë…¸ë“œ í•¨ìˆ˜ ì •ì˜
# =============================================================================

def extract_entities(state: EntityRAGState):
    """ì—”í‹°í‹° ì¶”ì¶œ ë…¸ë“œ"""
    print(f"\nğŸ·ï¸ ì—”í‹°í‹° ì¶”ì¶œ ì¤‘: {state['question']}")
    
    # ê°„ë‹¨í•œ ì—”í‹°í‹° ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ìœ ë„)
    llm = get_llm()
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ(ì—”í‹°í‹°)ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
ì˜ˆì‹œ: {{"entities": ["Apple", "iPhone"]}}
ì§ˆë¬¸: {question}"""),
    ])
    
    try:
        chain = prompt | llm | JsonOutputParser()
        result = chain.invoke({"question": state["question"]})
        entities = result.get("entities", [])
        print(f"   -> ì¶”ì¶œëœ ì—”í‹°í‹°: {entities}")
        return {"entities": entities}
    except Exception as e:
        print(f"   -> ì¶”ì¶œ ì‹¤íŒ¨, ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜: {e}")
        return {"entities": []}


def search_by_entity(state: EntityRAGState):
    """ì—”í‹°í‹° ê¸°ë°˜ ê²€ìƒ‰ ë…¸ë“œ (ë³‘ë ¬ ì‹¤í–‰ 1)"""
    print("ğŸ” ì—”í‹°í‹° ê²€ìƒ‰ ìˆ˜í–‰...")
    vs = get_vector_store()
    results = []
    
    # ì¶”ì¶œëœ ì—”í‹°í‹°ê°€ ë©”íƒ€ë°ì´í„°ë‚˜ ë³¸ë¬¸ì— í¬í•¨ëœ ë¬¸ì„œ ê²€ìƒ‰ (ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜)
    for entity in state["entities"]:
        # ì‹¤ì œë¡œëŠ” ë©”íƒ€ë°ì´í„° í•„í„°ë§ ë“±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
        docs = vs.search(entity, k=1)
        results.extend(docs)

    return {"entity_docs": results}


def search_semantic(state: EntityRAGState):
    """ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ë…¸ë“œ (ë³‘ë ¬ ì‹¤í–‰ 2)"""
    print("ğŸ” ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ìˆ˜í–‰...")
    vs = get_vector_store()
    docs = vs.search(state["question"], k=2)
    return {"semantic_docs": docs}


def merge_results(state: EntityRAGState):
    """ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ë…¸ë“œ"""
    print("ğŸ”„ ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ì¤‘...")
    
    # ì¤‘ë³µ ì œê±° ë° ë³‘í•©
    seen = set()
    merged = []
    
    # ì—”í‹°í‹° ê²€ìƒ‰ ê²°ê³¼ ìš°ì„ 
    for doc in state.get("entity_docs", []) + state.get("semantic_docs", []):
        if doc.page_content not in seen:
            merged.append(doc)
            seen.add(doc.page_content)

    print(f"   -> ì´ {len(merged)}ê°œ ë¬¸ì„œ ë³‘í•©ë¨")
    return {"merged_docs": merged}


def generate_answer(state: EntityRAGState):
    """ë‹µë³€ ìƒì„± ë…¸ë“œ"""
    print("ğŸ“ ë‹µë³€ ìƒì„± ì¤‘...")
    context = "\n".join(d.page_content for d in state["merged_docs"])
    
    llm = get_llm()
    response = llm.invoke(f"ì»¨í…ìŠ¤íŠ¸: {context}\n\nì§ˆë¬¸: {state['question']}\në‹µë³€:")
    
    return {"answer": response.content}


# =============================================================================
# 4. ê·¸ë˜í”„ êµ¬ì„± (ë³‘ë ¬ ì‹¤í–‰)
# =============================================================================

def create_entity_rag_graph():
    """Entity RAG ê·¸ë˜í”„ ìƒì„±"""
    builder = StateGraph(EntityRAGState)
    
    # ë…¸ë“œ ì¶”ê°€
    builder.add_node("extract_entities", extract_entities)
    builder.add_node("entity_search", search_by_entity)
    builder.add_node("semantic_search", search_semantic)
    builder.add_node("merge", merge_results)
    builder.add_node("generate", generate_answer)
    
    # ì—£ì§€ ì—°ê²°
    builder.add_edge(START, "extract_entities")
    
    # ë³‘ë ¬ ì‹¤í–‰ (Fan-out): extract_entities ì™„ë£Œ í›„ ë‘ ê²€ìƒ‰ ë…¸ë“œë¡œ ë™ì‹œì— ë¶„ê¸°
    builder.add_edge("extract_entities", "entity_search")
    builder.add_edge("extract_entities", "semantic_search")
    
    # ë³‘í•© (Fan-in): ë‘ ê²€ìƒ‰ ë…¸ë“œê°€ ëª¨ë‘ ì™„ë£Œë˜ë©´ merge ë…¸ë“œë¡œ ì´ë™
    builder.add_edge("entity_search", "merge")
    builder.add_edge("semantic_search", "merge")
    
    builder.add_edge("merge", "generate")
    builder.add_edge("generate", END)
    
    return builder.compile()


# =============================================================================
# 5. ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸
# =============================================================================

if __name__ == "__main__":
    print("\nLangGraph Entity RAG Example (Parallel Execution)")
    
    graph = create_entity_rag_graph()
    
    questions = ["LangGraphì™€ LangChainì— ëŒ€í•´ ì•Œë ¤ì¤˜"]
    
    for q in questions:
        print(f"\n{'='*40}\nì§ˆë¬¸: {q}\n{'='*40}")
        try:
            result = graph.invoke({"question": q})
            print(f"\nğŸ¤– ë‹µë³€: {result['answer']}")
        except Exception as e:
            log_llm_error(e)
