# -*- coding: utf-8 -*-
"""
03. Entity RAG ì˜ˆì œ - ì—”í‹°í‹° ê¸°ë°˜ RAG êµ¬í˜„

ì¿¼ë¦¬ì—ì„œ ì—”í‹°í‹°ë¥¼ ì¶”ì¶œí•˜ê³ , ì—”í‹°í‹° ê¸°ë°˜ ê²€ìƒ‰ê³¼ ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì„ ê²°í•©í•©ë‹ˆë‹¤.

í•™ìŠµ ëª©í‘œ:
    1. LLMì„ í™œìš©í•œ ì—”í‹°í‹° ì¶”ì¶œ
    2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì „ëµ (ì—”í‹°í‹° + ì˜ë¯¸ë¡ ì )
    3. ë³‘ë ¬ ë…¸ë“œ ì‹¤í–‰

ì‹¤í–‰: python examples/03_entity_rag.py
"""

import sys
from pathlib import Path
from typing import TypedDict, List

sys.path.insert(0, str(Path(__file__).parent.parent))

from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langgraph.graph import StateGraph, START, END

from config.settings import get_settings
from utils.llm_factory import get_llm, get_embeddings
from utils.vector_store import VectorStoreManager


# =============================================================================
# 1. State ì •ì˜
# =============================================================================

class EntityRAGState(TypedDict):
    """Entity RAG ìƒíƒœ"""
    question: str                    # ì‚¬ìš©ì ì§ˆë¬¸
    entities: List[dict]             # ì¶”ì¶œëœ ì—”í‹°í‹° [{"name": str, "type": str}]
    entity_documents: List[Document] # ì—”í‹°í‹° ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼
    semantic_documents: List[Document]  # ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ê²°ê³¼
    merged_documents: List[Document] # ë³‘í•©ëœ ë¬¸ì„œ
    context: str                     # ìµœì¢… ì»¨í…ìŠ¤íŠ¸
    answer: str                      # ìƒì„±ëœ ë‹µë³€


# =============================================================================
# 2. Vector Store ì´ˆê¸°í™”
# =============================================================================

_entity_vs: VectorStoreManager = None

def get_entity_vs() -> VectorStoreManager:
    """ì—”í‹°í‹° Vector Store ë°˜í™˜ (ì‹±ê¸€í†¤)"""
    global _entity_vs
    if _entity_vs is None:
        print("ğŸ“š Entity Vector Store ì´ˆê¸°í™”...")
        _entity_vs = VectorStoreManager(
            embeddings=get_embeddings(),
            collection_name="entity_rag",
            chunk_size=300,
        )
        # ìƒ˜í”Œ ë°ì´í„°
        samples = [
            ("LangGraphëŠ” LangChain íŒ€ì´ ê°œë°œí•œ ìƒíƒœ ê¸°ë°˜ ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.", "LangGraph,LangChain"),
            ("RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„±ìœ¼ë¡œ, ì™¸ë¶€ ì§€ì‹ìœ¼ë¡œ LLM ì‘ë‹µì„ ê°œì„ í•©ë‹ˆë‹¤.", "RAG,LLM"),
            ("ChromaDBëŠ” LangChainê³¼ í•¨ê»˜ ì‚¬ìš©ë˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ë²¡í„° DBì…ë‹ˆë‹¤.", "ChromaDB,LangChain"),
            ("OpenAIëŠ” GPT-4ì™€ ChatGPTë¥¼ ê°œë°œí•œ AI ì—°êµ¬ íšŒì‚¬ì…ë‹ˆë‹¤.", "OpenAI,GPT-4,ChatGPT"),
            ("Self-RAGëŠ” LLMì´ ê²€ìƒ‰ í•„ìš”ì„±ì„ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.", "Self-RAG,LLM"),
            ("Corrective RAGëŠ” ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆì„ í‰ê°€í•˜ê³  ì¬ê²€ìƒ‰í•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤.", "Corrective RAG"),
        ]
        _entity_vs.add_texts(
            texts=[s[0] for s in samples],
            metadatas=[{"entities": s[1]} for s in samples]
        )
        print(f"âœ… {len(samples)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ")
    return _entity_vs


# =============================================================================
# 3. ë…¸ë“œ í•¨ìˆ˜
# =============================================================================

def extract_entities_node(state: EntityRAGState) -> dict:
    """ì¿¼ë¦¬ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ (LLM ì‚¬ìš©)"""
    print(f"\nğŸ·ï¸ ì—”í‹°í‹° ì¶”ì¶œ: '{state['question']}'")
    
    llm = get_llm()
    prompt = ChatPromptTemplate.from_messages([
        ("system", """í…ìŠ¤íŠ¸ì—ì„œ ê¸°ìˆ /ê°œë…/ì¡°ì§ ì—”í‹°í‹°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
JSON í˜•ì‹: {{"entities": [{{"name": "ì´ë¦„", "type": "technology|concept|organization"}}]}}
ì—”í‹°í‹° ì—†ìœ¼ë©´: {{"entities": []}}"""),
        ("human", "{question}"),
    ])
    
    try:
        chain = prompt | llm | JsonOutputParser()
        result = chain.invoke({"question": state["question"]})
        entities = result.get("entities", [])
        print(f"   â†’ ì¶”ì¶œ: {[e['name'] for e in entities]}")
    except Exception as e:
        print(f"   âš ï¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        entities = []
    
    return {"entities": entities}


def entity_search_node(state: EntityRAGState) -> dict:
    """ì—”í‹°í‹° ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰"""
    print("\nğŸ” ì—”í‹°í‹° ê¸°ë°˜ ê²€ìƒ‰...")
    
    entities = state.get("entities", [])
    if not entities:
        return {"entity_documents": []}
    
    vs = get_entity_vs()
    entity_docs = []
    
    for entity in entities:
        docs = vs.search(query=entity["name"], k=2)
        for doc in docs:
            if entity["name"].lower() in doc.metadata.get("entities", "").lower():
                if doc not in entity_docs:
                    entity_docs.append(doc)
    
    print(f"   â†’ {len(entity_docs)}ê°œ ë¬¸ì„œ")
    return {"entity_documents": entity_docs}


def semantic_search_node(state: EntityRAGState) -> dict:
    """ì˜ë¯¸ë¡ ì  ê²€ìƒ‰"""
    print("\nğŸ” ì˜ë¯¸ë¡ ì  ê²€ìƒ‰...")
    
    docs = get_entity_vs().search(query=state["question"], k=3)
    print(f"   â†’ {len(docs)}ê°œ ë¬¸ì„œ")
    return {"semantic_documents": docs}


def merge_results_node(state: EntityRAGState) -> dict:
    """ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© (ì—”í‹°í‹° ìš°ì„ , ì¤‘ë³µ ì œê±°)"""
    print("\nğŸ”€ ê²°ê³¼ ë³‘í•©...")
    
    entity_docs = state.get("entity_documents", [])
    semantic_docs = state.get("semantic_documents", [])
    
    # ì—”í‹°í‹° ë¬¸ì„œ ìš°ì„ , ì¤‘ë³µ ì œê±°
    merged = list(entity_docs)
    seen = {doc.page_content for doc in merged}
    
    for doc in semantic_docs:
        if doc.page_content not in seen:
            merged.append(doc)
            seen.add(doc.page_content)
    
    merged = merged[:5]  # ìµœëŒ€ 5ê°œ
    
    # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    context = "\n\n".join([
        f"[ë¬¸ì„œ {i+1}] {doc.page_content}" for i, doc in enumerate(merged)
    ])
    
    print(f"   â†’ ìµœì¢… {len(merged)}ê°œ")
    return {"merged_documents": merged, "context": context}


def generate_answer_node(state: EntityRAGState) -> dict:
    """ë‹µë³€ ìƒì„±"""
    print("\nğŸ’­ ë‹µë³€ ìƒì„±...")
    
    llm = get_llm()
    entities_str = ", ".join([e["name"] for e in state.get("entities", [])]) or "ì—†ìŒ"
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
ì£¼ìš” ì—”í‹°í‹°: {entities}
ì»¨í…ìŠ¤íŠ¸:
{context}"""),
        ("human", "{question}"),
    ])
    
    response = (prompt | llm).invoke({
        "entities": entities_str,
        "context": state["context"],
        "question": state["question"],
    })
    
    return {"answer": response.content}


# =============================================================================
# 4. ê·¸ë˜í”„ ìƒì„±
# =============================================================================

def create_entity_rag_graph():
    """
    Entity RAG ê·¸ë˜í”„ ìƒì„±
    
    êµ¬ì¡°:
        START â†’ extract_entities â†’ entity_search â”€â”
                                                  â”œâ†’ merge â†’ generate â†’ END
                                 semantic_search â”€â”˜
    """
    graph = StateGraph(EntityRAGState)
    
    # ë…¸ë“œ ì¶”ê°€
    graph.add_node("extract_entities", extract_entities_node)
    graph.add_node("entity_search", entity_search_node)
    graph.add_node("semantic_search", semantic_search_node)
    graph.add_node("merge", merge_results_node)
    graph.add_node("generate", generate_answer_node)
    
    # ì—£ì§€: ì‹œì‘ â†’ ì—”í‹°í‹° ì¶”ì¶œ â†’ ë³‘ë ¬ ê²€ìƒ‰ â†’ ë³‘í•© â†’ ìƒì„± â†’ ì¢…ë£Œ
    graph.add_edge(START, "extract_entities")
    graph.add_edge("extract_entities", "entity_search")
    graph.add_edge("extract_entities", "semantic_search")
    graph.add_edge("entity_search", "merge")
    graph.add_edge("semantic_search", "merge")
    graph.add_edge("merge", "generate")
    graph.add_edge("generate", END)
    
    print("âœ… Entity RAG ê·¸ë˜í”„ ì»´íŒŒì¼ ì™„ë£Œ!")
    return graph.compile()


# =============================================================================
# 5. ì‹¤í–‰
# =============================================================================

def run_entity_rag(question: str) -> str:
    """Entity RAG ì‹¤í–‰"""
    graph = create_entity_rag_graph()
    
    initial_state = {
        "question": question, "entities": [], "entity_documents": [],
        "semantic_documents": [], "merged_documents": [], "context": "", "answer": "",
    }
    
    print(f"\n{'='*60}\nğŸ™‹ ì§ˆë¬¸: {question}\n{'='*60}")
    result = graph.invoke(initial_state)
    
    print(f"\nğŸ·ï¸ ì—”í‹°í‹°: {[e['name'] for e in result['entities']]}")
    print(f"ğŸ“š ìµœì¢… ë¬¸ì„œ: {len(result['merged_documents'])}ê°œ")
    print(f"\nğŸ¤– ë‹µë³€:\n{result['answer']}\n{'='*60}")
    
    return result["answer"]


if __name__ == "__main__":
    print("\n" + "="*60)
    print("Entity RAG ì˜ˆì œ")
    print("="*60)
    # ì„¤ì • í™•ì¸ (ì œê±°ë¨: Local LLM ë“± ë‹¤ì–‘í•œ í™˜ê²½ ì§€ì›ì„ ìœ„í•´ ì—„ê²©í•œ í‚¤ ê²€ì¦ ìƒëµ)
    
    test_queries = [
        "LangGraphì™€ LangChainì˜ ê´€ê³„ëŠ”?",
        "Self-RAGì™€ Corrective RAGì˜ ì°¨ì´ì ì€?",
    ]
    
    from utils.llm_factory import log_llm_error
    
    for query in test_queries:
        try:
            run_entity_rag(query)
        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒì„¸ ë¡œê¹…
            log_llm_error(e)
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print()
