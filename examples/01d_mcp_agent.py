# -*- coding: utf-8 -*-
"""
============================================================================
ğŸ“š 01d. MCP Agent - Model Context Protocol ì„œë²„ ì—°ë™ ì˜ˆì œ
============================================================================

ì´ ì˜ˆì œëŠ” ì™¸ë¶€ MCP(Model Context Protocol) ì„œë²„ì— ì—°ê²°í•˜ì—¬ 
í•´ë‹¹ ì„œë²„ê°€ ì œê³µí•˜ëŠ” ë„êµ¬ë¥¼ LangGraph ì—ì´ì „íŠ¸ì—ì„œ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

ğŸ¯ í•™ìŠµ ëª©í‘œ:
    1. MCP ì„œë²„ ë“±ë¡ ë° ì—°ê²° ë°©ë²• ì´í•´
    2. MultiServerMCPClientë¥¼ í†µí•œ ë‹¤ì¤‘ MCP ì„œë²„ ê´€ë¦¬
    3. MCP ë„êµ¬ë¥¼ LangGraph ì—ì´ì „íŠ¸ì— ë°”ì¸ë”©í•˜ëŠ” íŒ¨í„´

ğŸ’¡ í•µì‹¬ ê°œë…:
    - MCP (Model Context Protocol): AI ëª¨ë¸ì´ ì™¸ë¶€ ë„êµ¬/ë¦¬ì†ŒìŠ¤ì— ì ‘ê·¼í•˜ëŠ” í‘œì¤€ í”„ë¡œí† ì½œ
    - MultiServerMCPClient: ì—¬ëŸ¬ MCP ì„œë²„ë¥¼ ë™ì‹œì— ê´€ë¦¬í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸
    - Transport: MCP ì„œë²„ì™€ í†µì‹ í•˜ëŠ” ë°©ì‹ (stdio, sse, streamable-http)

ğŸ“¦ í•„ìˆ˜ íŒ¨í‚¤ì§€:
    pip install langchain-mcp-adapters langgraph

ì‹¤í–‰ ë°©ë²•:
    python examples/01d_mcp_agent.py
    
âš ï¸ ì£¼ì˜ì‚¬í•­:
    - MCP ì„œë²„ê°€ ë¯¸ë¦¬ ì‹¤í–‰ ì¤‘ì´ê±°ë‚˜, commandë¡œ ì‹œì‘ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.
    - ì•„ë˜ ì˜ˆì œì˜ ì„œë²„ ì„¤ì •ì€ ì‚¬ìš© í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.
"""

# =============================================================================
# ğŸ“¦ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# =============================================================================

import sys
import asyncio
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

# LangGraph í”„ë¦¬ë¹ŒíŠ¸ ì»´í¬ë„ŒíŠ¸
from langgraph.prebuilt import create_react_agent

# LangChain ì»´í¬ë„ŒíŠ¸
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

# MCP ì–´ëŒ‘í„° (MCP ì„œë²„ ì—°ê²°ìš©)
# pip install langchain-mcp-adapters
from langchain_mcp_adapters.client import MultiServerMCPClient

# í”„ë¡œì íŠ¸ ì„¤ì • ë¡œë“œ
from config.settings import get_settings


# =============================================================================
# âš™ï¸ 1. MCP ì„œë²„ ì„¤ì • ì •ì˜
# =============================================================================
# 
# MCP ì„œë²„ëŠ” í¬ê²Œ ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
# 
# 1. stdio (Standard I/O): ë¡œì»¬ í”„ë¡œì„¸ìŠ¤ë¡œ ì„œë²„ë¥¼ ì‹¤í–‰
#    - command: ì‹¤í–‰í•  ëª…ë ¹ì–´ (ì˜ˆ: "python", "npx", "node")
#    - args: ëª…ë ¹ì–´ ì¸ì (ì˜ˆ: ["/path/to/server.py"])
#    - transport: "stdio"
#
# 2. SSE (Server-Sent Events): ì›ê²© HTTP ì„œë²„ì— ì—°ê²°
#    - url: ì„œë²„ URL (ì˜ˆ: "http://localhost:8000/sse")
#    - transport: "sse"
#
# ğŸ’¡ ë³¸ ì˜ˆì œì—ì„œëŠ” ìì£¼ ì‚¬ìš©ë˜ëŠ” MCP ì„œë²„ë“¤ì˜ ì„¤ì • ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤.
# =============================================================================

# MCP ì„œë²„ ì„¤ì • ë”•ì…”ë„ˆë¦¬
# í‚¤(key)ëŠ” ì„œë²„ ì‹ë³„ìë¡œ, ì›í•˜ëŠ” ì´ë¦„ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
MCP_SERVER_CONFIGS = {
    # ì˜ˆì‹œ 1: Context7 MCP ì„œë²„ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œ ê²€ìƒ‰)
    # npxë¥¼ í†µí•´ ìë™ìœ¼ë¡œ íŒ¨í‚¤ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
    "context7": {
        "command": "npx",
        "args": ["-y", "@upstash/context7-mcp@latest"],
        "transport": "stdio",
    },
    
    # ì˜ˆì‹œ 2: Sequential Thinking MCP ì„œë²„ (ë‹¨ê³„ë³„ ì‚¬ê³ )
    # ë³µì¡í•œ ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•˜ëŠ” ì‚¬ê³  ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    "sequential_thinking": {
        "command": "npx",
        "args": ["-y", "@modelcontextprotocol/server-sequential-thinking"],
        "transport": "stdio",
    },
    
    # ì˜ˆì‹œ 3: ì»¤ìŠ¤í…€ ë¡œì»¬ MCP ì„œë²„ (Python ê¸°ë°˜)
    # ì§ì ‘ ë§Œë“  MCP ì„œë²„ë¥¼ ì—°ê²°í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # "custom_server": {
    #     "command": "python",
    #     "args": ["/absolute/path/to/your/mcp_server.py"],
    #     "transport": "stdio",
    # },
    
    # ì˜ˆì‹œ 4: ì›ê²© MCP ì„œë²„ (SSE ë°©ì‹)
    # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ HTTP ê¸°ë°˜ MCP ì„œë²„ì— ì—°ê²°í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # "remote_server": {
    #     "url": "http://localhost:8000/sse",
    #     "transport": "sse",
    # },
}


# =============================================================================
# ğŸ¤– 2. MCP ì—ì´ì „íŠ¸ ìƒì„± í•¨ìˆ˜
# =============================================================================

async def create_mcp_agent(server_configs: dict):
    """
    MCP ì„œë²„ì— ì—°ê²°í•˜ê³ , í•´ë‹¹ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        server_configs: MCP ì„œë²„ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        
    Returns:
        tuple: (client, agent) - MCP í´ë¼ì´ì–¸íŠ¸ì™€ ì—ì´ì „íŠ¸
        
    ğŸ’¡ MultiServerMCPClientëŠ” async context managerë¡œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
       with ë¸”ë¡ ì•ˆì—ì„œë§Œ MCP ì„œë²„ ì—°ê²°ì´ ìœ ì§€ë©ë‹ˆë‹¤.
    """
    settings = get_settings()
    
    # LLM ëª¨ë¸ ì´ˆê¸°í™” (ë„êµ¬ ë°”ì¸ë”©ì€ create_react_agentê°€ ì²˜ë¦¬)
    model = ChatOpenAI(
        base_url=settings.openai_api_base,
        api_key=settings.openai_api_key,
        model=settings.openai_model,
    )
    
    # MCP í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° ì—°ê²°
    # MultiServerMCPClientëŠ” ì—¬ëŸ¬ MCP ì„œë²„ë¥¼ ë™ì‹œì— ê´€ë¦¬í•©ë‹ˆë‹¤.
    client = MultiServerMCPClient(server_configs)
    
    # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì… (ì„œë²„ ì—°ê²° ì‹œì‘)
    await client.__aenter__()
    
    # MCP ì„œë²„ì—ì„œ ì œê³µí•˜ëŠ” ëª¨ë“  ë„êµ¬ ê°€ì ¸ì˜¤ê¸°
    # get_tools()ëŠ” ì—°ê²°ëœ ëª¨ë“  ì„œë²„ì˜ ë„êµ¬ë¥¼ LangChain Tool í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    tools = client.get_tools()
    
    print(f"ğŸ“¦ [MCP] ì—°ê²°ëœ ì„œë²„: {list(server_configs.keys())}")
    print(f"ğŸ”§ [MCP] ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {[t.name for t in tools]}")
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ì—ì´ì „íŠ¸ì˜ ì—­í•  ì •ì˜
    system_prompt = """ë‹¹ì‹ ì€ MCP ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ìë¥¼ ë•ëŠ” ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    
ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ í•´ì£¼ì„¸ìš”."""
    
    # create_react_agentë¡œ ì—ì´ì „íŠ¸ ìƒì„±
    # MCPì—ì„œ ê°€ì ¸ì˜¨ ë„êµ¬ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
    agent = create_react_agent(
        model,
        tools=tools,
        prompt=system_prompt,
    )
    
    return client, agent


# =============================================================================
# â–¶ï¸ 3. ì—ì´ì „íŠ¸ ì‹¤í–‰ í•¨ìˆ˜
# =============================================================================

async def run_mcp_agent(query: str, server_configs: dict = None):
    """
    MCP ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        server_configs: MCP ì„œë²„ ì„¤ì • (ê¸°ë³¸ê°’: MCP_SERVER_CONFIGS)
    """
    # ì„œë²„ ì„¤ì •ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
    if server_configs is None:
        server_configs = MCP_SERVER_CONFIGS
    
    print(f"\n{'='*60}")
    print(f"ğŸ™‹ ì‚¬ìš©ì: {query}")
    print('='*60)
    
    client = None
    try:
        # MCP ì—ì´ì „íŠ¸ ìƒì„± (ì„œë²„ ì—°ê²° í¬í•¨)
        client, agent = await create_mcp_agent(server_configs)
        
        # ì—ì´ì „íŠ¸ ì‹¤í–‰
        result = await agent.ainvoke(
            {"messages": [HumanMessage(content=query)]}
        )
        
        # ê²°ê³¼ì—ì„œ ë§ˆì§€ë§‰ ë©”ì‹œì§€(AI ì‘ë‹µ) ì¶”ì¶œ
        if result.get("messages"):
            final_msg = result["messages"][-1]
            print(f"\nğŸ¤– Agent: {final_msg.content}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("íŒ: MCP ì„œë²„ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        raise
        
    finally:
        # MCP í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ
        if client:
            await client.__aexit__(None, None, None)


# =============================================================================
# ğŸ”„ 4. ê°„ë‹¨ ì‚¬ìš© ì˜ˆì‹œ (ë‹¨ì¼ ì„œë²„ ì—°ê²°)
# =============================================================================

async def simple_mcp_example():
    """
    ë‹¨ì¼ MCP ì„œë²„(Context7)ë§Œ ì—°ê²°í•˜ëŠ” ê°„ë‹¨í•œ ì˜ˆì œì…ë‹ˆë‹¤.
    
    ğŸ’¡ async with ë¬¸ë²•ì„ ì‚¬ìš©í•˜ë©´ ìë™ìœ¼ë¡œ ì—°ê²° ì¢…ë£Œê°€ ì²˜ë¦¬ë©ë‹ˆë‹¤.
    """
    settings = get_settings()
    
    # LLM ëª¨ë¸ ì´ˆê¸°í™”
    model = ChatOpenAI(
        base_url=settings.openai_api_base,
        api_key=settings.openai_api_key,
        model=settings.openai_model,
    )
    
    # Context7 MCP ì„œë²„ë§Œ ì—°ê²°í•˜ëŠ” ê°„ë‹¨í•œ ì˜ˆì œ
    async with MultiServerMCPClient(
        {
            "context7": {
                "command": "npx",
                "args": ["-y", "@upstash/context7-mcp@latest"],
                "transport": "stdio",
            }
        }
    ) as client:
        # MCP ë„êµ¬ ê°€ì ¸ì˜¤ê¸°
        tools = client.get_tools()
        print(f"ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {[t.name for t in tools]}")
        
        # ì—ì´ì „íŠ¸ ìƒì„±
        agent = create_react_agent(
            model,
            tools=tools,
            prompt="ë‹¹ì‹ ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
        )
        
        # ì§ˆë¬¸ ì‹¤í–‰
        result = await agent.ainvoke(
            {"messages": [HumanMessage(content="LangGraphì˜ ì£¼ìš” ê¸°ëŠ¥ì„ ì•Œë ¤ì¤˜")]}
        )
        
        if result.get("messages"):
            print(f"\nğŸ¤– ì‘ë‹µ: {result['messages'][-1].content}")


# =============================================================================
# ğŸš€ 5. ë©”ì¸ ì‹¤í–‰ë¶€
# =============================================================================

if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸŒ LangGraph MCP Agent Example")
    print("="*60)
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
    # Context7 MCPë¥¼ ì‚¬ìš©í•˜ì—¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ì˜ˆì œ
    test_query = "LangGraphì˜ create_react_agent í•¨ìˆ˜ ì‚¬ìš©ë²•ì„ ì•Œë ¤ì¤˜"
    
    # ë¹„ë™ê¸° ì‹¤í–‰
    # asyncio.run()ìœ¼ë¡œ async í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    try:
        asyncio.run(run_mcp_agent(test_query))
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
