# -*- coding: utf-8 -*-
"""
============================================================================
ğŸ“š 01d. MCP Agent - Model Context Protocol ì„œë²„ ì—°ë™ ì˜ˆì œ
============================================================================

ì´ ì˜ˆì œëŠ” ì™¸ë¶€ MCP(Model Context Protocol) ì„œë²„ì— ì—°ê²°í•˜ì—¬ 
í•´ë‹¹ ì„œë²„ê°€ ì œê³µí•˜ëŠ” ë„êµ¬ë¥¼ LangGraph ì—ì´ì „íŠ¸ì—ì„œ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

ğŸ¯ í•™ìŠµ ëª©í‘œ:
    1. MCP ì„œë²„ ë“±ë¡ ë° ì—°ê²° ë°©ë²• ì´í•´
    2. MultiServerMCPClientë¥¼ í†µí•œ ë‹¤ì¤‘ MCP ì„œë²„ ê´€ë¦¬
    3. MCP ë„êµ¬ë¥¼ LangGraph ì—ì´ì „íŠ¸ì— ë°”ì¸ë”©í•˜ëŠ” íŒ¨í„´

ğŸ’¡ í•µì‹¬ ê°œë…:
    - MCP (Model Context Protocol): AI ëª¨ë¸ì´ ì™¸ë¶€ ë„êµ¬/ë¦¬ì†ŒìŠ¤ì— ì ‘ê·¼í•˜ëŠ” í‘œì¤€ í”„ë¡œí† ì½œ
    - MultiServerMCPClient: ì—¬ëŸ¬ MCP ì„œë²„ë¥¼ ë™ì‹œì— ê´€ë¦¬í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸
    - Transport: MCP ì„œë²„ì™€ í†µì‹ í•˜ëŠ” ë°©ì‹ (stdio, sse, streamable-http)

ğŸ“¦ í•„ìˆ˜ íŒ¨í‚¤ì§€:
    pip install langchain-mcp-adapters langgraph

ì‹¤í–‰ ë°©ë²•:
    python examples/01d_mcp_agent.py
    
âš ï¸ ì£¼ì˜ì‚¬í•­:
    - MCP ì„œë²„ê°€ ë¯¸ë¦¬ ì‹¤í–‰ ì¤‘ì´ê±°ë‚˜, commandë¡œ ì‹œì‘ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.
    - ì•„ë˜ ì˜ˆì œì˜ ì„œë²„ ì„¤ì •ì€ ì‚¬ìš© í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.
"""

# =============================================================================
# ğŸ“¦ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# =============================================================================

import sys
import os
import asyncio
from pathlib import Path

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

# LangGraph í”„ë¦¬ë¹ŒíŠ¸ ì»´í¬ë„ŒíŠ¸
from langgraph.prebuilt import create_react_agent

# LangChain ì»´í¬ë„ŒíŠ¸
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

# MCP í´ë¼ì´ì–¸íŠ¸ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹° (ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§ í¬í•¨)
from utils.mcp_client import MCPClientManager


# =============================================================================
# âš™ï¸ 1. MCP ì„œë²„ ì„¤ì • ì •ì˜
# =============================================================================
# 
# MCP ì„œë²„ëŠ” í¬ê²Œ ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
# 
# 1. stdio (Standard I/O): ë¡œì»¬ í”„ë¡œì„¸ìŠ¤ë¡œ ì„œë²„ë¥¼ ì‹¤í–‰
#    - command: ì‹¤í–‰í•  ëª…ë ¹ì–´ (ì˜ˆ: "python", "npx", "node")
#    - args: ëª…ë ¹ì–´ ì¸ì (ì˜ˆ: ["/path/to/server.py"])
#    - transport: "stdio"
#
# 2. SSE (Server-Sent Events): ì›ê²© HTTP ì„œë²„ì— ì—°ê²°
#    - url: ì„œë²„ URL (ì˜ˆ: "http://localhost:8000/sse")
#    - transport: "sse"
#
# ğŸ’¡ ë³¸ ì˜ˆì œì—ì„œëŠ” ìì£¼ ì‚¬ìš©ë˜ëŠ” MCP ì„œë²„ë“¤ì˜ ì„¤ì • ì˜ˆì‹œë¥¼ ì œê³µí•©ë‹ˆë‹¤.
# =============================================================================

# MCP ì„œë²„ ì„¤ì • ë”•ì…”ë„ˆë¦¬
# í‚¤(key)ëŠ” ì„œë²„ ì‹ë³„ìë¡œ, ì›í•˜ëŠ” ì´ë¦„ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
MCP_SERVER_CONFIGS = {
    # ì˜ˆì‹œ 1: Context7 MCP ì„œë²„ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œ ê²€ìƒ‰)
    # npxë¥¼ í†µí•´ ìë™ìœ¼ë¡œ íŒ¨í‚¤ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
    # Transport: stdio (ë¡œì»¬ í”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰)
    # "context7": {
    #     "command": "npx",
    #     "args": ["-y", "@upstash/context7-mcp@latest"],
    #     "transport": "stdio",
    # },
    
    # ì˜ˆì‹œ 2: Sequential Thinking MCP ì„œë²„ (ë‹¨ê³„ë³„ ì‚¬ê³ )
    # ë³µì¡í•œ ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•˜ëŠ” ì‚¬ê³  ë„êµ¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    # Transport: stdio (ë¡œì»¬ í”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰)
    "sequential_thinking": {
        "command": "npx",
        "args": ["-y", "@modelcontextprotocol/server-sequential-thinking"],
        "transport": "stdio",
    },
    
    # ì˜ˆì‹œ 3: Analysis LLM MCP ì„œë²„ (3GPP ë¶„ì„ ë„êµ¬)
    # ì›ê²© IP(165...)ëŠ” Python í™˜ê²½ì—ì„œ ì ‘ê·¼ ë¶ˆê°€í•˜ë¯€ë¡œ localhostë¥¼ íƒ€ê²Ÿìœ¼ë¡œ í•©ë‹ˆë‹¤.
    # Transport: streamable_http (HTTP ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹)
    # "analysis_llm": {
    #     "transport": "streamable_http", 
    #     "url": "http://localhost:8001/mcp",  # localhost ì£¼ì†Œë¡œ ë³€ê²½
    #     # PowerShell ì„±ê³µ ì‹œ ì‚¬ìš©ëœ í—¤ë”ë¥¼ MCPClientManagerê°€ ìë™ ì£¼ì…í•©ë‹ˆë‹¤.
    #     "headers": {
    #         "Accept": "application/json, text/event-stream"
    #     },
    # },
    
    # ì˜ˆì‹œ 4: ì»¤ìŠ¤í…€ ë¡œì»¬ MCP ì„œë²„ (Python ê¸°ë°˜)
    # ì§ì ‘ ë§Œë“  MCP ì„œë²„ë¥¼ ì—°ê²°í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # Transport: stdio (ë¡œì»¬ í”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰)
    # "custom_server": {
    #     "command": "python",
    #     "args": ["/absolute/path/to/your/mcp_server.py"],
    #     "transport": "stdio",
    # },
    
    # ì˜ˆì‹œ 5: ì›ê²© MCP ì„œë²„ (SSE ë°©ì‹)
    # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì„œë²„ì— Server-Sent Eventsë¡œ ì—°ê²°í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # Transport: sse (ì„œë²„ í‘¸ì‹œ ê¸°ë°˜ í†µì‹ )
    # "remote_server": {
    #     "url": "http://localhost:8000/sse",
    #     "transport": "sse",
    # },
    
    # [NEW] ë¡œì»¬ PC ë””ë ‰í† ë¦¬ íƒìƒ‰ MCP (FastMCP)
    "directory_explorer": {
        "command": "python",
        "args": [str(Path(__file__).parent.parent / "mcp" / "simple_dir_mcp.py")],
        "transport": "stdio",
    },
}


# =============================================================================
# ğŸ¤– 2. MCP ì—ì´ì „íŠ¸ ìƒì„± í•¨ìˆ˜
# =============================================================================

async def create_mcp_agent(server_configs: dict):
    """
    MCP ì„œë²„ì— ì—°ê²°í•˜ê³ , í•´ë‹¹ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        server_configs: MCP ì„œë²„ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        
    Returns:
        tuple: (manager, agent) - MCP í´ë¼ì´ì–¸íŠ¸ ë§¤ë‹ˆì €ì™€ ì—ì´ì „íŠ¸
        
    ğŸ’¡ MCPClientManagerë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°ê²° ê´€ë¦¬, ì˜¤ë¥˜ ì²˜ë¦¬, ì¬ì‹œë„ ë“±ì„ ìë™í™”í•©ë‹ˆë‹¤.
       ë°˜í™˜ëœ managerëŠ” ë°˜ë“œì‹œ disconnect()ë¥¼ í˜¸ì¶œí•˜ì—¬ ì •ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.
    """
    # LLM ëª¨ë¸ ì´ˆê¸°í™”
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°’ì„ ê°€ì ¸ì™€ ë³€ìˆ˜ì— í• ë‹¹ (printë¬¸ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•¨)
    api_base = os.getenv("OPENAI_API_BASE")
    api_key = os.getenv("OPENAI_API_KEY")
    model_name = os.getenv("OPENAI_MODEL")
    
    model = ChatOpenAI(
        base_url=api_base,
        api_key=api_key,
        model=model_name
    )
    
    print(f"\n{'='*70}")
    print(f"ğŸ¤– [Agent] LLM ëª¨ë¸ ì´ˆê¸°í™”: {model_name}")
    print(f"ğŸŒ [Agent] API Base: {api_base}")
    print(f"{'='*70}\n")
    
    # MCP í´ë¼ì´ì–¸íŠ¸ ë§¤ë‹ˆì € ìƒì„± ë° ì—°ê²°
    # MCPClientManagerëŠ” PowerShell ì„±ê³µ ì‚¬ë¡€ì˜ í—¤ë”(Connection: keep-alive ë“±)ë¥¼ 
    # ìë™ìœ¼ë¡œ ì£¼ì…í•˜ì—¬ RemoteProtocolErrorë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    manager = MCPClientManager(
        server_configs=server_configs,
        max_retries=3,
        retry_delay=2.0  # ì„œë²„ ì‘ë‹µ ëŒ€ê¸° ì‹œê°„ì„ ê³ ë ¤í•˜ì—¬ ì§€ì—° ì‹œê°„ ìƒí–¥
    )
    
    # ì„œë²„ ì—°ê²° ì‹œë„ (ë‚´ë¶€ì ìœ¼ë¡œ ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    # ì—°ê²° ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ê°€ ë°œìƒí•˜ë¯€ë¡œ í˜¸ì¶œí•˜ëŠ” ìª½ì—ì„œ try-exceptë¡œ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.
    await manager.connect()
    
    # MCP ì„œë²„ì—ì„œ ì œê³µí•˜ëŠ” ëª¨ë“  ë„êµ¬ ê°€ì ¸ì˜¤ê¸°
    # get_tools()ëŠ” ì—°ê²°ëœ ëª¨ë“  ì„œë²„ì˜ ë„êµ¬ë¥¼ LangChain Tool í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    tools = await manager.get_tools()
    
    # ì—°ê²° ì •ë³´ ì¶œë ¥
    print(f"\n{'='*70}")
    print(f"ğŸ“¦ [MCP] ì—°ê²°ëœ ì„œë²„: {list(server_configs.keys())}")
    print(f"ğŸ”§ [MCP] ì´ {len(tools)}ê°œì˜ ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥")
    print(f"{'='*70}\n")
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ì—ì´ì „íŠ¸ì˜ ì—­í•  ë° ì§€ì¹¨ ì •ì˜
    system_prompt = """ë‹¹ì‹ ì€ MCP(Model Context Protocol) ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì‚¬ìš©ìë¥¼ ë•ëŠ” ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    
ì£¼ìš” ì—­í• :
- ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- ë³µì¡í•œ ì§ˆë¬¸ì€ ë‹¨ê³„ë³„ë¡œ ë¶„í•´í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.
- ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

ë‹µë³€ ì›ì¹™:
- ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤.
- ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ê³  ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í™•ì¸í•©ë‹ˆë‹¤.
- ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì‚¬ìš©ìì—ê²Œ ëª…í™•íˆ ì„¤ëª…í•©ë‹ˆë‹¤."""
    
    # create_react_agentë¡œ ReAct íŒ¨í„´ ì—ì´ì „íŠ¸ ìƒì„±
    # ReAct: Reasoningê³¼ Actingì„ ë°˜ë³µí•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” íŒ¨í„´
    # - Reasoning: LLMì´ ë‹¤ìŒ í–‰ë™ì„ ê²°ì •
    # - Acting: ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ê±°ë‚˜ ìµœì¢… ë‹µë³€ ìƒì„±
    agent = create_react_agent(
        model,              # LLM ëª¨ë¸ (ChatOpenAI ì¸ìŠ¤í„´ìŠ¤)
        tools=tools,        # MCP ì„œë²„ì—ì„œ ê°€ì ¸ì˜¨ ë„êµ¬ ë¦¬ìŠ¤íŠ¸
        prompt=system_prompt,  # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì—ì´ì „íŠ¸ì˜ ì—­í•  ì •ì˜)
    )
    
    print(f"âœ… [Agent] ReAct ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ\n")
    
    # MCP í´ë¼ì´ì–¸íŠ¸ ë§¤ë‹ˆì €ì™€ ì—ì´ì „íŠ¸ë¥¼ í•¨ê»˜ ë°˜í™˜
    # ë§¤ë‹ˆì €ëŠ” ë‚˜ì¤‘ì— ì—°ê²°ì„ ì¢…ë£Œí•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.
    return manager, agent









# =============================================================================
# ğŸ”„ 4. ëŒ€í™”í˜• ì‹¤í–‰ í•¨ìˆ˜ (CLI Chat)
# =============================================================================

async def run_interactive_mcp_agent(server_configs: dict = None):
    """
    ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë©° MCP ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” ëŒ€í™”í˜• ë£¨í”„ì…ë‹ˆë‹¤.
    ì—°ê²°ì„ ìœ ì§€í•œ ìƒíƒœë¡œ ì—°ì†ì ì¸ ëŒ€í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    """
    if server_configs is None:
        server_configs = MCP_SERVER_CONFIGS

    print(f"\n{'='*70}")
    print("ğŸ’¬ MCP Interactive Chat Mode")
    print(f"{'='*70}")
    print("MCP ì„œë²„ì— ì—°ê²°í•˜ê³  ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...\n")

    manager = None
    
    try:
        # 1. ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ìˆ˜í–‰)
        manager, app = await create_mcp_agent(server_configs)
        
        # ëŒ€í™” ê¸°ë¡ ìœ ì§€
        chat_history = []
        
        print("\nâœ… ì¤€ë¹„ ì™„ë£Œ! ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”. (ì¢…ë£Œí•˜ë ¤ë©´ 'q' ë˜ëŠ” 'quit' ì…ë ¥)")
        print(f"{'-'*70}\n")
        
        while True:
            try:
                # ì‚¬ìš©ì ì…ë ¥
                query = input("\nğŸ™‹ User: ").strip()
                if not query:
                    continue
                    
                if query.lower() in ['q', 'quit', 'exit']:
                    print("\nğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                
                # ë©”ì‹œì§€ êµ¬ì„± (ê¸°ì¡´ íˆìŠ¤í† ë¦¬ + ìƒˆ ì§ˆë¬¸)
                current_messages = chat_history + [HumanMessage(content=query)]
                
                print(f"\nğŸ¤– Agent ìƒê° ì¤‘...", end="", flush=True)
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
                step_count = 0
                final_response_chunk = None
                
                # astreamì„ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰ ê³¼ì • ì‹œê°í™”
                async for chunk in app.astream(
                    {"messages": current_messages},
                    stream_mode="values"
                ):
                    if "messages" in chunk:
                        messages = chunk["messages"]
                        if messages:
                            last_msg = messages[-1]
                            
                            # ë„êµ¬ í˜¸ì¶œ ë¡œê¹…
                            if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:
                                step_count += 1
                                print(f"\n\nğŸ”§ [Step {step_count}] ë„êµ¬ í˜¸ì¶œ:")
                                for tool_call in last_msg.tool_calls:
                                    print(f"  ğŸ“Œ {tool_call.get('name')}: {tool_call.get('args')}")
                                print("  â³ ì‹¤í–‰ ì¤‘...", end="", flush=True)
                            
                            # ë„êµ¬ ê²°ê³¼ ë¡œê¹…
                            elif hasattr(last_msg, 'content') and last_msg.content and len(messages) > len(current_messages):
                                # AIì˜ ì¤‘ê°„ ì‘ë‹µì´ë‚˜ ìµœì¢… ì‘ë‹µì´ ì•„ë‹ ë•Œ (ì¦‰, ToolMessage ë°”ë¡œ ë‹¤ìŒì´ ì•„ë‹Œ ê²½ìš° ë“±)
                                pass

                        final_response_chunk = chunk

                # ìµœì¢… ì‘ë‹µ ì²˜ë¦¬
                if final_response_chunk and "messages" in final_response_chunk:
                    final_messages = final_response_chunk["messages"]
                    last_msg = final_messages[-1]
                    
                    if hasattr(last_msg, 'content') and last_msg.content:
                        print(f"\n\nğŸ¤– Agent:\n{last_msg.content}\n")
                    
                    # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸ (ì „ì²´ íˆìŠ¤í† ë¦¬ ë®ì–´ì“°ê¸°)
                    chat_history = final_messages
                    
            except KeyboardInterrupt:
                print("\n\nâš ï¸ ì¸í„°ëŸ½íŠ¸ ê°ì§€. ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"\n\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()
                
    except Exception as e:
        print(f"\nâŒ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    finally:
        if manager:
            print("\nğŸ”Œ ì—°ê²° ì¢…ë£Œ ì¤‘...")
            await manager.disconnect()
            print("âœ… ì—°ê²° ì¢…ë£Œ ì™„ë£Œ")


# =============================================================================
# ğŸš€ 5. ë©”ì¸ ì‹¤í–‰ë¶€
# =============================================================================

if __name__ == "__main__":
    # ë¹„ë™ê¸° ì‹¤í–‰
    try:
        # CLI ì±„íŒ… ëª¨ë“œ ì‹¤í–‰
        asyncio.run(run_interactive_mcp_agent())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
