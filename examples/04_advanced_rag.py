# -*- coding: utf-8 -*-
"""
04. Advanced RAG ì˜ˆì œ - Self-RAG & Corrective RAG êµ¬í˜„

ê³ ê¸‰ RAG íŒ¨í„´ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ í‰ê°€, ê´€ë ¨ì„± ê²€ì¦, ìê¸° ìˆ˜ì • ë£¨í”„ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

í•™ìŠµ ëª©í‘œ:
    1. ì¡°ê±´ë¶€ ë¶„ê¸°ë¥¼ í™œìš©í•œ ì ì‘í˜• RAG
    2. ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ (Grading)
    3. ë‹µë³€ í’ˆì§ˆ ê²€ì¦ (Hallucination Check)
    4. ìê¸° ìˆ˜ì • ë£¨í”„ êµ¬í˜„

ì‹¤í–‰: python examples/04_advanced_rag.py
"""

import sys
from pathlib import Path
from typing import TypedDict, List, Literal

sys.path.insert(0, str(Path(__file__).parent.parent))

from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langgraph.graph import StateGraph, START, END

from config.settings import get_settings
from utils.llm_factory import get_llm, get_embeddings
from utils.vector_store import VectorStoreManager


# =============================================================================
# 1. State ì •ì˜
# =============================================================================

class AdvancedRAGState(TypedDict):
    """
    Advanced RAG ìƒíƒœ
    
    Naive RAGì™€ ë‹¬ë¦¬ í‰ê°€ ë° ìˆ˜ì • ê´€ë ¨ í•„ë“œê°€ ì¶”ê°€ë¨
    """
    question: str                    # ì‚¬ìš©ì ì§ˆë¬¸
    documents: List[Document]        # ê²€ìƒ‰ëœ ë¬¸ì„œ
    relevant_documents: List[Document]  # ê´€ë ¨ì„± ìˆëŠ” ë¬¸ì„œë§Œ
    context: str                     # ì»¨í…ìŠ¤íŠ¸
    answer: str                      # ìƒì„±ëœ ë‹µë³€
    relevance_score: str             # ê´€ë ¨ì„± í‰ê°€ ("relevant" | "not_relevant")
    hallucination_check: str         # í™˜ê° ì²´í¬ ("grounded" | "hallucinated")
    retry_count: int                 # ì¬ì‹œë„ íšŸìˆ˜


# =============================================================================
# 2. Vector Store ì´ˆê¸°í™”
# =============================================================================

_adv_vs: VectorStoreManager = None

def get_advanced_vs() -> VectorStoreManager:
    """Advanced RAGìš© Vector Store"""
    global _adv_vs
    if _adv_vs is None:
        print("ğŸ“š Advanced RAG Vector Store ì´ˆê¸°í™”...")
        _adv_vs = VectorStoreManager(
            embeddings=get_embeddings(),
            collection_name="advanced_rag",
            chunk_size=400,
        )
        samples = [
            "LangGraphëŠ” ìƒíƒœ ê¸°ë°˜ ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. StateGraphë¡œ ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.",
            "Self-RAGëŠ” LLMì´ ê²€ìƒ‰ í•„ìš”ì„±ì„ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ê³ , ê²€ìƒ‰ ê²°ê³¼ì™€ ìƒì„± ì‘ë‹µì˜ í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤.",
            "Corrective RAGëŠ” ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ê³ , í’ˆì§ˆì´ ë‚®ìœ¼ë©´ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ë³´ì™„í•©ë‹ˆë‹¤.",
            "RAG íŒŒì´í”„ë¼ì¸ì€ ê²€ìƒ‰(Retrieval), ì¦ê°•(Augmentation), ìƒì„±(Generation) 3ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.",
            "Adaptive RAGëŠ” ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¼ ë‹¨ìˆœ ì‘ë‹µ, ê²€ìƒ‰ ì‘ë‹µ, ë‹¤ë‹¨ê³„ ì¶”ë¡ ì„ ì„ íƒí•©ë‹ˆë‹¤.",
            "Hallucinationì€ LLMì´ ì‚¬ì‹¤ì´ ì•„ë‹Œ ì •ë³´ë¥¼ ìƒì„±í•˜ëŠ” í˜„ìƒìœ¼ë¡œ, RAGë¡œ ì™„í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        ]
        _adv_vs.add_texts(texts=samples)
        print(f"âœ… {len(samples)}ê°œ ë¬¸ì„œ ë¡œë“œ")
    return _adv_vs


# =============================================================================
# 3. ë…¸ë“œ í•¨ìˆ˜
# =============================================================================

def retrieve_node(state: AdvancedRAGState) -> dict:
    """ë¬¸ì„œ ê²€ìƒ‰"""
    print(f"\nğŸ” ê²€ìƒ‰: '{state['question']}'")
    docs = get_advanced_vs().search(query=state["question"], k=4)
    print(f"   â†’ {len(docs)}ê°œ ë¬¸ì„œ")
    return {"documents": docs}


def grade_documents_node(state: AdvancedRAGState) -> dict:
    """
    ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ (Grading)
    
    LLMì„ ì‚¬ìš©í•˜ì—¬ ê° ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ìˆëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.
    ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œëŠ” í•„í„°ë§í•©ë‹ˆë‹¤.
    """
    print("\nğŸ“Š ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€...")
    
    llm = get_llm()
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ìˆìœ¼ë©´ "yes", ì—†ìœ¼ë©´ "no"ë§Œ ë‹µí•˜ì„¸ìš”.

ì§ˆë¬¸: {question}
ë¬¸ì„œ: {document}

ê´€ë ¨ì„± (yes/no):"""),
    ])
    
    chain = prompt | llm
    relevant_docs = []
    
    for doc in state["documents"]:
        result = chain.invoke({
            "question": state["question"],
            "document": doc.page_content[:500]
        })
        
        if "yes" in result.content.lower():
            relevant_docs.append(doc)
    
    print(f"   â†’ ê´€ë ¨ ë¬¸ì„œ: {len(relevant_docs)}/{len(state['documents'])}ê°œ")
    
    # ê´€ë ¨ì„± ì ìˆ˜ ê²°ì •
    score = "relevant" if len(relevant_docs) >= 2 else "not_relevant"
    
    # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    context = "\n\n".join([
        f"[{i+1}] {doc.page_content}" for i, doc in enumerate(relevant_docs)
    ]) if relevant_docs else ""
    
    return {
        "relevant_documents": relevant_docs,
        "relevance_score": score,
        "context": context,
    }


def generate_node(state: AdvancedRAGState) -> dict:
    """ë‹µë³€ ìƒì„±"""
    print("\nğŸ’­ ë‹µë³€ ìƒì„±...")
    
    if not state["context"]:
        return {"answer": "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    llm = get_llm()
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ì»¨í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”. ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}"""),
        ("human", "{question}"),
    ])
    
    response = (prompt | llm).invoke({
        "context": state["context"],
        "question": state["question"],
    })
    
    return {"answer": response.content}


def check_hallucination_node(state: AdvancedRAGState) -> dict:
    """
    í™˜ê° ê²€ì‚¬ (Hallucination Check)
    
    ìƒì„±ëœ ë‹µë³€ì´ ì»¨í…ìŠ¤íŠ¸ì— ê¸°ë°˜í•˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
    """
    print("\nğŸ”¬ í™˜ê° ê²€ì‚¬...")
    
    if not state["context"] or not state["answer"]:
        return {"hallucination_check": "grounded"}
    
    llm = get_llm()
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹µë³€ì´ ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•˜ë©´ "grounded", ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ "hallucinated"ë§Œ ë‹µí•˜ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ë‹µë³€:
{answer}

íŒì • (grounded/hallucinated):"""),
    ])
    
    result = (prompt | llm).invoke({
        "context": state["context"],
        "answer": state["answer"],
    })
    
    check = "grounded" if "grounded" in result.content.lower() else "hallucinated"
    print(f"   â†’ ê²°ê³¼: {check}")
    
    return {"hallucination_check": check}


def fallback_search_node(state: AdvancedRAGState) -> dict:
    """
    í´ë°± ê²€ìƒ‰ (Fallback)
    
    ê´€ë ¨ ë¬¸ì„œê°€ ë¶€ì¡±í•˜ê±°ë‚˜ í™˜ê°ì´ ê°ì§€ë˜ë©´ ì¶”ê°€ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    ì‹¤ì œë¡œëŠ” ì›¹ ê²€ìƒ‰ ë“±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    print("\nğŸ”„ í´ë°± ê²€ìƒ‰...")
    
    # ì¬ì‹œë„ íšŸìˆ˜ ì¦ê°€
    retry = state.get("retry_count", 0) + 1
    
    if retry >= 2:
        print("   â†’ ìµœëŒ€ ì¬ì‹œë„ ë„ë‹¬")
        return {
            "retry_count": retry,
            "answer": f"ì£„ì†¡í•©ë‹ˆë‹¤. '{state['question']}'ì— ëŒ€í•œ ì •í™•í•œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        }
    
    # ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¡œ ì¬ê²€ìƒ‰ (ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ ì¬ê²€ìƒ‰)
    vs = get_advanced_vs()
    docs = vs.search(query=f"{state['question']} ì„¤ëª…", k=3)
    
    context = "\n\n".join([doc.page_content for doc in docs])
    
    print(f"   â†’ ì¬ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê°œ")
    return {
        "documents": docs,
        "relevant_documents": docs,
        "context": context,
        "retry_count": retry,
        "relevance_score": "relevant" if docs else "not_relevant",
    }


# =============================================================================
# 4. ë¼ìš°í„° í•¨ìˆ˜ (ì¡°ê±´ë¶€ ë¶„ê¸°)
# =============================================================================

def route_by_relevance(state: AdvancedRAGState) -> Literal["generate", "fallback"]:
    """ê´€ë ¨ì„±ì— ë”°ë¼ ë¶„ê¸°"""
    if state.get("relevance_score") == "relevant":
        return "generate"
    return "fallback"


def route_by_hallucination(state: AdvancedRAGState) -> Literal[END, "fallback"]:
    """í™˜ê° ê²€ì‚¬ ê²°ê³¼ì— ë”°ë¼ ë¶„ê¸°"""
    if state.get("hallucination_check") == "grounded":
        return END
    if state.get("retry_count", 0) >= 2:
        return END
    return "fallback"


# =============================================================================
# 5. ê·¸ë˜í”„ ìƒì„±
# =============================================================================

def create_advanced_rag_graph():
    """
    Advanced RAG ê·¸ë˜í”„ ìƒì„±
    
    êµ¬ì¡°:
        START â†’ retrieve â†’ grade_documents â”€â”¬â†’ generate â†’ check_hallucination â”€â”¬â†’ END
                                            â”‚                                   â”‚
                                            â””â†’ fallback â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    í•µì‹¬ ê¸°ëŠ¥:
    1. ë¬¸ì„œ ê´€ë ¨ì„± í‰ê°€ (Grade Documents)
    2. ê´€ë ¨ ë¬¸ì„œ ë¶€ì¡± ì‹œ í´ë°± ê²€ìƒ‰
    3. í™˜ê° ê²€ì‚¬ (Hallucination Check)  
    4. í™˜ê° ê°ì§€ ì‹œ ì¬ê²€ìƒ‰
    """
    graph = StateGraph(AdvancedRAGState)
    
    # ë…¸ë“œ ì¶”ê°€
    graph.add_node("retrieve", retrieve_node)
    graph.add_node("grade", grade_documents_node)
    graph.add_node("generate", generate_node)
    graph.add_node("check_hallucination", check_hallucination_node)
    graph.add_node("fallback", fallback_search_node)
    
    # ì—£ì§€
    graph.add_edge(START, "retrieve")
    graph.add_edge("retrieve", "grade")
    
    # ì¡°ê±´ë¶€ ë¶„ê¸°: ê´€ë ¨ì„±ì— ë”°ë¼
    graph.add_conditional_edges(
        "grade",
        route_by_relevance,
        {"generate": "generate", "fallback": "fallback"}
    )
    
    graph.add_edge("generate", "check_hallucination")
    
    # ì¡°ê±´ë¶€ ë¶„ê¸°: í™˜ê°ì— ë”°ë¼
    graph.add_conditional_edges(
        "check_hallucination",
        route_by_hallucination,
        {END: END, "fallback": "fallback"}
    )
    
    # í´ë°± í›„ ì¬ìƒì„±
    graph.add_edge("fallback", "generate")
    
    print("âœ… Advanced RAG ê·¸ë˜í”„ ì»´íŒŒì¼ ì™„ë£Œ!")
    return graph.compile()


# =============================================================================
# 6. ì‹¤í–‰
# =============================================================================

def run_advanced_rag(question: str) -> str:
    """Advanced RAG ì‹¤í–‰"""
    graph = create_advanced_rag_graph()
    
    initial_state = {
        "question": question,
        "documents": [],
        "relevant_documents": [],
        "context": "",
        "answer": "",
        "relevance_score": "",
        "hallucination_check": "",
        "retry_count": 0,
    }
    
    print(f"\n{'='*60}\nğŸ™‹ ì§ˆë¬¸: {question}\n{'='*60}")
    result = graph.invoke(initial_state)
    
    print(f"\nğŸ“Š í‰ê°€ ê²°ê³¼:")
    print(f"   - ê´€ë ¨ì„±: {result['relevance_score']}")
    print(f"   - í™˜ê° ê²€ì‚¬: {result['hallucination_check']}")
    print(f"   - ì¬ì‹œë„: {result['retry_count']}íšŒ")
    print(f"\nğŸ¤– ë‹µë³€:\n{result['answer']}\n{'='*60}")
    
    return result["answer"]


def visualize_graph():
    """ê·¸ë˜í”„ êµ¬ì¡° ì‹œê°í™”"""
    print("\nğŸ“Š Advanced RAG ê·¸ë˜í”„ (Mermaid)")
    print("```mermaid")
    print("graph TD")
    print("    START --> retrieve[ê²€ìƒ‰]")
    print("    retrieve --> grade[ê´€ë ¨ì„± í‰ê°€]")
    print("    grade -->|relevant| generate[ìƒì„±]")
    print("    grade -->|not_relevant| fallback[í´ë°± ê²€ìƒ‰]")
    print("    generate --> check[í™˜ê° ê²€ì‚¬]")
    print("    check -->|grounded| END")
    print("    check -->|hallucinated| fallback")
    print("    fallback --> generate")
    print("```")


if __name__ == "__main__":
    print("\n" + "="*60)
    print("Advanced RAG ì˜ˆì œ - Self-RAG & Corrective RAG")
    print("="*60)
    
    if not get_settings().validate_openai_key():
        print("\nâš ï¸ OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        sys.exit(1)
    
    visualize_graph()
    
    queries = [
        "Self-RAGë€ ë¬´ì—‡ì¸ê°€ìš”?",
        "Hallucinationì„ ë°©ì§€í•˜ëŠ” ë°©ë²•ì€?",
        "íŒŒì´ì¬ìœ¼ë¡œ ì›¹ì„œë²„ ë§Œë“œëŠ” ë²•ì€?",  # ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
    ]
    
    for q in queries:
        try:
            run_advanced_rag(q)
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
        print()
