# -*- coding: utf-8 -*-
"""
02. Naive RAG ì˜ˆì œ - ê¸°ë³¸ RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„

LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¥ ê¸°ë³¸ì ì¸ ê²€ìƒ‰-ìƒì„±(Retrieve-Generate) íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.
StateGraphë¥¼ í™œìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ì™€ ìƒì„±ëœ ë‹µë³€ì„ ìƒíƒœë¡œ ê´€ë¦¬í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.

í•™ìŠµ ëª©í‘œ:
    1. RAGì˜ í‘œì¤€ íŒŒì´í”„ë¼ì¸(Retrieve -> Generate) êµ¬í˜„
    2. ì‚¬ìš©ì ì •ì˜ State(TypedDict) ì„¤ê³„
    3. Vector Store ì—°ë™ ë° ê²€ìƒ‰ ë…¸ë“œ êµ¬í˜„

ì‹¤í–‰ ë°©ë²•:
    python examples/02_naive_rag.py
"""

import sys
from pathlib import Path
from typing import TypedDict, List, Annotated

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, START, END

from config.settings import get_settings
from utils.llm_factory import get_llm, get_embeddings, log_llm_error
from utils.vector_store import VectorStoreManager


# =============================================================================
# 1. State ì •ì˜
# =============================================================================

class RAGState(TypedDict):
    """
    RAG íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì •ì˜
    
    í•„ë“œ ì„¤ëª…:
    - question: ì‚¬ìš©ì ì§ˆë¬¸ (Input)
    - documents: ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ (Intermediate)
    - answer: ìµœì¢… ë‹µë³€ (Output)
    """
    question: str
    documents: List[Document]
    answer: str


# =============================================================================
# 2. Vector Store ë° ë°ì´í„° ì¤€ë¹„
# =============================================================================

def get_vector_store() -> VectorStoreManager:
    """Vector Store ì´ˆê¸°í™” ë° ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ (ì‹±ê¸€í†¤ íŒ¨í„´)"""
    # ì‹¤ì œë¡œëŠ” ë³„ë„ ì„¤ì •ì´ë‚˜ DBì—ì„œ ë¡œë“œí•˜ê² ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ë©”ëª¨ë¦¬ì— ìƒì„±
    embeddings = get_embeddings()
    manager = VectorStoreManager(embeddings=embeddings, collection_name="naive_rag")
    
    # ìƒ˜í”Œ ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì¶”ê°€
    # (ì£¼ì˜: ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” ë§¤ë²ˆ ì¶”ê°€í•˜ì§€ ì•Šë„ë¡ ì²´í¬ ë¡œì§ í•„ìš”)
    if True: # ê°„ë‹¨í•œ ì˜ˆì œë¥¼ ìœ„í•´ í•­ìƒ ë¡œë“œ ì‹œë„ (VectorStoreManager ë‚´ë¶€ì—ì„œ ì¤‘ë³µ ì²˜ë¦¬ ê°€ì •í•˜ê±°ë‚˜ ë§¤ë²ˆ ì¬ìƒì„±)
        texts = [
            "LangGraphëŠ” LangChain ìœ„ì—ì„œ êµ¬ì¶•ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ìˆœí™˜(Cyclic) ê·¸ë˜í”„ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.",
            "RAG(Retrieval-Augmented Generation)ëŠ” ì™¸ë¶€ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ì—¬ LLMì˜ ë§¥ë½ì„ ë³´ê°•í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.",
            "LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.",
            "StateGraphëŠ” LangGraphì˜ í•µì‹¬ í´ë˜ìŠ¤ë¡œ, ìƒíƒœë¥¼ ê°€ì§„ ë…¸ë“œë“¤ì˜ íë¦„ì„ ì •ì˜í•©ë‹ˆë‹¤.",
        ]
        manager.add_texts(texts)

    return manager


# =============================================================================
# 3. ë…¸ë“œ í•¨ìˆ˜ ì •ì˜
# =============================================================================

def retrieve(state: RAGState):
    """ë¬¸ì„œ ê²€ìƒ‰ ë…¸ë“œ"""
    print(f"\nğŸ” ê²€ìƒ‰ ìˆ˜í–‰: {state['question']}")
    vs = get_vector_store()
    docs = vs.search(state["question"], k=2)
    return {"documents": docs}


def generate(state: RAGState):
    """ë‹µë³€ ìƒì„± ë…¸ë“œ"""
    print("ğŸ“ ë‹µë³€ ìƒì„± ì¤‘...")
    
    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context = "\n\n".join(doc.page_content for doc in state["documents"])
    
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    template = """ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
    
    ì»¨í…ìŠ¤íŠ¸:
    {context}
    
    ì§ˆë¬¸: {question}
    """
    prompt = ChatPromptTemplate.from_template(template)
    
    # ì²´ì¸ êµ¬ì„±
    llm = get_llm()
    chain = prompt | llm
    
    response = chain.invoke({
        "context": context,
        "question": state["question"]
    })
    
    return {"answer": response.content}


# =============================================================================
# 4. ê·¸ë˜í”„ êµ¬ì„±
# =============================================================================

def create_rag_graph():
    """Naive RAG ê·¸ë˜í”„ ìƒì„±"""
    builder = StateGraph(RAGState)
    
    # ë…¸ë“œ ì¶”ê°€
    builder.add_node("retrieve", retrieve)
    builder.add_node("generate", generate)
    
    # ì—£ì§€ ì—°ê²° (ì„ í˜• êµ¬ì¡°)
    # START -> retrieve -> generate -> END
    builder.add_edge(START, "retrieve")
    builder.add_edge("retrieve", "generate")
    builder.add_edge("generate", END)
    
    return builder.compile()


# =============================================================================
# 5. ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸
# =============================================================================

if __name__ == "__main__":
    print("\nLangGraph Naive RAG Example")
    
    graph = create_rag_graph()
    
    questions = [
        "LangGraphê°€ ë¬´ì—‡ì¸ê°€ìš”?",
        "RAGì˜ ëœ»ì€?",
    ]
    
    for q in questions:
        print(f"\n{'='*40}\nì§ˆë¬¸: {q}\n{'='*40}")
        try:
            result = graph.invoke({"question": q})
            print(f"\nğŸ¤– ë‹µë³€: {result['answer']}")
        except Exception as e:
            log_llm_error(e)
