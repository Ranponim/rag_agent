# -*- coding: utf-8 -*-
# ì´ íŒŒì¼ì€ UTF-8 ì¸ì½”ë”©ì„ ì‚¬ìš©í•˜ì—¬ í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤. (ì´ˆì‹¬ììš© ìƒì„¸ ì£¼ì„ ë²„ì „)

"""
============================================================================
ğŸ“š 04a. Adaptive RAG - ì§ˆë¬¸ì˜ ë‚œì´ë„ì— ë§ì¶° ìŠ¤ìŠ¤ë¡œ ë³€í•˜ëŠ” AI
============================================================================

ì‚¬ìš©ìê°€ ë¬¼ì–´ë³´ëŠ” ì§ˆë¬¸ì´ 'ì‰¬ìš´ì§€', 'ë³´í†µì¸ì§€', 'ì–´ë ¤ìš´ì§€' AIê°€ ë¨¼ì € íŒë‹¨í•˜ê³ , 
ê·¸ ë‚œì´ë„ì— ê°€ì¥ ì í•©í•œ ê²€ìƒ‰ ì „ëµì„ ìë™ìœ¼ë¡œ ì„ íƒí•˜ëŠ” 'ì ì‘í˜• RAG' ê¸°ë²•ì…ë‹ˆë‹¤.

ğŸ¯ í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸:
    1. ì§ˆë¬¸ ë¶„ë¥˜: ì§ˆë¬¸ì„ simple(ì‰¬ì›€), moderate(ë³´í†µ), complex(ì–´ë ¤ì›€)ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    2. ë™ì  ê²½ë¡œ: ë‚œì´ë„ì— ë”°ë¼ ì„œë¡œ ë‹¤ë¥¸ ì²˜ë¦¬ ê³¼ì •(ë…¸ë“œ)ìœ¼ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.
    3. íš¨ìœ¨ì„±: ì‰¬ìš´ ê±´ ë°”ë¡œ ë‹µí•´ì„œ ì•„ë¼ê³ , ì–´ë ¤ìš´ ê±´ ê¹Šê²Œ ì¡°ì‚¬í•´ì„œ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
"""

# =============================================================================
# ğŸ“¦ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (ë„êµ¬í•¨ ì—´ê¸°)
# =============================================================================

import sys                              # ì‹œìŠ¤í…œ í™˜ê²½ ì œì–´
import os                               # í™˜ê²½ë³€ìˆ˜ ì ‘ê·¼ìš©
from pathlib import Path                # íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬
from typing import TypedDict, List, Literal  # ë°ì´í„° í˜•ì‹ ë° ë¦¬í„°ëŸ´ íƒ€ì… ì •ì˜

# í”„ë¡œì íŠ¸ ìµœìƒìœ„ í´ë”ë¥¼ ì¸ì‹ì‹œì¼œ configë‚˜ utilsë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
sys.path.insert(0, str(Path(__file__).parent.parent))

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# LangChain ë¬¸ì„œ í˜•ì‹ ë° í”„ë¡¬í”„íŠ¸ ë„êµ¬
from langchain_openai import ChatOpenAI # LLM ëª¨ë¸ í´ë˜ìŠ¤
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate

# LangGraph ìˆœì„œë„(ê·¸ë˜í”„) ì œì‘ ë„êµ¬
from langgraph.graph import StateGraph, START, END

# í”„ë¡œì íŠ¸ ì „ìš© ìœ í‹¸ë¦¬í‹°
from utils.llm_factory import get_embeddings, log_llm_error
from utils.vector_store import VectorStoreManager


# =============================================================================
# ğŸ“‹ 1. ìƒíƒœ(State) ì •ì˜í•˜ê¸° (ê³µìœ  ì‘ì—…ë…¸íŠ¸)
# =============================================================================

class AdaptiveRAGState(TypedDict):
    """ì¼ì˜ ì§„í–‰ ìƒí™©ì„ ê¸°ë¡í•  í•­ëª©ë“¤ì…ë‹ˆë‹¤."""
    question: str                    # ì‚¬ìš©ìê°€ ë˜ì§„ ì§ˆë¬¸
    query_complexity: str            # AIê°€ íŒë³„í•œ ì§ˆë¬¸ì˜ ë‚œì´ë„ (ì‰¬ì›€/ë³´í†µ/ì–´ë ¤ì›€)
    strategy_used: str               # ì´ë²ˆì— ì–´ë–¤ ì „ëµì„ ì¼ëŠ”ì§€ ê¸°ë¡ (í™•ì¸ìš©)
    documents: List[Document]        # ì§€ì‹ ì°½ê³ ì—ì„œ ì°¾ì€ ê²°ê³¼ë“¤
    context: str                     # ë‹µë³€ì„ ìœ„í•´ ì •ë¦¬ëœ ì°¸ê³  ì§€ì‹
    answer: str                      # AIê°€ ë‚´ë†“ì€ ìµœì¢… ë‹µë³€


# =============================================================================
# ğŸ—„ï¸ 2. Vector Store ì´ˆê¸°í™” (ê³µí†µ ëª¨ë“ˆ ì‚¬ìš©)
# =============================================================================

from utils.data_loader import get_rag_vector_store

def get_adaptive_vs() -> VectorStoreManager:
    """ì ì‘í˜• RAGë¥¼ ìœ„í•œ Vector Storeë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤."""
    return get_rag_vector_store(collection_name="rag_collection")


# =============================================================================
# ğŸ§  3. ê´€ë¬¸ ë…¸ë“œ: ì§ˆë¬¸ì˜ ë‚œì´ë„ íŒë³„ (Classification)
# =============================================================================

def classify_query_node(state: AdaptiveRAGState) -> dict:
    """[íŒë³„ ë‹¨ê³„] ì§ˆë¬¸ì„ ì½ê³  'ì‰¬ì›€/ë³´í†µ/ì–´ë ¤ì›€' ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
    print(f"\nğŸ§ [ë¶„ë¥˜] ì§ˆë¬¸ì˜ ìˆ˜ì¤€ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ì–´ë–¤ ì „ëµì´ ì¢‹ì„ê¹Œìš”?")
    
    # AI ëª¨ë¸ ì´ˆê¸°í™”
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    # ì‹¬ì‚¬ìœ„ì› AIì—ê²Œ ì§ˆë¬¸ì˜ ë‚œì´ë„ë¥¼ íŒë‹¨í•´ë‹¬ë¼ê³  ì§€ì‹œí•©ë‹ˆë‹¤.
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ì§ˆë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ 3ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œë§Œ ëŒ€ë‹µí•˜ì„¸ìš”.
1. "simple": ì¸ì‚¬, ì´ë¦„ ë¬»ê¸°, í˜¹ì€ ì•„ì£¼ ë»”í•œ ìƒì‹ ì§ˆë¬¸
2. "moderate": ì§€ì‹ ì°½ê³  ê²€ìƒ‰ì´ í•œ ë²ˆì¯¤ í•„ìš”í•œ ì¼ë°˜ì ì¸ ì§ˆë¬¸
3. "complex": ì—¬ëŸ¬ ê´€ì ì˜ ë¶„ì„, ë¹„êµ, ê¹Šì€ ì‚¬ê³ ê°€ í•„ìš”í•œ ë³µì¡í•œ ì§ˆë¬¸
ì˜¤ì§ ì˜ë¬¸ ë‹¨ì–´ í•˜ë‚˜("simple", "moderate", "complex")ë§Œ ë‹µë³€í•˜ì„¸ìš”."""),
        ("human", "ì‚¬ìš©ì ì§ˆë¬¸: {question}"),
    ])
    
    response = (prompt | model).invoke({"question": state["question"]})
    # AIì˜ ë‹µë³€ì„ ì†Œë¬¸ìë¡œ ë°”ê¾¸ê³  ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤.
    complexity = response.content.lower().strip()
    
    # ë§Œì•½ AIê°€ ì´ìƒí•œ ë§ì„ í•˜ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ 'ë³´í†µ(moderate)'ì„ ì§€ì •í•©ë‹ˆë‹¤.
    if complexity not in ["simple", "moderate", "complex"]:
        complexity = "moderate"
        
    print(f"   â†’ íŒë‹¨ ê²°ê³¼: ì´ ì§ˆë¬¸ì€ '{complexity}' ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
    # íŒë‹¨ ê²°ê³¼ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
    return {"query_complexity": complexity}


# =============================================================================
# ğŸ› ï¸ 4. ì „ëµë³„ í–‰ë™ ìš”ê°• (ê° ë‹¨ê³„ ì •ì˜)
# =============================================================================

def simple_strategy_node(state: AdaptiveRAGState) -> dict:
    """[ì „ëµ 1: ì‰¬ìš´ ì§ˆë¬¸] ê²€ìƒ‰ ì—†ì´ AI ë³¸ì¸ì˜ ìƒì‹ìœ¼ë¡œ ë°”ë¡œ ë‹µí•©ë‹ˆë‹¤."""
    print("âš¡ [Simple] ë„ˆë¬´ ì‰¬ìš´ ì§ˆë¬¸ì´ë¼ ê²€ìƒ‰ ì—†ì´ ë°”ë¡œ ëŒ€ë‹µí•©ë‹ˆë‹¤.")
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    res = model.invoke(state["question"])
    return {"strategy_used": "Simple (ì§ì ‘ ë‹µë³€)", "answer": res.content}


def moderate_strategy_node(state: AdaptiveRAGState) -> dict:
    """[ì „ëµ 2: ë³´í†µ ì§ˆë¬¸] ì§€ì‹ ì°½ê³ ì—ì„œ ìë£Œë¥¼ í•œ ë²ˆ ì°¾ì•„ë³´ê³  ë‹µí•©ë‹ˆë‹¤."""
    print("ğŸ“š [Moderate] ì§€ì‹ ì°½ê³ ì—ì„œ í•„ìš”í•œ ìë£Œë¥¼ í•œ ë²ˆ ì°¾ì•„ë´…ë‹ˆë‹¤.")
    vs = get_adaptive_vs()
    # ì§ˆë¬¸ê³¼ ë‹®ì€ ìë£Œë¥¼ 3ê°œ ì°¾ì•„ì˜µë‹ˆë‹¤.
    docs = vs.search(state["question"], k=3)
    
    # ì°¾ì€ ìë£Œë“¤ì„ í•œë° ë¬¶ìŠµë‹ˆë‹¤.
    context = "\n".join([d.page_content for d in docs])
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    # ì°¾ì€ ìë£Œì™€ í•¨ê»˜ ì§ˆë¬¸ì„ ë˜ì ¸ ë‹µë³€ì„ ë°›ìŠµë‹ˆë‹¤.
    res = model.invoke(f"ì§€ì‹ ë‚´ìš©:\n{context}\n\nì§ˆë¬¸: {state['question']}")
    
    return {
        "strategy_used": "Moderate (ì¼ë°˜ RAG)", 
        "documents": docs, 
        "answer": res.content
    }


def complex_strategy_node(state: AdaptiveRAGState) -> dict:
    """[ì „ëµ 3: ì–´ë ¤ìš´ ì§ˆë¬¸] ì§ˆë¬¸ì„ ìª¼ê°œì„œ ê¹Šê²Œ ì¡°ì‚¬í•˜ê³  ë¶„ì„ ë³´ê³ ì„œë¥¼ ì”ë‹ˆë‹¤."""
    print("ğŸ”¬ [Complex] ì§ˆë¬¸ì´ ë³µì¡í•˜ë„¤ìš”! ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ë‚˜ëˆ ì„œ ì •ë°€ ë¶„ì„í•©ë‹ˆë‹¤.")
    model = ChatOpenAI(
        base_url=os.getenv("OPENAI_API_BASE"),
        api_key=os.getenv("OPENAI_API_KEY"),
        model=os.getenv("OPENAI_MODEL")
    )
    
    # 1. ì–´ë ¤ìš´ ì§ˆë¬¸ì„ í•´ê²°í•˜ê¸° ìœ„í•œ 2ê°œì˜ ì„¸ë¶€ ì§ˆë¬¸ì„ AIì—ê²Œ ë¨¼ì € ë¬¼ì–´ë´…ë‹ˆë‹¤.
    decompose_res = model.invoke(f"ì´ ì–´ë ¤ìš´ ì§ˆë¬¸ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ë¨¼ì € ì•Œì•„ì•¼ í•  ê¸°ì´ˆ ì§ˆë¬¸ 2ê°œë§Œ ë½‘ì•„ì£¼ì„¸ìš”. í•œ ì¤„ì”© ì“°ì„¸ìš”.\nì§ˆë¬¸: {state['question']}")
    sub_queries = [q.strip() for q in decompose_res.content.split("\n") if q.strip()][:2]
    
    print(f"   â†’ ë‹¨ê³„ë³„ ì„¸ë¶€ ì¡°ì‚¬ í•­ëª©: {sub_queries}")
    
    # 2. ì„¸ë¶€ ì§ˆë¬¸ë“¤ë¡œ ê°ê° ì§€ì‹ ì°½ê³ ë¥¼ ë’¤ì§‘ë‹ˆë‹¤.
    vs = get_adaptive_vs()
    all_context = []
    for sq in sub_queries + [state["question"]]:
        docs = vs.search(sq, k=2)
        all_context.extend([d.page_content for d in docs])
    
    # 3. ëª¨ì€ ëª¨ë“  ì •ë³´ë¥¼ í•©ì³ì„œ(ì¤‘ë³µ ì œê±°) ì‹¬ì¸µ ë³´ê³ ì„œ í˜•íƒœì˜ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    final_context = "\n".join(list(set(all_context)))
    res = model.invoke(f"ì‹¬ì¸µ ë¶„ì„ ë‹µë³€ ìš”ì²­:\nê´€ë ¨ëœ ëª¨ë“  ì •ë³´:\n{final_context}\n\nìµœì¢… ì§ˆë¬¸: {state['question']}")
    
    return {
        "strategy_used": "Complex (ë‹¤ë‹¨ê³„ ì •ë°€ RAG)", 
        "answer": res.content
    }


# =============================================================================
# ğŸš¦ 5. ì‹ í˜¸ë“±(ë¼ìš°í„°) ë° ì „ì²´ ì§€ë„(Graph) ë§Œë“¤ê¸°
# =============================================================================

def route_complexity(state: AdaptiveRAGState) -> Literal["simple", "moderate", "complex"]:
    """AIê°€ íŒë‹¨í•œ ë‚œì´ë„ ì¹¸ì„ ë³´ê³  ì–´ëŠ ê¸¸ë¡œ ê°ˆì§€ ì•ˆë‚´í•©ë‹ˆë‹¤."""
    return state["query_complexity"]

def create_graph():
    """ìƒí™©ì— ë”°ë¼ ê¸¸ì´ ë°”ë€ŒëŠ” 'ë˜‘ë˜‘í•œ ì§€ë„'ë¥¼ ì™„ì„±í•©ë‹ˆë‹¤."""
    # ìš°ë¦¬ê°€ ë§Œë“  ì‘ì—…ë…¸íŠ¸(AdaptiveRAGState)ë¥¼ ì‚¬ìš©í•˜ëŠ” ìˆœì„œë„ì…ë‹ˆë‹¤.
    builder = StateGraph(AdaptiveRAGState)
    
    # 1. í•  ì¼(ë…¸ë“œ)ë“¤ì„ ë“±ë¡í•©ë‹ˆë‹¤.
    builder.add_node("classify", classify_query_node) # íŒë³„ì‚¬
    builder.add_node("simple", simple_strategy_node)   # ì‰¬ìš´ ê¸¸
    builder.add_node("moderate", moderate_strategy_node) # ë³´í†µ ê¸¸
    builder.add_node("complex", complex_strategy_node)   # ì–´ë ¤ìš´ ê¸¸
    
    # 2. ì‹œì‘ ì „ì—ëŠ” ë¬´ì¡°ê±´ 'íŒë³„ì‚¬'ì—ê²Œ ë³´ë‚´ì¤ë‹ˆë‹¤.
    builder.add_edge(START, "classify")
    
    # 3. íŒë³„ì‚¬ê°€ ì •í•œ ë‚œì´ë„ì— ë”°ë¼ ì„¸ ê°ˆë˜ ê¸¸ë¡œ ë‚˜ëˆ  ë³´ëƒ…ë‹ˆë‹¤. (ì¡°ê±´ë¶€ ì—°ê²°)
    builder.add_conditional_edges(
        "classify",
        route_complexity, # ì‹ í˜¸ë“± ì—­í•  í•¨ìˆ˜
        {
            "simple": "simple",
            "moderate": "moderate",
            "complex": "complex"
        }
    )
    
    # 4. ì–´ë–¤ ê¸¸ë¡œ ê°€ë“  ë§ˆì§€ë§‰ì—” ëŒ€í™”ê°€ ëë‚©ë‹ˆë‹¤(END).
    builder.add_edge("simple", END)
    builder.add_edge("moderate", END)
    builder.add_edge("complex", END)
    
    # 5. ì™„ì„±ëœ ì§€ë„ë¥¼ ì‹¤í–‰ê¸°ì— ë„£ìŠµë‹ˆë‹¤.
    return builder.compile()


# =============================================================================
# â–¶ï¸ 6. ì‹¤ì œë¡œ ëŒë ¤ë³´ê¸° (ì‹¤í–‰ í”„ë¡œê·¸ë¨)
# =============================================================================

def run_adaptive_rag(query: str, app):
    """ì§ˆë¬¸ì„ í•˜ë©´ AIê°€ ë‚œì´ë„ë¥¼ ë¶„ì„í•˜ê³  ê·¸ì— ë§ì¶° ë‹µë³€í•´ì¤ë‹ˆë‹¤."""
    print(f"\n{'='*60}")
    print(f"ğŸ™‹ ì§ˆë¬¸: {query}")
    print(f"{'='*60}")
    
    try:
        # ê°€ë™ ì¤€ë¹„ ë° ì´ˆê¸° ë©”ëª¨ì¥ ì„¸íŒ…
        result = app.invoke({
            "question": query,
            "query_complexity": "",
            "strategy_used": "",
            "documents": [],
            "context": "",
            "answer": ""
        })
        
        # ì–´ë–¤ ì „ëµì„ ê³¨ëëŠ”ì§€ì™€ ìµœì¢… ë‹µë³€ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
        print(f"\nğŸ“Š ì„ íƒëœ ì „ëµ: {result['strategy_used']}")
        print(f"\nğŸ¤– AIì˜ ë‹µë³€:\n{result['answer']}")
        
    except Exception as e:
        log_llm_error(e)
        print(f"âŒ ë„ì¤‘ì— ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë‚¬ìŠµë‹ˆë‹¤: {e}")


if __name__ == "__main__":
    print("\n" + "ğŸŒŸ ìƒí™© ë§ì¶¤í˜• Adaptive RAGë¥¼ ê°€ë™í•©ë‹ˆë‹¤! ğŸŒŸ")
    print("ì§ˆë¬¸ì˜ ë‚œì´ë„ë¥¼ AIê°€ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ì—¬ ê°€ì¥ íš¨ìœ¨ì ìœ¼ë¡œ ì¼í•©ë‹ˆë‹¤.")
    print("- ì¢…ë£Œí•˜ë ¤ë©´ 'q' í˜¹ì€ 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")
    
    # 1. ë¼ˆëŒ€ê°€ ë˜ëŠ” íë¦„ë„ ê¸°ê³„ë¥¼ ì™„ì„±í•©ë‹ˆë‹¤.
    app = create_graph()
    
    # 2. ì§ˆë¬¸ì„ ê³„ì† ë°›ìŠµë‹ˆë‹¤.
    while True:
        try:
            user_input = input("ğŸ™‹ ì–´ë–¤ ê²ƒì´ë“  ë¬¼ì–´ë³´ì„¸ìš” : ").strip()
            
            if not user_input: continue
                
            if user_input.lower() in ("quit", "exit", "q"):
                print("ğŸ‘‹ ë˜‘ë˜‘í•œ ëŒ€í™”ë¥¼ ì¦ê²¨ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ì•ˆë…•íˆ ê°€ì„¸ìš”.")
                break
                
            # ì§ˆë¬¸ìœ¼ë¡œ ì‹œìŠ¤í…œ ì‘ë™!
            run_adaptive_rag(user_input, app)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ê¸‰íˆ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâš ï¸ ì‹œìŠ¤í…œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            break
