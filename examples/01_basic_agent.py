# -*- coding: utf-8 -*-
"""
01. Basic Agent ì˜ˆì œ - LangGraph ê¸°ë³¸ ê°œë… í•™ìŠµ

ì´ ì˜ˆì œëŠ” LangGraphì˜ ìµœì‹  í‘œì¤€ íŒ¨í„´ì„ ì ìš©í•œ ê¸°ë³¸ Agentì…ë‹ˆë‹¤.
`MessagesState`ì™€ `tools_condition`ì„ ì‚¬ìš©í•˜ì—¬ ê°„ê²°í•˜ê³  í‘œì¤€ì ì¸ ê·¸ë˜í”„ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

í•™ìŠµ ëª©í‘œ:
    1. StateGraph(MessagesState) í‘œì¤€ êµ¬ì¡° ì´í•´
    2. prebuilt.tools_conditionì„ ì´ìš©í•œ ì¡°ê±´ë¶€ ë¶„ê¸° í‘œì¤€í™”
    3. LLMì— ë„êµ¬ ë°”ì¸ë”© ë° ìƒíƒœ ê´€ë¦¬

ì‹¤í–‰ ë°©ë²•:
    python examples/01_basic_agent.py
"""

import sys
from pathlib import Path
from typing import Annotated, Literal  # Annotated: ìƒíƒœ ì—…ë°ì´íŠ¸ ë°©ì‹ ì§€ì •, Literal: ê°’ì˜ ì¢…ë¥˜ ì œí•œ

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€í•˜ì—¬ ë‚´ë¶€ ëª¨ë“ˆ(config, utils)ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆê²Œ í•¨
sys.path.insert(0, str(Path(__file__).parent.parent))

# ğŸ” LangChain DEBUG ë¡œê¹… í™œì„±í™” - LLMê³¼ ì£¼ê³ ë°›ëŠ” raw ë©”ì‹œì§€ í™•ì¸
import langchain
langchain.debug = True  # ìƒì„¸ ë¡œê·¸ë¥¼ ìœ„í•´ ë‹¤ì‹œ ì¼­ë‹ˆë‹¤
# ë˜ëŠ” ë” ìƒì„¸í•œ ë¡œê·¸:
# import logging
# logging.getLogger("langchain").setLevel(logging.DEBUG)
# logging.getLogger("openai").setLevel(logging.DEBUG)
# logging.getLogger("httpx").setLevel(logging.DEBUG)

# LangChain: ëŒ€í™” ë©”ì‹œì§€ êµ¬ì¡° ë° ë„êµ¬ ì •ì˜
from langchain_core.messages import HumanMessage, SystemMessage  # Human: ì‚¬ìš©ì ë©”ì‹œì§€, System: AI ì§€ì¹¨
from langchain_core.tools import tool  # íŒŒì´ì¬ í•¨ìˆ˜ë¥¼ AI ë„êµ¬ë¡œ ë³€í™˜í•˜ëŠ” ë°ì½”ë ˆì´í„°

# LangGraph: ê·¸ë˜í”„ ê¸°ë°˜ ì—ì´ì „íŠ¸ ì„¤ê³„ ë° ì‹¤í–‰
from langgraph.graph import StateGraph, MessagesState, START, END  # ê·¸ë˜í”„ ë¹Œë”, í‘œì¤€ ìƒíƒœ, ì‹œì‘/ì¢…ë£Œ ì§€ì 
from langgraph.prebuilt import ToolNode, tools_condition  # í‘œì¤€ ë„êµ¬ ì‹¤í–‰ ë…¸ë“œ ë° ìë™ ë¼ìš°íŒ… ì¡°ê±´

# í”„ë¡œì íŠ¸ ìœ í‹¸ë¦¬í‹°: ì„¤ì • ë¡œë“œ ë° LLM ìƒì„± íŒ©í† ë¦¬
from config.settings import get_settings  # ì¤‘ì•™ ì„¤ì •(API í‚¤, ëª¨ë¸ëª… ë“±) ë¡œë“œ
from utils.llm_factory import get_llm, log_llm_error  # LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì˜¤ë¥˜ ë¡œê¹… ìœ í‹¸ë¦¬í‹°
from utils.harmony_parser import parse_harmony_tool_call, clean_history_for_harmony  # GPT-OSS Harmony ìœ í‹¸ë¦¬í‹°


# =============================================================================
# 1. ë„êµ¬(Tool) ì •ì˜
# =============================================================================

@tool
def get_weather(city: str) -> str:
    """íŠ¹ì • ë„ì‹œì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    weather_data = {
        "ì„œìš¸": "ë§‘ìŒ, 15Â°C",
        "ë¶€ì‚°": "íë¦¼, 18Â°C",
        "ì œì£¼": "ë¹„, 20Â°C",
        "ì¸ì²œ": "ë§‘ìŒ, 14Â°C",
    }
    return weather_data.get(city, f"{city}ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


@tool
def calculate(expression: str) -> str:
    """ìˆ˜í•™ í‘œí˜„ì‹ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    try:
        return f"ê²°ê³¼: {eval(expression)}"
    except Exception as e:
        return f"ê³„ì‚° ì˜¤ë¥˜: {str(e)}"


tools = [get_weather, calculate]


# =============================================================================
# 2. Agent ë…¸ë“œ ì •ì˜
# =============================================================================

def agent_node(state: MessagesState):
    """
    Agent ë…¸ë“œ: ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLM ì‘ë‹µ ìƒì„±
    
    í‘œì¤€ íŒ¨í„´:
    - LLM ì¸ìŠ¤í„´ìŠ¤ëŠ” ë…¸ë“œ ë‚´ë¶€ í˜¹ì€ ì™¸ë¶€ì—ì„œ ì¤€ë¹„ ê°€ëŠ¥
    - bind_toolsë¡œ ë„êµ¬ ì •ë³´ ì£¼ì…
    - state["messages"] ì „ì²´ë¥¼ ì „ë‹¬í•˜ì—¬ ë¬¸ë§¥ ìœ ì§€
    """
    import json
    
    llm = get_llm()
    # ğŸ’¡ vLLM/Local LLM í˜¸í™˜ì„±: ë³‘ë ¬ ë„êµ¬ í˜¸ì¶œ ë¹„í™œì„±í™” (ë§ì€ ì„œë²„ê°€ ì§€ì›í•˜ì§€ ì•ŠìŒ)
    llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì •ì˜
    sys_msg = SystemMessage(content="ë‹¹ì‹ ì€ ë‚ ì”¨ ì¡°íšŒì™€ ê³„ì‚°ì„ ë•ëŠ” ìœ ìš©í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.")

    # ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
    messages = [sys_msg] + state["messages"]
    
    # ğŸ§¹ vLLM í˜¸í™˜ì„±: LLMì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í´ë¦°í•œ í¬ë§·ìœ¼ë¡œ ë³€í™˜ (History Cleaning)
    cleaned_messages = clean_history_for_harmony(messages)
    
    # LLM í˜¸ì¶œ
    response = llm_with_tools.invoke(cleaned_messages)
    
    # ğŸ” ë””ë²„ê¹… ë¡œê·¸: LLM ì‘ë‹µ ìƒì„¸ ë¶„ì„
    print(f"\n{'='*60}")
    print(f"ğŸ” [DEBUG] LLM ì‘ë‹µ ë¶„ì„")
    print(f"{'='*60}")
    print(f"ğŸ“Œ response type: {type(response).__name__}")
    print(f"ğŸ“Œ response.content: {repr(response.content)}")
    print(f"ğŸ“Œ response.tool_calls: {response.tool_calls}")
    print(f"ğŸ“Œ response.additional_kwargs: {json.dumps(response.additional_kwargs, indent=2, ensure_ascii=False, default=str)}")
    
    # contentê°€ JSONì¸ì§€ í™•ì¸
    if response.content and isinstance(response.content, str):
        try:
            parsed = json.loads(response.content)
            print(f"ğŸ“Œ content JSON íŒŒì‹± ê²°ê³¼: {json.dumps(parsed, indent=2, ensure_ascii=False)}")
        except json.JSONDecodeError:
            print(f"ğŸ“Œ contentëŠ” JSONì´ ì•„ë‹˜ (ì¼ë°˜ í…ìŠ¤íŠ¸)")
    print(f"{'='*60}\n")
    
    # ğŸ”§ GPT-OSS Harmony í¬ë§· íŒŒì‹±: contentì˜ JSONì„ tool_callsë¡œ ë³€í™˜
    response = parse_harmony_tool_call(response, tools)
    
    if response.tool_calls:
        print(f"ğŸ”§ [HARMONY] tool_calls ë³€í™˜ ì™„ë£Œ: {[tc['name'] for tc in response.tool_calls]}")
    
    # ìƒˆë¡œìš´ ë©”ì‹œì§€ë§Œ ë°˜í™˜ (MessagesStateê°€ ìë™ìœ¼ë¡œ append ì²˜ë¦¬)
    return {"messages": [response]}


# =============================================================================
# 3. ê·¸ë˜í”„ êµ¬ì„± (í‘œì¤€ íŒ¨í„´)
# =============================================================================

def create_agent_graph():
    """
    LangGraph í‘œì¤€ íŒ¨í„´ì„ ì ìš©í•œ Agent ê·¸ë˜í”„ ìƒì„±
    
    íŠ¹ì§•:
    - MessagesState ì‚¬ìš©
    - prebuilt.ToolNode ì‚¬ìš©
    - prebuilt.tools_condition ì‚¬ìš© (ì§ì ‘ ë¼ìš°í„° í•¨ìˆ˜ ì‘ì„± ë¶ˆí•„ìš”)
    """
    # 1. ê·¸ë˜í”„ ë¹Œë” ì´ˆê¸°í™”
    builder = StateGraph(MessagesState)
    
    # 2. ë…¸ë“œ ì¶”ê°€
    builder.add_node("agent", agent_node)
    builder.add_node("tools", ToolNode(tools))
    
    # 3. ì—£ì§€ ì¶”ê°€
    # ì‹œì‘ -> ì—ì´ì „íŠ¸
    builder.add_edge(START, "agent")
    
    # ì¡°ê±´ë¶€ ì—£ì§€ (í‘œì¤€ ë¼ìš°í„° ì‚¬ìš©)
    # tools_conditionì€:
    # - tool_callsê°€ ìˆìœ¼ë©´ "tools"ë¡œ ì´ë™
    # - ì—†ìœ¼ë©´ ENDë¡œ ì´ë™
    builder.add_conditional_edges(
        "agent",
        tools_condition,
    )
    
    # ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ ì—ì´ì „íŠ¸ë¡œ (ReAct íŒ¨í„´)
    builder.add_edge("tools", "agent")
    
    # 4. ì»´íŒŒì¼
    return builder.compile()


# =============================================================================
# 4. ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸
# =============================================================================

def run_agent(query: str):
    """Agent ì‹¤í–‰ í•¨ìˆ˜"""
    graph = create_agent_graph()
    
    print(f"\n{'='*60}")
    print(f"ğŸ™‹ ì‚¬ìš©ì: {query}")
    print('='*60)
    
    try:
        # invoke ëª¨ë“œë¡œ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë° ëŒ€ì‹ )
        result = graph.invoke(
            {"messages": [HumanMessage(content=query)]}
        )
        
        final_msg = result["messages"][-1] if result.get("messages") else None
        
        if final_msg:
             print(f"\nğŸ¤– ìµœì¢… ë‹µë³€: {final_msg.content}")

    except Exception as e:
        log_llm_error(e)
        print("âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    print("\nLangGraph Basic Agent (Standard Pattern)")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")
    
    while True:
        try:
            query = input("ğŸ™‹ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if not query:
                continue
            
            if query.lower() in ("quit", "exit", "q"):
                print("ğŸ‘‹ Agentë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            run_agent(query)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Agentë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except EOFError:
            print("\nğŸ‘‹ Agentë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
